{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e823a433",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'FilesRouge'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-39fff50500b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbart\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBARTModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrouge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRouge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFilesRouge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm_notebook\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'FilesRouge'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from fairseq.models.bart import BARTModel\n",
    "from rouge import Rouge, FilesRouge\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(\"gpu num: \", n_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9950ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from rouge import Rouge, FilesRouge\n",
    "from tqdm import tqdm as tqdm\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "def create_hypotheses(weights_path, data_path, test_hypo):\n",
    "    bart = BARTModel.from_pretrained(\n",
    "        weights_path,\n",
    "        checkpoint_file='checkpoint_best.pt',\n",
    "        data_name_or_path=data_path\n",
    "    )\n",
    "\n",
    "    bart.eval()\n",
    "    bart.cuda()\n",
    "    count = 1\n",
    "    bsz = 8\n",
    "    test_trans = './data/dialogsum/DialogSum_Data/test_dialogsum_sent_trans_cons_label_2.source'\n",
    "    test_c99 = './data/dialogsum/DialogSum_Data/test_dialogsum_sent_c99_label.source'\n",
    "    with open(test_trans) as source, open(test_c99) as source2, open(test_hypo, 'wt', encoding='utf-8') as fout:\n",
    "        s1 = source.readlines()\n",
    "        s2 = source2.readlines()\n",
    "\n",
    "        slines = [s1[0].strip()]\n",
    "        slines2 = [s2[0].strip()]\n",
    "\n",
    "        for i in tqdm(range(1, len(s1))):\n",
    "            if count % bsz == 0:\n",
    "                with torch.no_grad():\n",
    "                    hypotheses_batch = bart.sample(slines, sentences2 = slines2, balance = True, beam=4, lenpen=2.0, max_len_b=100, min_len=5, no_repeat_ngram_size=3)\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                for hypothesis in hypotheses_batch:\n",
    "                    fout.write(hypothesis + '\\n')\n",
    "                    fout.flush()\n",
    "                slines = []\n",
    "                slines2 = []\n",
    "\n",
    "            slines.append(s1[i].strip())\n",
    "            slines2.append(s2[i].strip())\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        if slines != []:\n",
    "\n",
    "            hypotheses_batch = bart.sample(slines, sentences2 = slines2, balance = True, beam=4, lenpen=2.0, max_len_b=100, min_len=5, no_repeat_ngram_size=3)\n",
    "\n",
    "\n",
    "            for hypothesis in hypotheses_batch:\n",
    "                fout.write(hypothesis + '\\n')\n",
    "                fout.flush()\n",
    "\n",
    "    \n",
    "def load_ref_and_hypo(hyp_path, tokenize=False):\n",
    "    ref_path = './data/dialogsum/DialogSum_Data/test_dialogsum_sent_trans_cons_label_2.target'\n",
    "    hypotheses = []\n",
    "    with open(hyp_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            hypotheses.append(l[:-1])\n",
    "\n",
    "    reference = []\n",
    "    with open(ref_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            reference.append(l[:-1])\n",
    "\n",
    "    if tokenize:\n",
    "        hypotheses = [hypo.split() for hypo in hypotheses]\n",
    "        reference = [ref.split() for ref in reference]\n",
    "\n",
    "    return hypotheses, reference\n",
    "    \n",
    "    \n",
    "def get_rouge(hyp_path):\n",
    "    hypothesis, reference = load_ref_and_hypo(hyp_path)\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(hypothesis, reference, avg = True)\n",
    "    #print('Test', rouge.get_scores(hypothesis, reference, avg = True))\n",
    "\n",
    "    print('TEST')\n",
    "    for key, metric in scores.items():\n",
    "        print(key)\n",
    "        for k, v in metric.items():\n",
    "            print(f'{k}: {v}')\n",
    "        \n",
    "\n",
    "def get_bleu(hyp_path):\n",
    "    hypotheses, reference = load_ref_and_hypo(hyp_path, tokenize=True)\n",
    "    print('Corpus BLEU 1-gram: %f' % corpus_bleu(reference, hypotheses, weights=(1, 0, 0, 0)))\n",
    "    print('Corpus BLEU 2-gram: %f' % corpus_bleu(reference, hypotheses, weights=(0.5, 0.5, 0, 0)))\n",
    "    print('Corpus BLEU 3-gram: %f' % corpus_bleu(reference, hypotheses, weights=(0.33, 0.33, 0.33, 0)))\n",
    "    print('Corpus BLEU 4-gram: %f' % corpus_bleu(reference, hypotheses, weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "\n",
    "\n",
    "def get_meteor(hyp_path):\n",
    "    hypotheses, reference = load_ref_and_hypo(hyp_path, tokenize=True)\n",
    "    reference = [[ref] for ref in reference]\n",
    "    meteor_score = corpus_meteor(reference, hypotheses)\n",
    "    print('METEOR: %f' % meteor_score)\n",
    "\n",
    "    \n",
    "def corpus_meteor(expected, predicted):\n",
    "    meteor_score_sentences_list = list()\n",
    "    [meteor_score_sentences_list.append(meteor_score(expect, predict)) for expect, predict in zip(expected, predicted)]\n",
    "    meteor_score_res = np.mean(meteor_score_sentences_list)\n",
    "    return meteor_score_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6650234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = 'checkpoints_multi_view'\n",
    "data_path = './cnn_dm-bin_2'\n",
    "test_hypo_pretrained = './data/dialogsum/DialogSum_Data/test_best_multi_attn_best_PRETRAINED.hypo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71baae74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2a8694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 499/499 [05:57<00:00,  1.40it/s]\n"
     ]
    }
   ],
   "source": [
    "create_hypotheses(weights_path, data_path, test_hypo_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b92b8399",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = 'train_sh/checkpoints_stage'\n",
    "data_path = '../dialogsum-bin'\n",
    "test_hypo_single = './data/dialogsum/DialogSum_Data/test_best_multi_attn_best_SINGLE.hypo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "172b78b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 499/499 [06:41<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "create_hypotheses(weights_path, data_path, test_hypo_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6bda402",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = 'train_sh/checkpoints'\n",
    "data_path = '../dialogsum-bin_2'\n",
    "test_hypo_multi = './data/dialogsum/DialogSum_Data/test_best_multi_attn_best_MULTI.hypo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bddebc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 499/499 [07:05<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "create_hypotheses(weights_path, data_path, test_hypo_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "acf7a09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_best_multi_attn_best_PRETRAINED.hypo\n",
      "TEST\n",
      "rouge-1\n",
      "r: 0.42381762924534044\n",
      "p: 0.3106988218727275\n",
      "f: 0.34378587073025224\n",
      "rouge-2\n",
      "r: 0.16600478963012985\n",
      "p: 0.12211266858958905\n",
      "f: 0.13351775470396782\n",
      "rouge-l\n",
      "r: 0.3963902365567834\n",
      "p: 0.2902285889817407\n",
      "f: 0.3213212855506028\n",
      "Corpus BLEU 1-gram: 0.025165\n",
      "Corpus BLEU 2-gram: 0.001339\n",
      "Corpus BLEU 3-gram: 0.000000\n",
      "Corpus BLEU 4-gram: 0.000000\n",
      "METEOR: 0.284844\n",
      "\n",
      "\n",
      "test_best_multi_attn_best_SINGLE.hypo\n",
      "TEST\n",
      "rouge-1\n",
      "r: 0.5678239788779302\n",
      "p: 0.3457162632182704\n",
      "f: 0.4214851315520334\n",
      "rouge-2\n",
      "r: 0.24301067687032568\n",
      "p: 0.13907783503136428\n",
      "f: 0.1724773875682337\n",
      "rouge-l\n",
      "r: 0.5112094712565164\n",
      "p: 0.31107723812728544\n",
      "f: 0.3794061540863322\n",
      "Corpus BLEU 1-gram: 0.024588\n",
      "Corpus BLEU 2-gram: 0.000000\n",
      "Corpus BLEU 3-gram: 0.000000\n",
      "Corpus BLEU 4-gram: 0.000000\n",
      "METEOR: 0.379528\n",
      "\n",
      "\n",
      "test_best_multi_attn_best_MULTI.hypo\n",
      "TEST\n",
      "rouge-1\n",
      "r: 0.5688160508107216\n",
      "p: 0.33706890414542284\n",
      "f: 0.41499642528639163\n",
      "rouge-2\n",
      "r: 0.2374550157172321\n",
      "p: 0.12811426409120022\n",
      "f: 0.16217903172240364\n",
      "rouge-l\n",
      "r: 0.5177856624326739\n",
      "p: 0.30623147148425145\n",
      "f: 0.3773594050422384\n",
      "Corpus BLEU 1-gram: 0.021093\n",
      "Corpus BLEU 2-gram: 0.001080\n",
      "Corpus BLEU 3-gram: 0.000000\n",
      "Corpus BLEU 4-gram: 0.000000\n",
      "METEOR: 0.372279\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for path in [test_hypo_pretrained, test_hypo_single, test_hypo_multi]:\n",
    "    print(path.split('/')[-1])\n",
    "    get_rouge(path)\n",
    "    get_bleu(path)\n",
    "    get_meteor(path)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72b4226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses, reference = load_ref_and_hypo(test_hypo_pretrained, tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cc5c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = [[ref] for ref in reference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a64dd353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e14cac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.add_batch(predictions=hypotheses, references=reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5f2d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = metric.compute(predictions=hypotheses, references=reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b5d5654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.07378321415307464,\n",
       " 'precisions': [0.24236798679867988,\n",
       "  0.09498718313870692,\n",
       "  0.04909923213230951,\n",
       "  0.02621895124195032],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.5237297014143532,\n",
       " 'translation_length': 14544,\n",
       " 'reference_length': 9545}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4ba6f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"sacrebleu\")\n",
    "hypotheses, reference = load_ref_and_hypo(test_hypo_pretrained)\n",
    "reference = [[ref] for ref in reference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ddf808e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 12.548407269194492,\n",
       " 'counts': [6011, 2789, 1528, 773],\n",
       " 'totals': [17570, 17070, 16570, 16070],\n",
       " 'precisions': [34.21172453044963,\n",
       "  16.3386057410662,\n",
       "  9.221484610742305,\n",
       "  4.8102053515868075],\n",
       " 'bp': 1.0,\n",
       " 'sys_len': 17570,\n",
       " 'ref_len': 12718}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = metric.compute(predictions=hypotheses, references=reference)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "797ad87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 2.1835719620791547,\n",
       " 'counts': [13, 2, 0, 0],\n",
       " 'totals': [63, 62, 61, 60],\n",
       " 'precisions': [20.634920634920636,\n",
       "  3.225806451612903,\n",
       "  0.819672131147541,\n",
       "  0.4166666666666667],\n",
       " 'bp': 1.0,\n",
       " 'sys_len': 63,\n",
       " 'ref_len': 31}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = metric.compute(predictions=[hypotheses[0]], references=[reference[0]])\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
