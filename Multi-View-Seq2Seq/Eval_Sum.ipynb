{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\r\n",
      "#\r\n",
      "base                     /home/tnguyen/miniconda\r\n",
      "coref                 *  /home/tnguyen/miniconda/envs/coref\r\n",
      "corefs                   /home/tnguyen/miniconda/envs/corefs\r\n",
      "experiment               /home/tnguyen/miniconda/envs/experiment\r\n",
      "fairseq                  /home/tnguyen/miniconda/envs/fairseq\r\n",
      "ma_dialogue              /home/tnguyen/miniconda/envs/ma_dialogue\r\n",
      "seq                      /home/tnguyen/miniconda/envs/seq\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!conda info --envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu num:  1\n"
     ]
    }
   ],
   "source": [
    "from fairseq.models.bart import BARTModel\n",
    "import torch\n",
    "from rouge import Rouge, FilesRouge\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(\"gpu num: \", n_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n"
     ]
    }
   ],
   "source": [
    "bart = BARTModel.from_pretrained(\n",
    "    'checkpoints_multi_view',\n",
    "    checkpoint_file='checkpoint_best.pt',\n",
    "    data_name_or_path='./cnn_dm-bin_2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BARTHubInterface(\n",
       "  (model): BARTModel(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "    (section_positions): LearnedPositionalEmbedding(1025, 1024, padding_idx=0)\n",
       "    (section_layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (section): LSTM(1024, 1024)\n",
       "    (w_proj_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (w_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (w_context_vector): Linear(in_features=1024, out_features=1, bias=False)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart.eval()\n",
    "#bart.cpu()\n",
    "bart.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/499 [00:00<?, ?it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/search.py:81: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  self.beams_buf = self.indices_buf // vocab_size\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_mask,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:567: UserWarning: An output with one or more elements was resized since it had shape [8, 4], which does not match the required output shape [7, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(new_blacklist, active_hypos)\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:577: UserWarning: An output with one or more elements was resized since it had shape [8, 4], which does not match the required output shape [7, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/search.py:79: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(self.scores_buf, self.indices_buf),\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_mask,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:567: UserWarning: An output with one or more elements was resized since it had shape [7, 4], which does not match the required output shape [6, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(new_blacklist, active_hypos)\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:577: UserWarning: An output with one or more elements was resized since it had shape [7, 4], which does not match the required output shape [6, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/search.py:79: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(self.scores_buf, self.indices_buf),\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_mask,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:567: UserWarning: An output with one or more elements was resized since it had shape [6, 4], which does not match the required output shape [5, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(new_blacklist, active_hypos)\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:577: UserWarning: An output with one or more elements was resized since it had shape [6, 4], which does not match the required output shape [5, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_bbsz_idx,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/search.py:79: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(self.scores_buf, self.indices_buf),\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_mask,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:567: UserWarning: An output with one or more elements was resized since it had shape [5, 4], which does not match the required output shape [4, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(new_blacklist, active_hypos)\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:577: UserWarning: An output with one or more elements was resized since it had shape [5, 4], which does not match the required output shape [4, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/search.py:79: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(self.scores_buf, self.indices_buf),\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_mask,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:567: UserWarning: An output with one or more elements was resized since it had shape [4, 4], which does not match the required output shape [3, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(new_blacklist, active_hypos)\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:577: UserWarning: An output with one or more elements was resized since it had shape [4, 4], which does not match the required output shape [3, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/search.py:79: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(self.scores_buf, self.indices_buf),\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_mask,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:567: UserWarning: An output with one or more elements was resized since it had shape [3, 4], which does not match the required output shape [2, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(new_blacklist, active_hypos)\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:577: UserWarning: An output with one or more elements was resized since it had shape [3, 4], which does not match the required output shape [2, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/search.py:79: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(self.scores_buf, self.indices_buf),\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_mask,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:567: UserWarning: An output with one or more elements was resized since it had shape [2, 4], which does not match the required output shape [1, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(new_blacklist, active_hypos)\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:577: UserWarning: An output with one or more elements was resized since it had shape [2, 4], which does not match the required output shape [1, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/search.py:79: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(self.scores_buf, self.indices_buf),\n",
      "  2%|▏         | 8/499 [00:04<04:37,  1.77it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      "  3%|▎         | 16/499 [00:07<03:39,  2.20it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "  5%|▍         | 24/499 [00:10<03:25,  2.32it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 32/499 [00:14<03:28,  2.24it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_mask,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:567: UserWarning: An output with one or more elements was resized since it had shape [7, 4], which does not match the required output shape [5, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(new_blacklist, active_hypos)\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:577: UserWarning: An output with one or more elements was resized since it had shape [7, 4], which does not match the required output shape [5, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/search.py:79: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(self.scores_buf, self.indices_buf),\n",
      "  8%|▊         | 40/499 [00:18<03:42,  2.06it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      " 11%|█         | 56/499 [00:27<03:41,  2.00it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      " 13%|█▎        | 64/499 [00:32<03:54,  1.86it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_mask,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:567: UserWarning: An output with one or more elements was resized since it had shape [5, 4], which does not match the required output shape [3, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(new_blacklist, active_hypos)\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:577: UserWarning: An output with one or more elements was resized since it had shape [5, 4], which does not match the required output shape [3, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/search.py:79: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(self.scores_buf, self.indices_buf),\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 72/499 [00:35<03:35,  1.98it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_mask,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:567: UserWarning: An output with one or more elements was resized since it had shape [4, 4], which does not match the required output shape [2, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(new_blacklist, active_hypos)\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:577: UserWarning: An output with one or more elements was resized since it had shape [4, 4], which does not match the required output shape [2, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/search.py:79: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(self.scores_buf, self.indices_buf),\n",
      " 16%|█▌        | 80/499 [00:40<03:33,  1.96it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      " 19%|█▉        | 96/499 [00:49<03:40,  1.83it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      " 22%|██▏       | 112/499 [00:56<03:11,  2.02it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_mask,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:567: UserWarning: An output with one or more elements was resized since it had shape [8, 4], which does not match the required output shape [6, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(new_blacklist, active_hypos)\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:577: UserWarning: An output with one or more elements was resized since it had shape [8, 4], which does not match the required output shape [6, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/search.py:79: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(self.scores_buf, self.indices_buf),\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 120/499 [01:01<03:14,  1.95it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      " 37%|███▋      | 184/499 [01:36<02:55,  1.79it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      " 40%|████      | 200/499 [01:44<02:40,  1.87it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_mask,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:567: UserWarning: An output with one or more elements was resized since it had shape [3, 4], which does not match the required output shape [1, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(new_blacklist, active_hypos)\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:577: UserWarning: An output with one or more elements was resized since it had shape [3, 4], which does not match the required output shape [1, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/search.py:79: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(self.scores_buf, self.indices_buf),\n",
      " 42%|████▏     | 208/499 [01:48<02:35,  1.87it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_mask,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:567: UserWarning: An output with one or more elements was resized since it had shape [6, 4], which does not match the required output shape [4, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(new_blacklist, active_hypos)\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:577: UserWarning: An output with one or more elements was resized since it had shape [6, 4], which does not match the required output shape [4, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/search.py:79: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(self.scores_buf, self.indices_buf),\n",
      " 43%|████▎     | 216/499 [01:52<02:31,  1.87it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 344/499 [02:59<01:12,  2.13it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "100%|██████████| 499/499 [04:31<00:00,  1.84it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm as tqdm\n",
    "import torch\n",
    "\n",
    "count = 1\n",
    "bsz = 8\n",
    "test_trans = './data/dialogsum/DialogSum_Data/test_dialogsum_sent_trans_cons_label_2.source'\n",
    "test_c99 = './data/dialogsum/DialogSum_Data/test_dialogsum_sent_c99_label.source'\n",
    "test_hypo = './data/dialogsum/DialogSum_Data/test_best_multi_attn_best.hypo'\n",
    "with open(test_trans) as source, open(test_c99) as source2, open(test_hypo, 'wt', encoding='utf-8') as fout:\n",
    "    s1 = source.readlines()\n",
    "    s2 = source2.readlines()\n",
    "\n",
    "    slines = [s1[0].strip()]\n",
    "    slines2 = [s2[0].strip()]\n",
    "\n",
    "    for i in tqdm(range(1, len(s1))):\n",
    "        if count % bsz == 0:\n",
    "            with torch.no_grad():\n",
    "                hypotheses_batch = bart.sample(slines, sentences2 = slines2, balance = True, beam=4, lenpen=2.0, max_len_b=100, min_len=5, no_repeat_ngram_size=3)\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            for hypothesis in hypotheses_batch:\n",
    "                fout.write(hypothesis + '\\n')\n",
    "                fout.flush()\n",
    "            slines = []\n",
    "            slines2 = []\n",
    "\n",
    "        slines.append(s1[i].strip())\n",
    "        slines2.append(s2[i].strip())\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    if slines != []:\n",
    "\n",
    "        hypotheses_batch = bart.sample(slines, sentences2 = slines2, balance = True, beam=4, lenpen=2.0, max_len_b=100, min_len=5, no_repeat_ngram_size=3)\n",
    "       \n",
    "\n",
    "        for hypothesis in hypotheses_batch:\n",
    "            fout.write(hypothesis + '\\n')\n",
    "            fout.flush()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST\n",
      "rouge-1\n",
      "r: 0.42381762924534044\n",
      "p: 0.3106988218727275\n",
      "f: 0.34378587073025224\n",
      "rouge-2\n",
      "r: 0.16600478963012985\n",
      "p: 0.12211266858958905\n",
      "f: 0.13351775470396782\n",
      "rouge-l\n",
      "r: 0.3963902365567834\n",
      "p: 0.2902285889817407\n",
      "f: 0.3213212855506028\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge, FilesRouge\n",
    "hyp_path = './data/dialogsum/DialogSum_Data/test_best_multi_attn_best.hypo'\n",
    "ref_path = './data/dialogsum/DialogSum_Data/test_dialogsum_sent_trans_cons_label_2.target'\n",
    "hypothesis = []\n",
    "with open(hyp_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        hypothesis.append(l[:-1])\n",
    "\n",
    "reference = []\n",
    "with open(ref_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        reference.append(l[:-1])\n",
    "\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(hypothesis, reference, avg = True)\n",
    "#print('Test', rouge.get_scores(hypothesis, reference, avg = True))\n",
    "            \n",
    "print('TEST')\n",
    "for key, metric in scores.items():\n",
    "    print(key)\n",
    "    for k, v in metric.items():\n",
    "        print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED:\n",
      "Person1# sends an intra-office memorandum to all employees. The use of Instant Message programs by employees during working hours is strictly prohibited. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. The policy applies to internal and external communications.\n",
      "LABEL:\n",
      "Ms. Dawson helps #Person1# to write a memo to inform every employee that they have to change the communication method and should not use Instant Messaging anymore.\n",
      "\n",
      "\n",
      "PRED:\n",
      "Person2# got stuck in a traffic jam near the Carrefour intersection. She will consider taking public transport system to work instead of driving to work.\n",
      "LABEL:\n",
      "#Person2# arrives late because of traffic jam. #Person1# persuades #Person2# to use public transportations to keep healthy and to protect the environment.\n",
      "\n",
      "\n",
      "PRED:\n",
      "Masha and Hero are getting divorced. They filed for a divorce. The divorce will be final in the New Year.\n",
      "LABEL:\n",
      "#Person1# tells Kate that Masha and Hero get divorced. Kate is surprised because she thought they are perfect couple.\n",
      "\n",
      "\n",
      "PRED:\n",
      "It's Brian's birthday. #Person1# will have a dance with him. They should have a drink together to celebrate his birthday.\n",
      "LABEL:\n",
      "#Person1# and Brian are at the birthday party of Brian. Brian thinks #Person1# looks great and is popular.\n",
      "\n",
      "\n",
      "PRED:\n",
      "#Person1# and #Person2# are in the Olympic stadium, the center of the park. The whole stadium is to be finished this June. There are 5000 seats in the stand. No climbing is allowed in the stadium.\n",
      "LABEL:\n",
      "#Person1# is surprised at the Olympic Stadium'volume, capacity and interior setting to #Person1#.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('PRED:')\n",
    "    print(hypothesis[i])\n",
    "    print('LABEL:')\n",
    "    print(reference[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BARTHubInterface(\n",
       "  (model): BARTModel(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "    (section_positions): LearnedPositionalEmbedding(1025, 1024, padding_idx=0)\n",
       "    (section_layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (section): LSTM(1024, 1024)\n",
       "    (w_proj_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (w_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (w_context_vector): Linear(in_features=1024, out_features=1, bias=False)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart = BARTModel.from_pretrained(\n",
    "    'train_sh/checkpoints_stage',\n",
    "    checkpoint_file='checkpoint_best.pt',\n",
    "    data_name_or_path='../dialogsum-bin'\n",
    ")\n",
    "\n",
    "bart.eval()\n",
    "bart.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/499 [00:00<?, ?it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_mask,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:567: UserWarning: An output with one or more elements was resized since it had shape [8, 4], which does not match the required output shape [5, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(new_blacklist, active_hypos)\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:577: UserWarning: An output with one or more elements was resized since it had shape [8, 4], which does not match the required output shape [5, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/search.py:79: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(self.scores_buf, self.indices_buf),\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      " 24%|██▍       | 120/499 [01:12<04:17,  1.47it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=eos_scores,\n",
      " 79%|███████▊  | 392/499 [03:56<01:06,  1.61it/s]/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_mask,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:567: UserWarning: An output with one or more elements was resized since it had shape [5, 4], which does not match the required output shape [2, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(new_blacklist, active_hypos)\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/sequence_generator.py:577: UserWarning: An output with one or more elements was resized since it had shape [5, 4], which does not match the required output shape [2, 4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=active_bbsz_idx,\n",
      "/home/tnguyen/Multi-View-Seq2Seq/fairseq_multi_view/fairseq/search.py:79: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  out=(self.scores_buf, self.indices_buf),\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 499/499 [05:07<00:00,  1.62it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm as tqdm\n",
    "import torch\n",
    "\n",
    "count = 1\n",
    "bsz = 8\n",
    "test_trans = './data/dialogsum/DialogSum_Data/test_dialogsum_sent_trans_cons_label_2.source'\n",
    "test_c99 = './data/dialogsum/DialogSum_Data/test_dialogsum_sent_c99_label.source'\n",
    "test_hypo = './data/dialogsum/DialogSum_Data/test_best_multi_attn_best.hypo'\n",
    "\n",
    "with open(test_trans) as source, open(test_c99) as source2, open(test_hypo, 'wt', encoding='utf-8') as fout:\n",
    "    s1 = source.readlines()\n",
    "    s2 = source2.readlines()\n",
    "\n",
    "    slines = [s1[0].strip()]\n",
    "    slines2 = [s2[0].strip()]\n",
    "\n",
    "    for i in tqdm(range(1, len(s1))):\n",
    "        if count % bsz == 0:\n",
    "            with torch.no_grad():\n",
    "                hypotheses_batch = bart.sample(slines, sentences2 = slines2, balance = True, beam=4, lenpen=2.0, max_len_b=100, min_len=5, no_repeat_ngram_size=3)\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            for hypothesis in hypotheses_batch:\n",
    "                fout.write(hypothesis + '\\n')\n",
    "                fout.flush()\n",
    "            slines = []\n",
    "            slines2 = []\n",
    "\n",
    "        slines.append(s1[i].strip())\n",
    "        slines2.append(s2[i].strip())\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    if slines != []:\n",
    "\n",
    "        hypotheses_batch = bart.sample(slines, sentences2 = slines2, balance = True, beam=4, lenpen=2.0, max_len_b=100, min_len=5, no_repeat_ngram_size=3)\n",
    "       \n",
    "\n",
    "        for hypothesis in hypotheses_batch:\n",
    "            fout.write(hypothesis + '\\n')\n",
    "            fout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST\n",
      "rouge-1\n",
      "r: 0.5678239788779302\n",
      "p: 0.3457162632182704\n",
      "f: 0.4214851315520334\n",
      "rouge-2\n",
      "r: 0.24301067687032568\n",
      "p: 0.13907783503136428\n",
      "f: 0.1724773875682337\n",
      "rouge-l\n",
      "r: 0.5112094712565164\n",
      "p: 0.31107723812728544\n",
      "f: 0.3794061540863322\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge, FilesRouge\n",
    "\n",
    "hyp_path = './data/dialogsum/DialogSum_Data/test_best_multi_attn_best.hypo'\n",
    "ref_path = './data/dialogsum/DialogSum_Data/test_dialogsum_sent_trans_cons_label_2.target'\n",
    "hypothesis = []\n",
    "with open(hyp_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        hypothesis.append(l[:-1])\n",
    "\n",
    "reference = []\n",
    "with open(ref_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        reference.append(l[:-1])\n",
    "\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(hypothesis, reference, avg = True)\n",
    "#print('Test', rouge.get_scores(hypothesis, reference, avg = True))\n",
    "            \n",
    "print('TEST')\n",
    "for key, metric in scores.items():\n",
    "    print(key)\n",
    "    for k, v in metric.items():\n",
    "        print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED:\n",
      "#Person1# asks Ms. Dawson to take a dictation for him and asks her to send an intra-office memorandum to all employees by this afternoon. He tells her that Instant Message programs by employees during working hours are strictly prohibited and applies to internal and external communications. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation, and at second offense, the employee will face termination.\n",
      "LABEL:\n",
      "Ms. Dawson helps #Person1# to write a memo to inform every employee that they have to change the communication method and should not use Instant Messaging anymore.\n",
      "\n",
      "\n",
      "PRED:\n",
      "#Person2# got stuck in traffic again. #Person1# suggests taking public transport system to work to get home and suggests biking to work when it's nicer outside, but #Person2 # is going to miss having the freedom with a car. Then they talk about the environment.\n",
      "LABEL:\n",
      "#Person2# arrives late because of traffic jam. #Person1# persuades #Person2# to use public transportations to keep healthy and to protect the environment.\n",
      "\n",
      "\n",
      "PRED:\n",
      "#Person1# tells Kate that Masha and Hero are getting divorced. Kate can't believe it because she always thought they are well matched and the perfect couple. They talk about the details of the divorce.\n",
      "LABEL:\n",
      "#Person1# tells Kate that Masha and Hero get divorced. Kate is surprised because she thought they are perfect couple.\n",
      "\n",
      "\n",
      "PRED:\n",
      "#Person1# comes to Brian's birthday party and dances with him. Brian compliments #Person2#'s dress and necklace. They have a drink together to celebrate his birthday and talk about the party.\n",
      "LABEL:\n",
      "#Person1# and Brian are at the birthday party of Brian. Brian thinks #Person1# looks great and is popular.\n",
      "\n",
      "\n",
      "PRED:\n",
      "#Person1# and #Person2# are visiting the Olympic park. #Person3# introduces the Olympic stadium, including the seats, the tracks, the jumping pit, and the sign with English translations.\n",
      "LABEL:\n",
      "#Person1# is surprised at the Olympic Stadium'volume, capacity and interior setting to #Person1#.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('PRED:')\n",
    "    print(hypothesis[i])\n",
    "    print('LABEL:')\n",
    "    print(reference[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
