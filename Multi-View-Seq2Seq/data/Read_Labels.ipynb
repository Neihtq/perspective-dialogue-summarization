{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_conversation(data, labels, sep = ' | ', label_type = '_sent_c99_label'):\n",
    "    conversations = []\n",
    "    summaries = []\n",
    "    for i in range(0, len(data)):\n",
    "        if len(data[i]['dialogue'].split('\\r\\n')) > 1:\n",
    "            sentences = data[i]['dialogue'].replace(\" |\", \" \").split('\\r\\n')\n",
    "            \n",
    "        else:\n",
    "            sentences = data[i]['dialogue'].replace(\" |\", \" \").split('\\n')\n",
    "            \n",
    "        if len(sentences) == 1:\n",
    "            continue\n",
    "         \n",
    "        if 'summary' in data[i]:\n",
    "            summaries.append(data[i]['summary'].strip('\\n').replace('\\r\\nt', ' '))\n",
    "        else:\n",
    "            summaries.append(data[i]['summary1'].strip('\\n').replace('\\r\\nt', ' '))\n",
    "\n",
    "        if len(labels) > 1:\n",
    "            \n",
    "            if label_type == '_sent_c99_label':\n",
    "                temp = ''\n",
    "                temp += sentences[0]\n",
    "                for j in range(1, len(sentences)):\n",
    "                    if labels[i][j] != labels[i][j-1]:\n",
    "\n",
    "                        temp = temp + sep + sentences[j]\n",
    "                    else:\n",
    "                        temp = temp + ' ' + sentences[j]\n",
    "                temp += ' | '\n",
    "                conversations.append(temp)\n",
    "            else:\n",
    "                temp = ' | '\n",
    "                temp += sentences[0]\n",
    "                for j in range(1, len(sentences)):\n",
    "                    if labels[i][j] != labels[i][j-1]:\n",
    "\n",
    "                        temp = temp + sep + sentences[j]\n",
    "                    else:\n",
    "                        temp = temp + ' ' + sentences[j]\n",
    "                conversations.append(temp)\n",
    "                \n",
    "        elif labels[0] == 1:\n",
    "            conversations.append(' | ' + ' | '.join(sentences))\n",
    "        elif labels[0] == 0:\n",
    "            conversations.append(' | ' + ' '.join(sentences))\n",
    "        \n",
    "    return conversations, summaries\n",
    "    \n",
    "def read_json(file):\n",
    "    json_arr = []\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        jsn = json.loads(line)\n",
    "        json_arr.append(jsn)\n",
    "    return json_arr\n",
    "    \n",
    "    \n",
    "def transform_format(prefix, label_type = '_sent_c99_label'):\n",
    "    with open(prefix + '.jsonl', encoding = 'utf8') as json_file:\n",
    "        data = read_json(json_file)\n",
    "        #data = json.load(json_file)\n",
    "    if label_type != '_all' and label_type != '_none':\n",
    "        with open(prefix + label_type +'.pkl', 'rb') as f:\n",
    "            labels = pickle.load(f)\n",
    "    elif label_type == '_all':\n",
    "        labels = [1]\n",
    "    elif label_type == '_none':\n",
    "        labels = [0]\n",
    "        \n",
    "    cons, sums = concat_conversation(data, labels, label_type)    \n",
    "\n",
    "    with open(prefix + label_type +'.source', 'wt', encoding='utf-8') as source_file, open(prefix + label_type + '.target', 'wt', encoding='utf-8') as target_file:\n",
    "        for i in range(0, len(cons)):\n",
    "            article = cons[i]\n",
    "            abstract = sums[i]\n",
    "            if '\\n' in abstract:\n",
    "                abstract = ' '.join(abstract.split('\\n'))\n",
    "            source_file.write(article + '\\n')\n",
    "            target_file.write(abstract + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prefix = './dialogsum/DialogSum_Data/train_dialogsum'\n",
    "dev_prefix = './dialogsum/DialogSum_Data/val_dialogsum'\n",
    "test_prefix = './dialogsum/DialogSum_Data/test_dialogsum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for u in [train_prefix, dev_prefix, test_prefix]:\n",
    "    transform_format(u, '_all')\n",
    "    transform_format(u, '_none')\n",
    "    transform_format(u, '_sent_trans_cons_label_2') \n",
    "    transform_format(u, '_sent_c99_label') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_format_alt(prefix, label_type = '_sent_c99_label'):\n",
    "    with open(prefix + '.jsonl', encoding = 'utf8') as json_file:\n",
    "        data = read_json(json_file)\n",
    "        #data = json.load(json_file)\n",
    "    if label_type != '_all' and label_type != '_none':\n",
    "        with open(prefix + label_type +'.pkl', 'rb') as f:\n",
    "            labels = pickle.load(f)\n",
    "    elif label_type == '_all':\n",
    "        labels = [1]\n",
    "    elif label_type == '_none':\n",
    "        labels = [0]\n",
    "        \n",
    "    cons, sums = concat_conversation(data, labels, label_type)    \n",
    "    \n",
    "    return cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_format_alt(dev_prefix, '_all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
