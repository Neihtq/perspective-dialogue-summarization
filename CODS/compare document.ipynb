{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed111a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/tnguyen/dialogue-text-summarization-dokument/CODS, universal_newlines=False, shell=None, istream=None)\n",
      "DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/tnguyen/dialogue-text-summarization-dokument/CODS, universal_newlines=False, shell=None, istream=None)\n",
      "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
      "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
      "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
      "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
      "[nltk_data] Downloading package punkt to /home/tnguyen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import torch\n",
    "from src.models.model import SummarizerModel, ModelWrapper\n",
    "from tqdm import tqdm, trange\n",
    "from transformers import get_linear_schedule_with_warmup \n",
    "from src.utils.data_preprocess import load_examples, convert_examples_to_features\n",
    "from src.models.training import logger, get_train_dataloader, check_accumulation_step, get_train_batch_data, get_loss_functurn, cosine_similarity\n",
    "from src.utils.constants import MINI_DIALOGSUM_PATH\n",
    "from src.models.evaluate import evaluate, predict, get_eval_dataloader, get_eval_batch_data, evaluate_rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdbfdcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /Salesforce/cods-bart-large-xsum-samsum/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 140436574632648 on /home/tnguyen/.cache/huggingface/transformers/3779da8f409c6c0362f125d484851b0109552de13148a2d808b3b137fb6df52b.3dc588a59cb4425586e048c07f434f55bc79f8c047a0c4a6fb68fe6754ddc04c.lock\n",
      "INFO:filelock:Lock 140436574632648 acquired on /home/tnguyen/.cache/huggingface/transformers/3779da8f409c6c0362f125d484851b0109552de13148a2d808b3b137fb6df52b.3dc588a59cb4425586e048c07f434f55bc79f8c047a0c4a6fb68fe6754ddc04c.lock\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /Salesforce/cods-bart-large-xsum-samsum/resolve/main/config.json HTTP/1.1\" 200 1510\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7dd98d4c7a149e1aba73d7c8ca349c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.51k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 140436574632648 on /home/tnguyen/.cache/huggingface/transformers/3779da8f409c6c0362f125d484851b0109552de13148a2d808b3b137fb6df52b.3dc588a59cb4425586e048c07f434f55bc79f8c047a0c4a6fb68fe6754ddc04c.lock\n",
      "INFO:filelock:Lock 140436574632648 released on /home/tnguyen/.cache/huggingface/transformers/3779da8f409c6c0362f125d484851b0109552de13148a2d808b3b137fb6df52b.3dc588a59cb4425586e048c07f434f55bc79f8c047a0c4a6fb68fe6754ddc04c.lock\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /Salesforce/cods-bart-large-xsum-samsum/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n",
      "DEBUG:filelock:Attempting to acquire lock 140431575584664 on /home/tnguyen/.cache/huggingface/transformers/02d928e6493a7c380c9647abb42c0fcd3a46fd98c25a7b581e5acb75ccf00bb3.d0ec7d0ec6323d1b4588dbf9effa02274e995c428a3646fd11faffc3cab946d2.lock\n",
      "INFO:filelock:Lock 140431575584664 acquired on /home/tnguyen/.cache/huggingface/transformers/02d928e6493a7c380c9647abb42c0fcd3a46fd98c25a7b581e5acb75ccf00bb3.d0ec7d0ec6323d1b4588dbf9effa02274e995c428a3646fd11faffc3cab946d2.lock\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): cdn-lfs.huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://cdn-lfs.huggingface.co:443 \"GET /Salesforce/cods-bart-large-xsum-samsum/6294bddb7ab533b4779bd6711a465751c7c7b27cb382abdf4ebe1c0736572e8d?response-content-disposition=attachment%3B%20filename%3D%22pytorch_model.bin%22 HTTP/1.1\" 200 1625478132\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229140e3fe9449a3b46352438a9c24b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 140431575584664 on /home/tnguyen/.cache/huggingface/transformers/02d928e6493a7c380c9647abb42c0fcd3a46fd98c25a7b581e5acb75ccf00bb3.d0ec7d0ec6323d1b4588dbf9effa02274e995c428a3646fd11faffc3cab946d2.lock\n",
      "INFO:filelock:Lock 140431575584664 released on /home/tnguyen/.cache/huggingface/transformers/02d928e6493a7c380c9647abb42c0fcd3a46fd98c25a7b581e5acb75ccf00bb3.d0ec7d0ec6323d1b4588dbf9effa02274e995c428a3646fd11faffc3cab946d2.lock\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /Salesforce/cods-bart-large-xsum-samsum/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /Salesforce/cods-bart-large-xsum-samsum/resolve/main/vocab.json HTTP/1.1\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 140431540337016 on /home/tnguyen/.cache/huggingface/transformers/d2bf8f0d9fe655ad9978633646e6fddb69d5a55e79b5da1055d6e2d718f909c0.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05.lock\n",
      "INFO:filelock:Lock 140431540337016 acquired on /home/tnguyen/.cache/huggingface/transformers/d2bf8f0d9fe655ad9978633646e6fddb69d5a55e79b5da1055d6e2d718f909c0.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05.lock\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /Salesforce/cods-bart-large-xsum-samsum/resolve/main/vocab.json HTTP/1.1\" 200 898822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b464a3807773487ebddc9c6009cacaa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 140431540337016 on /home/tnguyen/.cache/huggingface/transformers/d2bf8f0d9fe655ad9978633646e6fddb69d5a55e79b5da1055d6e2d718f909c0.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05.lock\n",
      "INFO:filelock:Lock 140431540337016 released on /home/tnguyen/.cache/huggingface/transformers/d2bf8f0d9fe655ad9978633646e6fddb69d5a55e79b5da1055d6e2d718f909c0.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05.lock\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /Salesforce/cods-bart-large-xsum-samsum/resolve/main/merges.txt HTTP/1.1\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 140431540404120 on /home/tnguyen/.cache/huggingface/transformers/18570ffa8ed96de3b9c6d3dc3b4ab37d59e42750a14a0bb0624151b09c3f2ddf.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b.lock\n",
      "INFO:filelock:Lock 140431540404120 acquired on /home/tnguyen/.cache/huggingface/transformers/18570ffa8ed96de3b9c6d3dc3b4ab37d59e42750a14a0bb0624151b09c3f2ddf.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b.lock\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /Salesforce/cods-bart-large-xsum-samsum/resolve/main/merges.txt HTTP/1.1\" 200 456318\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bc0d79212343e78055ce3bf26b70da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 140431540404120 on /home/tnguyen/.cache/huggingface/transformers/18570ffa8ed96de3b9c6d3dc3b4ab37d59e42750a14a0bb0624151b09c3f2ddf.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b.lock\n",
      "INFO:filelock:Lock 140431540404120 released on /home/tnguyen/.cache/huggingface/transformers/18570ffa8ed96de3b9c6d3dc3b4ab37d59e42750a14a0bb0624151b09c3f2ddf.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b.lock\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /Salesforce/cods-bart-large-xsum-samsum/resolve/main/tokenizer.json HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /Salesforce/cods-bart-large-xsum-samsum/resolve/main/added_tokens.json HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /Salesforce/cods-bart-large-xsum-samsum/resolve/main/special_tokens_map.json HTTP/1.1\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 140431540336456 on /home/tnguyen/.cache/huggingface/transformers/6c67b427feb7ff0cbdb0d19a0ac0021cc926e8cc94c735437d17223b988eb994.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock\n",
      "INFO:filelock:Lock 140431540336456 acquired on /home/tnguyen/.cache/huggingface/transformers/6c67b427feb7ff0cbdb0d19a0ac0021cc926e8cc94c735437d17223b988eb994.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /Salesforce/cods-bart-large-xsum-samsum/resolve/main/special_tokens_map.json HTTP/1.1\" 200 772\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b88b3f5cf564d8b96e3815c23cacd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 140431540336456 on /home/tnguyen/.cache/huggingface/transformers/6c67b427feb7ff0cbdb0d19a0ac0021cc926e8cc94c735437d17223b988eb994.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock\n",
      "INFO:filelock:Lock 140431540336456 released on /home/tnguyen/.cache/huggingface/transformers/6c67b427feb7ff0cbdb0d19a0ac0021cc926e8cc94c735437d17223b988eb994.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /Salesforce/cods-bart-large-xsum-samsum/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 140431540373320 on /home/tnguyen/.cache/huggingface/transformers/39a5a5c6e885e7af471326d2cb9e5062a3cf1a3b82c1d73460d44c31995a446d.10366e0e2faaf644b007c4bcc1a01abaa7fedc6a66e79a4a82a7359de93c46fb.lock\n",
      "INFO:filelock:Lock 140431540373320 acquired on /home/tnguyen/.cache/huggingface/transformers/39a5a5c6e885e7af471326d2cb9e5062a3cf1a3b82c1d73460d44c31995a446d.10366e0e2faaf644b007c4bcc1a01abaa7fedc6a66e79a4a82a7359de93c46fb.lock\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /Salesforce/cods-bart-large-xsum-samsum/resolve/main/tokenizer_config.json HTTP/1.1\" 200 1115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c9659934b741ff9045fa06850778f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 140431540373320 on /home/tnguyen/.cache/huggingface/transformers/39a5a5c6e885e7af471326d2cb9e5062a3cf1a3b82c1d73460d44c31995a446d.10366e0e2faaf644b007c4bcc1a01abaa7fedc6a66e79a4a82a7359de93c46fb.lock\n",
      "INFO:filelock:Lock 140431540373320 released on /home/tnguyen/.cache/huggingface/transformers/39a5a5c6e885e7af471326d2cb9e5062a3cf1a3b82c1d73460d44c31995a446d.10366e0e2faaf644b007c4bcc1a01abaa7fedc6a66e79a4a82a7359de93c46fb.lock\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /Salesforce/cods-bart-large-xsum-samsum/resolve/main/modelcard.json HTTP/1.1\" 404 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "conv =  [\n",
    "\"Jason: whats up? Any plan for this weekend?\", \n",
    "\"John: I'm thinking of go watch a movie, but not decide which yet.\", \n",
    "\"Debbie: What? I thought that now all the theaters are closed due to the pandamic?\", \n",
    "\"John: Oh! That's right. Then no idea what to do.\"\n",
    "]\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"Salesforce/cods-bart-large-xsum-samsum\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30c21ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 400, but you input_length is only 351. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"0 abstain need you to take a dictation for me 1 none 2 abstain should go out as an intra-office memorandum to all employees by this afternoon 3 none 4 abstain the use of instant message programs by employees during working hours is strictly prohibited 5 none 6 abstain apply to all communications , not only in this office between employees , but also any outside communications 7 abstain use instant messaging to communicate with their clients 8 abstain don't want any - one using instant messaging 9 abstain applies to internal and external communications 10 none 11 none 12 abstain get this memo typed up and distributed before 4 pm TLDR The new policy on instant messaging has come into effect.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_cods1 = summarizer(ctrl, min_length=10, max_length=400, num_beams=4)[0][\"summary_text\"]\n",
    "summary_cods1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06731323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c88bcf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "train_path = os.path.join(MINI_DIALOGSUM_PATH, 'train.json')\n",
    "#train_path = 'data/processed/new_dialogsum_shuffled/train.json'\n",
    "val_path = os.path.join(MINI_DIALOGSUM_PATH, 'eval.json')\n",
    "test_path = os.path.join(MINI_DIALOGSUM_PATH, 'test.json')\n",
    "#test_path = os.path.join('data', 'processed', 'new_dialogsum_clean_data', 'test.json')\n",
    "batch_size = 1\n",
    "\n",
    "class Args:\n",
    "    do_segment = True\n",
    "    #do_train = True\n",
    "    output_dir='models/penalty_salesforce_5'\n",
    "    use_pred_segment = False\n",
    "    #train_file_path = train_path\n",
    "    #dev_file_path = val_path\n",
    "    test_file_path = test_path\n",
    "    oracle_functurn_context = False\n",
    "    source_max_len = 512\n",
    "    gen_keyphrase_summary = True\n",
    "    target_max_len = 50\n",
    "    add_module_loss = False\n",
    "    add_functurn_loss = False\n",
    "    #train_batch_size = batch_size\n",
    "    #gradient_accumulation_steps = 1\n",
    "    #num_train_epochs = 30\n",
    "    #warmup_proportion = 0.1\n",
    "    #patience = 8\n",
    "    #model_name = 'mini_dialogsum_1'\n",
    "    #max_grad_norm = 1.0\n",
    "    #validation_timing = 1\n",
    "    eval_batch_size = batch_size\n",
    "    no_repeat_ngram_size = 0\n",
    "    beam = 4\n",
    "    test_target_max_len = 50\n",
    "    #wandb = False\n",
    "    #learning_rate = 5e-5\n",
    "    #adam_epsilon = 1e-8\n",
    "    #seed = 42\n",
    "    #penalty_term = 1\n",
    "    #k_fold_cross_validation = False\n",
    "    distributed = False\n",
    "    add_name = ''\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3d092c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /Salesforce/bart-large-xsum-samsum/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /Salesforce/bart-large-xsum-samsum/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /Salesforce/bart-large-xsum-samsum/resolve/main/vocab.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /Salesforce/bart-large-xsum-samsum/resolve/main/merges.txt HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /Salesforce/bart-large-xsum-samsum/resolve/main/added_tokens.json HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /Salesforce/bart-large-xsum-samsum/resolve/main/special_tokens_map.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /Salesforce/bart-large-xsum-samsum/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /Salesforce/bart-large-xsum-samsum/resolve/main/tokenizer.json HTTP/1.1\" 404 0\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Salesforce/bart-large-xsum-samsum\"\n",
    "#model_name = 'facebook/bart-large-xsum'\n",
    "params = {\n",
    "    'model_name': model_name,\n",
    "    'load_path': None,\n",
    "    'add_module_loss': None,\n",
    "    'add_functurn_loss': None\n",
    "}\n",
    "\n",
    "model = SummarizerModel(params)\n",
    "#model = ModelWrapper(args, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ced668e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Examples: 100%|██████████| 2/2 [00:00<00:00, 157.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] max_target_len 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = args.test_file_path\n",
    "dev_examples = load_examples(args, file_path)\n",
    "#dev_features = convert_examples_to_features(args, model.module.config, model.module.tokenizer, dev_examples)\n",
    "dev_features = convert_examples_to_features(args, model.config, model.tokenizer, dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "818bf9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl = dev_examples[0].context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f5e03ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sentence_transformers import SentenceTransformer, util\n",
    "def get_similarity(dev_examples, pred):\n",
    "    pred_sum_arr_p1 = []\n",
    "    pred_sum_arr_p2 = []\n",
    "    for d in dev_examples:\n",
    "        pred_sum_arr_p1.append(pred[d.ID]['Person1'])\n",
    "        pred_sum_arr_p2.append(pred[d.ID]['Person2'])\n",
    "        \n",
    "    return pred_sum_arr_p1, pred_sum_arr_p2\n",
    "        \n",
    "def similar(p1_sents, p2_sents, model):\n",
    "    embeddings_p1 = model.encode(p1_sents, convert_to_tensor=True)\n",
    "    embeddings_p2 = model.encode(p2_sents, convert_to_tensor=True)\n",
    "    \n",
    "    cosine_scores = util.cos_sim(embeddings_p1, embeddings_p2)\n",
    "    \n",
    "    return cosine_scores.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03346a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_dir = os.path.join('models', 'penalty_salesforce_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e6b65f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nkees_playground/dialogue-text-summarization-dokument/.venv/lib/python3.9/site-packages/huggingface_hub/snapshot_download.py:6: FutureWarning: snapshot_download.py has been made private and will no longer be available from version 0.11. Please use `from huggingface_hub import snapshot_download` to import the only public function in this module. Other members of the file may be changed without a deprecation notice.\n",
      "  warnings.warn(\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1\" 200 1609\n",
      "/mnt/nkees_playground/dialogue-text-summarization-dokument/.venv/lib/python3.9/site-packages/huggingface_hub/file_download.py:560: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
      "  warnings.warn(\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/3746fd5f4cfd46ae64fc781df53e7cbb7849eb62/.gitattributes HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/3746fd5f4cfd46ae64fc781df53e7cbb7849eb62/1_Pooling/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/3746fd5f4cfd46ae64fc781df53e7cbb7849eb62/README.md HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/3746fd5f4cfd46ae64fc781df53e7cbb7849eb62/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/3746fd5f4cfd46ae64fc781df53e7cbb7849eb62/config_sentence_transformers.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/3746fd5f4cfd46ae64fc781df53e7cbb7849eb62/data_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/3746fd5f4cfd46ae64fc781df53e7cbb7849eb62/modules.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/3746fd5f4cfd46ae64fc781df53e7cbb7849eb62/pytorch_model.bin HTTP/1.1\" 302 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/3746fd5f4cfd46ae64fc781df53e7cbb7849eb62/sentence_bert_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/3746fd5f4cfd46ae64fc781df53e7cbb7849eb62/special_tokens_map.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/3746fd5f4cfd46ae64fc781df53e7cbb7849eb62/tokenizer.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/3746fd5f4cfd46ae64fc781df53e7cbb7849eb62/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/3746fd5f4cfd46ae64fc781df53e7cbb7849eb62/train_script.py HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/3746fd5f4cfd46ae64fc781df53e7cbb7849eb62/vocab.txt HTTP/1.1\" 200 0\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cuda\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A/mnt/nkees_playground/dialogue-text-summarization-dokument/.venv/lib/python3.9/site-packages/transformers/generation_stopping_criteria.py:93: UserWarning: You set different `max_length` for stopping criteria and `max_length` parameter\n",
      "  warnings.warn(\n",
      "/mnt/nkees_playground/dialogue-text-summarization-dokument/.venv/lib/python3.9/site-packages/transformers/generation_utils.py:1777: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  next_indices = next_tokens // vocab_size\n",
      "\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:18, 15.60s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:02, 15.72s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.69s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.07s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:17<00:15, 15.35s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:31<00:00, 15.30s/it]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 127.03it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 136.37it/s]\u001b[A\n",
      "  2%|▊                                         | 1/53 [01:33<1:20:44, 93.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:14, 14.90s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:02, 15.58s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:46, 15.65s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.13s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:17<00:15, 15.47s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:31<00:00, 15.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.34s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  50%|████████████████▌                | 12/24 [00:00<00:00, 119.98it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 112.68it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 127.89it/s]\u001b[A\n",
      "  4%|█▌                                        | 2/53 [03:06<1:19:24, 93.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:14, 14.99s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:02, 15.56s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:47, 15.69s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.17s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:17<00:15, 15.49s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.36s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 118.28it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 131.78it/s]\u001b[A\n",
      "  6%|██▍                                       | 3/53 [04:40<1:17:54, 93.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:15, 15.00s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:02, 15.61s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:47, 15.68s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.16s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:17<00:15, 15.50s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.36s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  38%|█████████████▏                     | 9/24 [00:00<00:00, 89.94it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 106.29it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 132.32it/s]\u001b[A\n",
      "  8%|███▏                                      | 4/53 [06:23<1:19:25, 97.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:16, 15.20s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:03, 15.81s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.90s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:02<00:30, 15.44s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.74s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.59s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 128.21it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 124.75it/s]\u001b[A\n",
      "  9%|███▉                                      | 5/53 [07:58<1:17:08, 96.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:12, 14.59s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:00, 15.25s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:45<00:46, 15.34s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [00:59<00:29, 14.81s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:15<00:15, 15.16s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:30<00:00, 14.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:30<00:00, 15.03s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 118.24it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 139.40it/s]\u001b[A\n",
      " 11%|████▊                                     | 6/53 [09:39<1:16:40, 97.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:15, 15.15s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:02, 15.71s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.86s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.35s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.65s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.51s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 118.31it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 124.11it/s]\u001b[A\n",
      " 13%|█████▌                                    | 7/53 [11:13<1:14:12, 96.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:16, 15.29s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:03, 15.90s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.97s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:02<00:31, 15.51s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.80s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.65s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  46%|███████████████▏                 | 11/24 [00:00<00:00, 108.73it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 115.06it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 129.20it/s]\u001b[A\n",
      " 15%|██████▎                                   | 8/53 [12:48<1:12:14, 96.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:14, 15.00s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:02, 15.64s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:47, 15.71s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.20s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:17<00:15, 15.55s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.42s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  38%|█████████████▏                     | 9/24 [00:00<00:00, 89.04it/s]\u001b[A\n",
      "Batches: 100%|██████████████████████████████████| 24/24 [00:00<00:00, 99.47it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 128.72it/s]\u001b[A\n",
      " 17%|███████▏                                  | 9/53 [14:32<1:12:16, 98.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:14, 14.93s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:02, 15.51s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:47, 15.68s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.15s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:17<00:15, 15.48s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.35s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  46%|███████████████▏                 | 11/24 [00:00<00:00, 109.41it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 115.14it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 133.89it/s]\u001b[A\n",
      " 19%|███████▋                                 | 10/53 [16:05<1:09:31, 97.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:13, 14.64s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:01, 15.29s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:45<00:46, 15.39s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [00:59<00:29, 14.86s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:15<00:15, 15.19s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:30<00:00, 14.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:30<00:00, 15.07s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 121.17it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 138.31it/s]\u001b[A\n",
      " 21%|████████▌                                | 11/53 [17:46<1:08:45, 98.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:13, 14.68s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:01, 15.29s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:45<00:46, 15.43s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:00<00:29, 14.91s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:15<00:15, 15.24s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:30<00:00, 15.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:30<00:00, 15.10s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  42%|██████████████▏                   | 10/24 [00:00<00:00, 98.07it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 112.42it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 124.00it/s]\u001b[A\n",
      " 23%|█████████▎                               | 12/53 [19:28<1:07:47, 99.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:15, 15.08s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:02, 15.72s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.83s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.35s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.65s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.50s/it]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 127.21it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 134.27it/s]\u001b[A\n",
      " 25%|██████████                               | 13/53 [21:02<1:05:09, 97.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:12, 14.48s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:00, 15.11s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:45<00:45, 15.22s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [00:59<00:29, 14.68s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:14<00:15, 15.02s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:29<00:00, 14.90s/it]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 124.56it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 121.33it/s]\u001b[A\n",
      " 26%|██████████▊                              | 14/53 [22:43<1:04:05, 98.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:15, 15.17s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:03, 15.80s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.88s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:02<00:30, 15.42s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.73s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.56s/it]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 129.77it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 135.04it/s]\u001b[A\n",
      " 28%|███████████▌                             | 15/53 [24:18<1:01:43, 97.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:14, 14.89s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:02, 15.55s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:46, 15.65s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.13s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:17<00:15, 15.48s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.35s/it]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  42%|██████████████▏                   | 10/24 [00:00<00:00, 97.97it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 111.54it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 121.93it/s]\u001b[A\n",
      " 30%|████████████▍                            | 16/53 [26:00<1:01:06, 99.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:14, 14.99s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:02, 15.52s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:46, 15.63s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:00<00:30, 15.10s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:17<00:15, 15.45s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.33s/it]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  46%|███████████████▏                 | 11/24 [00:00<00:00, 101.41it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 112.93it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 129.44it/s]\u001b[A\n",
      " 32%|█████████████▊                             | 17/53 [27:34<58:26, 97.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:13, 14.80s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:01, 15.40s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:46, 15.50s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:00<00:29, 14.98s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:16<00:15, 15.28s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:30<00:00, 15.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:30<00:00, 15.16s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  42%|██████████████▏                   | 10/24 [00:00<00:00, 92.29it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 104.92it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 122.94it/s]\u001b[A\n",
      " 34%|██████████████▌                            | 18/53 [29:16<57:38, 98.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:15, 15.01s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:02, 15.65s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:47, 15.72s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.22s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:17<00:15, 15.57s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.42s/it]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  38%|█████████████▏                     | 9/24 [00:00<00:00, 86.78it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 104.69it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 130.47it/s]\u001b[A\n",
      " 36%|███████████████                           | 19/53 [30:59<56:45, 100.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:14, 14.94s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:02, 15.54s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:46, 15.64s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.15s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:17<00:15, 15.46s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:31<00:00, 15.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:31<00:00, 15.32s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 133.25it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 123.83it/s]\u001b[A\n",
      " 38%|███████████████▊                          | 20/53 [32:41<55:19, 100.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:15, 15.20s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:03, 15.83s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.91s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:02<00:30, 15.45s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.76s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.61s/it]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 129.82it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 131.89it/s]\u001b[A\n",
      " 40%|█████████████████                          | 21/53 [34:16<52:45, 98.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:16, 15.21s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:03, 15.85s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.93s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:02<00:30, 15.48s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.79s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.63s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 128.46it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 134.33it/s]\u001b[A\n",
      " 42%|█████████████████▊                         | 22/53 [35:51<50:32, 97.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:16, 15.23s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:03, 15.87s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.96s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:02<00:31, 15.50s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.81s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.65s/it]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 122.97it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 121.83it/s]\u001b[A\n",
      " 43%|██████████████████▋                        | 23/53 [37:27<48:32, 97.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:15, 15.02s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:02, 15.60s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:46, 15.66s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.14s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:17<00:15, 15.48s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.36s/it]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  42%|██████████████▏                   | 10/24 [00:00<00:00, 95.22it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 110.88it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  46%|███████████████▏                 | 11/24 [00:00<00:00, 105.10it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 114.31it/s]\u001b[A\n",
      " 45%|███████████████████▍                       | 24/53 [39:10<47:50, 99.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:14, 14.84s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:01, 15.44s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:46, 15.58s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:00<00:30, 15.06s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:16<00:15, 15.39s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:31<00:00, 15.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:31<00:00, 15.26s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 121.31it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 124.49it/s]\u001b[A\n",
      " 47%|███████████████████▊                      | 25/53 [40:53<46:42, 100.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:16, 15.27s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:03, 15.85s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.93s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:02<00:30, 15.47s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.77s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.61s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 134.46it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 131.34it/s]\u001b[A\n",
      " 49%|█████████████████████                      | 26/53 [42:28<44:22, 98.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:15, 15.17s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:03, 15.79s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.91s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:02<00:30, 15.46s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.77s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.60s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 119.50it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 136.03it/s]\u001b[A\n",
      " 51%|█████████████████████▉                     | 27/53 [44:03<42:16, 97.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:14, 14.89s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:02, 15.53s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:46, 15.64s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:00<00:30, 15.11s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:16<00:15, 15.44s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:31<00:00, 15.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:31<00:00, 15.31s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  42%|██████████████▏                   | 10/24 [00:00<00:00, 97.74it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 108.05it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 136.67it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 28/53 [45:45<41:11, 98.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:15, 15.17s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:03, 15.80s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.89s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:02<00:30, 15.42s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.73s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.58s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 147.59it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 145.63it/s]\u001b[A\n",
      " 55%|███████████████████████▌                   | 29/53 [47:20<39:02, 97.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:16, 15.22s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:03, 15.84s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.92s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:02<00:30, 15.48s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.78s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.62s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 143.21it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 149.55it/s]\u001b[A\n",
      " 57%|████████████████████████▎                  | 30/53 [48:55<37:07, 96.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:14, 14.90s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:02, 15.58s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:46, 15.65s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.12s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:17<00:15, 15.45s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:31<00:00, 15.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:31<00:00, 15.32s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 136.96it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 138.56it/s]\u001b[A\n",
      " 58%|█████████████████████████▏                 | 31/53 [50:38<36:11, 98.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:15, 15.03s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:02, 15.67s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:47, 15.72s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.22s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:17<00:15, 15.56s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.42s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 118.51it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 125.28it/s]\u001b[A\n",
      " 60%|█████████████████████████▉                 | 32/53 [52:20<34:57, 99.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:15, 15.13s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:03, 15.75s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.85s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.36s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.67s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.52s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  46%|███████████████▏                 | 11/24 [00:00<00:00, 102.46it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 106.83it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 133.59it/s]\u001b[A\n",
      " 62%|██████████████████████████▊                | 33/53 [53:55<32:45, 98.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:14, 14.96s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:02, 15.63s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:47, 15.67s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.17s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:17<00:15, 15.49s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.37s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 128.93it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 133.26it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 34/53 [55:38<31:36, 99.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:14, 14.98s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:02, 15.59s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:47, 15.67s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.16s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:17<00:15, 15.50s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.37s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  42%|██████████████▏                   | 10/24 [00:00<00:00, 91.02it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 104.06it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 124.13it/s]\u001b[A\n",
      " 66%|███████████████████████████▋              | 35/53 [57:22<30:15, 100.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:16, 15.23s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:03, 15.83s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.93s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:02<00:30, 15.46s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.77s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.62s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  42%|██████████████▏                   | 10/24 [00:00<00:00, 97.10it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 116.59it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 135.40it/s]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 36/53 [58:57<28:05, 99.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:12, 14.51s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:00, 15.10s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:45<00:45, 15.20s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [00:59<00:29, 14.66s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:14<00:14, 14.99s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:29<00:00, 14.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:29<00:00, 14.87s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  42%|██████████████▏                   | 10/24 [00:00<00:00, 95.80it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 110.97it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 132.73it/s]\u001b[A\n",
      " 70%|████████████████████████████▌            | 37/53 [1:00:37<26:31, 99.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:14, 14.91s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:02, 15.54s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:46, 15.64s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.15s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:17<00:15, 15.47s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:31<00:00, 15.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:31<00:00, 15.33s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  42%|██████████████▏                   | 10/24 [00:00<00:00, 99.77it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 105.72it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 128.36it/s]\u001b[A\n",
      " 72%|████████████████████████████▋           | 38/53 [1:02:21<25:11, 100.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:14, 14.81s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:01, 15.39s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:46, 15.53s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:00<00:30, 15.01s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:16<00:15, 15.33s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:31<00:00, 15.22s/it]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  42%|██████████████▏                   | 10/24 [00:00<00:00, 88.69it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 103.91it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 130.81it/s]\u001b[A\n",
      " 74%|█████████████████████████████▍          | 39/53 [1:04:03<23:37, 101.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:15, 15.16s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:03, 15.78s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.88s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:02<00:30, 15.42s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.74s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.58s/it]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 132.42it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 127.41it/s]\u001b[A\n",
      " 75%|██████████████████████████████▉          | 40/53 [1:05:38<21:31, 99.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:15, 15.18s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:03, 15.79s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.92s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:02<00:30, 15.44s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.74s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.59s/it]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  42%|██████████████▏                   | 10/24 [00:00<00:00, 99.62it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 110.75it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 119.19it/s]\u001b[A\n",
      " 77%|██████████████████████████████▉         | 41/53 [1:07:23<20:12, 101.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:12, 14.53s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:00, 15.15s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:45<00:45, 15.23s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [00:59<00:29, 14.68s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:14<00:14, 15.00s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:29<00:00, 14.89s/it]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  46%|███████████████▏                 | 11/24 [00:00<00:00, 102.38it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 108.40it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 134.10it/s]\u001b[A\n",
      " 79%|███████████████████████████████▋        | 42/53 [1:09:03<18:27, 100.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:16, 15.23s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:03, 15.80s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.86s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:02<00:30, 15.41s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.70s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.55s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  38%|█████████████▏                     | 9/24 [00:00<00:00, 83.80it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 106.24it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 129.48it/s]\u001b[A\n",
      " 81%|█████████████████████████████████▎       | 43/53 [1:10:38<16:29, 98.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:15, 15.13s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:03, 15.76s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.87s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:02<00:30, 15.43s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.72s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.56s/it]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  42%|██████████████▏                   | 10/24 [00:00<00:00, 99.56it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 112.61it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 121.66it/s]\u001b[A\n",
      " 83%|██████████████████████████████████       | 44/53 [1:12:13<14:39, 97.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:15, 15.16s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:03, 15.79s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.87s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:02<00:30, 15.41s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.70s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.55s/it]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  42%|██████████████▏                   | 10/24 [00:00<00:00, 99.16it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 109.22it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 136.36it/s]\u001b[A\n",
      " 85%|██████████████████████████████████▊      | 45/53 [1:13:47<12:54, 96.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:14, 14.98s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:02, 15.57s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:47, 15.72s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.21s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:17<00:15, 15.54s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.40s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  38%|█████████████▏                     | 9/24 [00:00<00:00, 85.71it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 104.82it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 130.21it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▌     | 46/53 [1:15:31<11:31, 98.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:14, 14.98s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:02, 15.62s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:47, 15.69s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.18s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:17<00:15, 15.51s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.38s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 126.53it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 128.17it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▎    | 47/53 [1:17:13<09:59, 99.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:11, 14.39s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:29<01:00, 15.03s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:45<00:45, 15.13s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [00:58<00:29, 14.60s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:14<00:14, 14.94s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:28<00:00, 14.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:28<00:00, 14.82s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  38%|█████████████▏                     | 9/24 [00:00<00:00, 84.04it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 105.67it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 131.99it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▏   | 48/53 [1:18:53<08:19, 99.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:15, 15.19s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:03, 15.82s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.90s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:02<00:30, 15.44s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.74s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.59s/it]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 116.70it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 131.87it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▉   | 49/53 [1:20:28<06:34, 98.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:13, 14.72s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:01, 15.32s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:46, 15.42s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:00<00:29, 14.90s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:15<00:15, 15.24s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:30<00:00, 15.11s/it]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 120.31it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 101.68it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▋  | 50/53 [1:22:10<04:57, 99.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:15<01:15, 15.13s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:31<01:03, 15.75s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:47<00:47, 15.86s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.40s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:18<00:15, 15.72s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:33<00:00, 15.55s/it]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 129.55it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 128.61it/s]\u001b[A\n",
      " 96%|██████████████████████████████████████▍ | 51/53 [1:23:53<03:21, 100.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:14, 14.92s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:02, 15.53s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:46<00:47, 15.70s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [01:01<00:30, 15.20s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:17<00:15, 15.53s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:32<00:00, 15.37s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  50%|████████████████▌                | 12/24 [00:00<00:00, 115.90it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 113.72it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 129.39it/s]\u001b[A\n",
      " 98%|███████████████████████████████████████▏| 52/53 [1:25:36<01:41, 101.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Generating:  17%|█████▌                           | 1/6 [00:14<01:12, 14.51s/it]\u001b[A\n",
      "Generating:  33%|███████████                      | 2/6 [00:30<01:00, 15.11s/it]\u001b[A\n",
      "Generating:  50%|████████████████▌                | 3/6 [00:45<00:45, 15.20s/it]\u001b[A\n",
      "Generating:  67%|██████████████████████           | 4/6 [00:59<00:29, 14.68s/it]\u001b[A\n",
      "Generating:  83%|███████████████████████████▌     | 5/6 [01:14<00:15, 15.01s/it]\u001b[A\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:29<00:00, 14.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|█████████████████████████████████| 6/6 [01:29<00:00, 14.89s/it]\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 125.75it/s]\u001b[A\n",
      "\n",
      "Batches:   0%|                                           | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████| 24/24 [00:00<00:00, 141.34it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████| 53/53 [1:27:16<00:00, 98.81s/it]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "checkpoints_dir = os.path.join('models', 'penalty_salesforce_5', 'checkpoints')\n",
    "sent_embed = SentenceTransformer('all-MiniLM-L6-v2').cuda()\n",
    "similarities = {}\n",
    "model.cuda()\n",
    "model.eval()\n",
    "for file in tqdm(os.listdir(checkpoints_dir)):\n",
    "    checkpoint = os.path.join(checkpoints_dir, file)\n",
    "    epoch = int(re.findall('[0-9]+', file)[0])\n",
    "    weights = torch.load(checkpoint)\n",
    "    model.load_state_dict(weights['model_state_dict'])\n",
    "    pred, pred_kp = predict(args, model, (dev_examples, dev_features))\n",
    "    preds_p1, preds_p2 = get_similarity(dev_examples, pred)\n",
    "    cosine_scores = similar(preds_p1, preds_p2, sent_embed)\n",
    "    sims = 0\n",
    "    for i in range(cosine_scores.shape[0]):\n",
    "        sims += cosine_scores[i, i].item()\n",
    "        \n",
    "    sims /= cosine_scores.shape[0]\n",
    "    similarities[epoch] = sims\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af7c65a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.266460</td>\n",
       "      <td>0.999887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.266444</td>\n",
       "      <td>0.999260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.264712</td>\n",
       "      <td>0.995657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.263771</td>\n",
       "      <td>0.991066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.260645</td>\n",
       "      <td>0.990532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1  similarity\n",
       "1  0.266460    0.999887\n",
       "3  0.266444    0.999260\n",
       "5  0.264712    0.995657\n",
       "7  0.263771    0.991066\n",
       "9  0.260645    0.990532"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "f1_df = pd.read_json('f1_cos_test_metrics.json').T\n",
    "f1_df = f1_df.sort_index().rename({1: 'similarity', 0: 'f1'}, axis=1)\n",
    "f1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa27e91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1            0.229382\n",
       "similarity    0.890456\n",
       "Name: 49, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_df.loc[49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22654b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmsElEQVR4nO3deXxddZ3/8dfn3tybfU+6pOkKhW5ISyOUTSuLFsGyCAICroj4YHFAGZ0Rf4OMjtsoiIMwgAr6c0CpCgUKDGCrgBRIWWwbKHSladI2TZul2W6W7/zxvW3TkrRpe5ObnLyfj8d53HvPOfec7+mBd879nu/5fs05h4iIDH2hZBdAREQSQ4EuIhIQCnQRkYBQoIuIBIQCXUQkIFKSteOioiI3YcKEZO1eRGRIWrZs2TbnXHFPy5IW6BMmTKC8vDxZuxcRGZLMbENvy1TlIiISEAp0EZGAUKCLiARE0urQRSS42tvbqayspLW1NdlFGbLS0tIoLS0lEon0+TsKdBFJuMrKSrKzs5kwYQJmluziDDnOOWpra6msrGTixIl9/t4Bq1zM7FdmttXMVvSy3MzsDjNbbWb/MLPjDqLcIhJAra2tFBYWKswPkZlRWFh40L9w+lKHfj8wbz/LzwImx6ergLsOqgQiEkgK88NzKP9+B6xycc79zcwm7GeVc4HfON8P71IzyzOz0c656oMuTV9seAnWLoZwBMLR+BR/n5YL+RMgfyKk5fTL7kVEBqtE1KGPATZ2+1wZn/e+QDezq/BX8YwbN+7Q9lb5Cvz1hwdeL6PQB3vBJCiaDCOmwohpPvBD4UPbt4gMGXfccQd33XUX06ZNo6qqitdee43vfe97fP3rX0920frNgN4Udc7dA9wDUFZWdmgja5z8VTjpeuhsh85YfIq/b9kO29fBjnV7Xt9bCssfBuK7S0mHEVN8uGcWQSgSv8KPxN9HIW8sFB3twz+s+8YiQ9EvfvELnn32WaLRKBs2bOCRRx5JdpH6XSLSahMwttvn0vi8/mMGKVE/dZc3FkYf+/71Y01Q8zZsqYCt8Wn1s9BS5/8Q0MvflnAUCo+EoqOgOB7weeP8lF2isBcZpK6++mrWrl3LWWedxRe+8AVuuOEGnnjiiWQXq98lIpEWAtea2UPACUB9v9WfH6poJoyZ7aeedHX6q/yuduhogx0b/B+Abaug5h2ofhPeWgiua893LAw5Y3y4F0yEwiN89c6uKZo5MMcmMsh957GVVFQ1JHSb00py+LdPTO91+d13381TTz3F4sWLKSoqSui+B7MDBrqZPQjMBYrMrBL4NyAC4Jy7G1gEfBxYDTQDn++vwvabUDher54Gqdm+KqZ0n/DvaIP6Sqh7b59pA7zzFDTV7L1+ZjFkjvDbyiyOT0WQNRKyR0POaP+anu9/cYiIHKa+tHK59ADLHXBNwko0WKWk+qvwwiN6Xt7a4Ovsa9fA9rU+7Ju2+aDftMy/jzX2sN00yB7lq4pmfBImfxQi6f17LCIDaH9X0pJYqgROlLQcH8o91eHv0t4KO7dAY7WfGqqhsQoaqmDd81DxKESzYMrZMONCmDT3/fcJRER6oUAfSJE0yB/vp311dsCGF2D5Al9f/4/f++qYEdP9H4u0XEiNv6blxqtvRvgqnMwRvplmSH2tiexr8+bNlJWV0dDQQCgU4vbbb6eiooKcnOA9q6JAHyzCKf6KfNJcOPunsOYvUPHInrr61gZorYe2BnpslWNhX0+/+wZtvHqo8Eh/k1bVODLMrF+/fvf7ysrK5BVkACnQB6OUKBw9z0/76uryod5c66tvdm6BnVv91Fjt29+/87/QtHXv7+WO9eFeeKR/0KrwSN8UM2eMbsqKBIQCfagJhSA9z0+93aAFf0W/fY2/SVu7BmpXQ+278OZDe9+czSiCkll7Tzmj+/soRKQfKNCDKi1nT0B355y/mq9d7R+wqnoDql6HNc/taWefOQJGToORM/wTtSOnQ/EUfw9ARAYtBfpwYwbZI/004eQ982PNsGUFbHoNNi+HrSvh1fugI959p4Vg9EyYeg5M+QQUH5WU4otI7xTo4kUzYOzxftqlq9O3qd+y0of96ufguVv9VHR0PNzP8U011eGZSNIp0KV3obC/gVo0GaafB6fdDPWb4O0n4O3H4IXb4fmfQCgFckv39HOTN8E3zZz0EcgqTvJBiAwfargsByd3DJxwFXz2MbhpNZx/j+/9ckyZf3Dq3Wdh8XfhT1+Cn06BBy+Ftx6HjliySy7D3JVXXklFRUWf1y8vL+f6668H4P777+faa689qP11//6SJUv4+9//flDfPxS6QpdDl1EAx178/vntLbDtHVjxR9+qZtUi/+DTMZ+CD1wEOaW+iieSqYehZMDcd999B7V+WVkZZWVlh7Svjo6Ovb6/ZMkSsrKyOOmkkw5pe32l/5sk8SLpvl79zFvhhgr49MMw4VQo/yXcexr85Cj4fincmg/fHQk/nAh3ngAv3AZNtckuvQRAU1MTZ599NsceeywzZszg97//PXPnzqW8vByArKwsbrrpJqZPn84ZZ5zBK6+8wty5c5k0aRILFy4EfAifc84579v2Y489xgknnMCsWbM444wz2LJlCwC33HILV1xxBSeffDJXXHHF7u+vX7+eu+++m9tuu42ZM2fy/PPPM3HiRNrb2wFoaGjY6/Ph0BW69K9wChz1UT81b/dPwLbW+T7qY83QHn/d+hY8ewss/j4ccyEc/6X3N7mUoenJb/qWU4k06hg46we9Ln7qqacoKSnZ3Qd6fX09d921Z7jjpqYmTjvtNH784x9z/vnnc/PNN/PMM89QUVHBZz/7WebPn9/rtk855RSWLl2KmXHffffxox/9iJ/85CcAVFRU8MILL5Cens6SJUsAmDBhAldffTVZWVm7R0uaO3cuTzzxBOeddx4PPfQQF1xwAZFI5HD/VRToMoAyCnxY92ZLBbx6r6+meeN3UPpBmHmZv9ovnuKraUT64JhjjuFrX/sa3/jGNzjnnHM49dRT91oejUaZN2/e7nVTU1OJRCIcc8wxe3UZ0JPKykouvvhiqquricViTJw4cfey+fPnk55+4G42rrzySn70ox9x3nnn8etf/5p777334A+yBwp0GTxGToNzboPT/w3efBBeuRce/6f4QvN90oyY6h90yp/o/0CkF8Rf8yEtT3Xyg9F+rqT7y1FHHcVrr73GokWLuPnmmzn99NP3Wh6JRLB4lxehUIjU1NTd7zs6Ova77euuu44bb7yR+fPns2TJEm655ZbdyzIz+zawzcknn8z69etZsmQJnZ2dzJgx4yCOrncKdBl80vNgzlfg+C/77gu2Vuw9fOCqRXuPHrWLhWDsCXDKjTD5TPVRM4xVVVVRUFDA5ZdfTl5e3kHfEN2f+vp6xowZA8ADDzzQp+9kZ2fT0LD3qE2f+cxn+PSnP823v/3thJVNgS6DVyi0px38tHP3zG9v8X3It+zw9fItO/wA4Tu3+gHB/+ciGPUB+NDX/VOtumofdpYvX85NN91EKBQiEolw11137a6/Ply33HILF110Efn5+Zx22mmsW7fugN/5xCc+wYUXXsijjz7Kz3/+c0499VQuu+wybr75Zi69dL9jCB0U8wMODbyysjK3646zSMJ0xHxf8i/c5q/ui46GU2/0A4ZoUO8B89ZbbzF16tRkF2NQW7BgAY8++ii//e1ve12np39HM1vmnOuxPaX+C5dgSYnCcVfAzE/Dyj/D8z+FP38ZXroT5v8cSmYmu4QiXHfddTz55JMsWrQoodtVoEswhcK+Rc30C/xAIU9907eBP/EamPsvajEjSfXzn/+8X7arykUJtlAIZlwA17wCsy6Hv98Bd50Ea/+a7JIFXrKqc4PiUP79FOgyPKTnwfw7fB80ZvCb+fDoNX5YP0m4tLQ0amtrFeqHyDlHbW0taWkHNwaBqlxkeJn4IfjK3+GvP4QX74ANf4dP/RZGJaYdsHilpaVUVlZSU1OT7KIMWWlpaZSWlh7Ud9TKRYavDS/Bw5/zV+nn3AYzE9d8TKS/7K+Vi6pcZPgafyJc/TyUlsEjV8Nj/+S7ABYZolTlIsNb1gi44hH4y7/Di7dD9Rtw0QN+gI7ByjmI7Yx3cNYE7c17OjpLzYXS2ckuoSSJAl0knAJnfsd3BvbIV+C/PwQf+RbM/pxv154ssWZY+Sc/DGBDFTRsgoZq/769qffvTTkHPv6fkDN64Moqg4Lq0EW6q10DC6+HDS9A/gQ47du+LftAdh/QEYPXHoC//Rh2bgELQ/ZoH9A5JZAzBrJGQmqWHyRk12Ah0Qx4b6m/4RuOwhm3wOzPq+uDgNlfHboCXWRfzsHqZ33/7FtW+H5hzvwOHHHa4W23bacfxamr3ff1PnIGpKTuWd7VCcsXwJL/gB3rYdyJ/g/KuDkHNwh37Rp4/AZY91cYOwc+8TMYMeXwyi6DhgJd5FB0dfnOvhZ/F+reg/Enw/Tz4aiP+cGw+6q+El65B5bdv3e791DEdwdcMst3QPbG//jeJEcd47sQPvKMQ+8x0jnfBfHT/+r/kJx8PZx4re9qWIY0BbrI4ehog/Jfwcv/DTviPesVT/WjME3+mO+yt6eOvyqXwdI7YeUjgIOpn4A51/iqk6rXoeqN+OvrfhSngiPgtG/BtPMTV02ys8aH+vI/+GqZss/7YFf9+pClQBdJBOegdjW88zS8+7R/KKlr12AI5qtFLAyhFN83e6wRUnPguM/A8Vf13nLGOWishswR/dcj5JYK3wPligW+fDMvg5O/CgUTD/xdGVQU6CL9obUe1iz246G6Tl8H3tXhB9/o6vQjLB17CaTlJLuke2xfBy/+zA/x19UJ08+DE77i2+JrQJAhQYEuIntrqIaX/gte+w20NUDJcXDC1f4eQTKbasoBKdBFpGdtjX5Q7pfv9tVJWSOh7AswaS5kFEFmoX9YSU0fBw0FuojsX1cXrP0LLL0bVj+z9zILQ0ahD/vTv+1b+UjSHPaIRWY2D/gZEAbuc879YJ/l44AHgLz4Ot90ziV2KA4R6T+hkG8meeQZvg38ttXQXAvN2/xr0zZ/E/jhz8OVz8DI6ckusfTggIFuZmHgTuBMoBJ41cwWOucquq12M/AH59xdZjYNWARM6Ifyikh/y5/gp301boZ75sKDl8CXlvjqGBlU+lIxdjyw2jm31jkXAx4Czt1nHQfsupWfC1QlrogiMihkj4KLfweNW+Dhz0Jne7JLJPvoS6CPATZ2+1wZn9fdLcDlZlaJvzq/rqcNmdlVZlZuZuXq+F5kCCqd7bsSWP+8f2BJBpVE3bq+FLjfOVcKfBz4rZm9b9vOuXucc2XOubLi4uIE7VpEBtTMS/3Tpq/cA8seSHZppJu+3BTdBIzt9rk0Pq+7LwLzAJxzL5lZGlAEbE1EIUVkkDnjO77fmSe+BsVH+w7E9uWcv5lat8HfaK17z78HOP7LMHLagBZ5OOhLoL8KTDazifggvwT49D7rvAecDtxvZlOBNEB1KiJBFU6BC38F954GD10G40/ybdp3Tw3QUgcdLXt/L73A942z7H6Ydh58+J/VYiaBDhjozrkOM7sWeBrfJPFXzrmVZnYrUO6cWwh8DbjXzG7A3yD9nNNw3yLBlp4PlzwIf/4ybHsHUrN9Nwe5Y3wfNmm5kDvW92GTN85PqdnQvB1eutN3dlbxCEydDx/+xp6Butt2+sE86iv9YB4jpvquCeSA9GCRiCRH83ZY+gv/MFOsEQonw86t0Fb//nU/+CU/YEdq1oAXc7DRk6IiMng1b/dX61tW+JGZcsdATql/zRoJr9zruybIGwvz/wsmfTjZJU4qBbqIDG0bXoJHr4Hta6Dsi34EqdTsZJcqKQ770X8RkaQafyJc/QIs/p6vf3/3GZh1mb+izx4Vn0b7DsWGcUdiCnQRGRqiGfCx7/mbqE/cCEu+//51Qikw6SMw63I4+qy9x2zdV1enb4kToC4MFOgiMrSMOwG+8iJ0xKBpq+9jprHav+5YDyv/7LsmSC+AD1zsw33UDL9+1euw4UXf0djGl33zyrEnwKwrfF/wQ/ymq+rQRSRYujph7WJ4/f/D209AZ8yP19pQtaddfPEUGHeir6ZZscA3u4xmwYwLYNZnBvUITropKiLDU/N2WP4wvPu/UHSUfwBq3ImQWbRnHedg4yt+9KaVf4L2Zhg5wz8NO/mM5JW9Fwp0EZG+aGuEFX+EF26HHet8//Af/a5/uGmQ2F+gD9/bwSIi+0rNhtmfg2tegY/9B1S+CnedBI/fADu79WbS2Q5b3/b19Ut+4Kt32luTVuxddIUuItKb5u3w1x/Cq/dBSrp/qKl2jR9/tWuf/uAziuD4L/l28ln915usqlxERA7Htnfh2Vt8D5NFR8OIKf7GavEUXzdf+Wq8ffzTEE6FYy+GOdf49RJMgS4iMhBq3vH907z5IHS0woRT4dhLYdq5CWsSqUAXERlITbWw7Ffw+u/8zdVIhn8gaualPuRD4UPetAJdRCQZnPMPML35IKz4s+9JMmeMv+E6/bxD2qT6chERSQYzP5rTuDkw7wew6kkf7hkF/bI7BbqIyECIpPsnUWdc0G+7UDt0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIPoU6GY2z8xWmdlqM/tmL+t8yswqzGylmf1PYospIiIHcsBBos0sDNwJnAlUAq+a2ULnXEW3dSYD/wKc7JzbYWYj+qvAIiLSs75coR8PrHbOrXXOxYCHgHP3WedLwJ3OuR0AzrmtiS2miIgcSF8CfQywsdvnyvi87o4CjjKzF81sqZnN62lDZnaVmZWbWXlNTc2hlVhERHqUqJuiKcBkYC5wKXCvmeXtu5Jz7h7nXJlzrqy4uDhBuxYREehboG8Cxnb7XBqf110lsNA51+6cWwe8gw94EREZIH0J9FeByWY20cyiwCXAwn3WeQR/dY6ZFeGrYNYmrpgiInIgBwx051wHcC3wNPAW8Afn3Eozu9XM5sdXexqoNbMKYDFwk3Outr8KLSIi72fOuaTsuKyszJWXlydl3yIiQ5WZLXPOlfW0TE+KiogEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQmIPgW6mc0zs1VmttrMvrmf9T5pZs7MyhJXRBER6YsDBrqZhYE7gbOAacClZjath/Wyga8CLye6kCIicmB9uUI/HljtnFvrnIsBDwHn9rDevwM/BFoTWD4REemjvgT6GGBjt8+V8Xm7mdlxwFjn3BP725CZXWVm5WZWXlNTc9CFFRGR3h32TVEzCwE/Bb52oHWdc/c458qcc2XFxcWHu2sREemmL4G+CRjb7XNpfN4u2cAMYImZrQfmAAt1Y1REZGD1JdBfBSab2UQziwKXAAt3LXTO1TvnipxzE5xzE4ClwHznXHm/lFhERHp0wEB3znUA1wJPA28Bf3DOrTSzW81sfn8XUERE+ialLys55xYBi/aZ9/96WXfu4RdLREQOlp4UFREJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiARESrILcLA2bm9mQ21zj8siYSMnPUJufMqIhjGzAS6hiEhyDLlAX7S8mu8/+Xaf1o2EjZy0CJmpKaRHwqRFQqRGwqRFwqSlhCjMSqU0P52SvDTG5GVQkpfGqJw0UsL64SIiQ8+QC/T5M0s4bnx+j8va2rtoaG2nvmXvqamtg9b2Tlrbu2ht76S+pZ0tsU6WbdhBbVNsr22EDAoyo+RlRCnIiJKfGaEgM0puepRI2DDAzDCDkBnhkP9VkJceIS8jQl56lLyMCLkZEbJTU/QLQUQGzJAL9NG56YzOTU/Y9lpinVTVt7BpRwtVdX7a1hRjR1OMHc0x1m9r5rX36qhrjtHZ5ehyfd92OGTk7g76CHkZPuz9H4ooBZlR8jP868icVEry0ono14GIHKIhF+iJlh4Nc0RxFkcUZ/X5O845nAMHtHd20RD/JVDX0k5dczt1zTHqmv28Hc0x6lraqW9uZ2tjK6s2N7KjOUZzrPN92w0ZjMpJo7Qgg9L8dMbmZ3DEiCymjspmYlGmqoJEZL+GfaAfil1VLgDhkK+TH5GTdlDbaG3vZHtTbPe0uaGVyh0tVG5vZuOOZl5aU8ufGzbh4r8IouEQR47IYsqobI4alU12WgphM0LxsoRDvvpnRHaavxeQm0ZqSjjBRy4ig5kCPUnSImFK8tIpyeu9+qito5M1W5tYtaWBt6sbeXtzIy+u2cafXt/Up30UZUUZnZvO2IJ0Zo8vYM6kAqaOyiEUUr2+SBAp0Aex1JQw00pymFaSA7P2zK9vaae1vZMu5+js8tU/Xc4R6+hia2MbVXUtVNe3Ul3fQlVdK8s31bNo+WYActJSOH5iIXMmFXDc+HzGF2RQkBnVzVuRAFCgD0G72tn3ZPLI7B7nV9W18PK6Wpau2c7SdbU8+9aW3cvSIiFK8329fWm+v+lclBWlMDOVouxUCjOjFGenkhYZmlU4zjn9wZJhQYE+TJTkpXP+rFLOn1UKQHV9C8sr69lU1+Lr7nc0s6muhTc21lHX3N7jNvIyIowryGBcQQbjCzMYX5DJ2Pj7UTlp/VKV09HZRc3ONjbXt7KloZUtDW1sbmhlR1OMplgnzW0dNMU6aGrrpCnWQVt7F20dXbR3dhHr6CLW2UVnlyMtEtrTpDTe8qggM5V5M0bxoclFCnwJBHPuINrhJVBZWZkrLy9Pyr5l/1pindQ2tVG7M8a2nf61Zqevynkv/qTuproWOru14YymhHzQF2QwrtC/luT5q/1RuWkUZkb3CvzOLkdNYxtV9S1srm+lur6VmsY2P+1sY1v8tXZn2/uaiqaEjPzMKFmpKWSmhsmIppAZDZMRf4AsEg6RmhIimhIiEjYi4RAtsU7fAqklFm+J1E51fQsNrR1MHpHFF0+ZyHmzxgzZXyEyfJjZMudcWY/LFOhyKNo7u6iua2XD9iY21Dbz3vZm1m9r2h34Le17N8uMhI2ROWkUZEap3RljS0MrHfskdSRsFGelUpzdbcpKZWSuf4J3ZHza94/DoYp1dPH4P6q47/l1VFQ3UJAZ5fI547lizniKs1MPe/si/UGBLgPKObe7mqQ6XlVSXd/K5vpWaptiFGZGGZ2bxui8dEpy0+IPi6WRlxFJStWHc46la7fzyxfW8tzbW4mEQ9z00aP54ikT1SJIBp3DDnQzmwf8DAgD9znnfrDP8huBK4EOoAb4gnNuw/62qUCXwWhtzU6+/+TbPFOxhZOOKOQ/Lzp2v01LRQba/gL9gI8emlkYuBM4C5gGXGpm0/ZZ7XWgzDn3AWAB8KPDK7JIckwqzuKeK2bzw08ewxsb65h3+9947M2qZBdLpE/68iz58cBq59xa51wMeAg4t/sKzrnFzrldfdouBUoTW0yRgWNmXPzBcTz51VM5YkQW1z34Ojf8/g0aWntu/SMyWPQl0McAG7t9rozP680XgSd7WmBmV5lZuZmV19TU9L2UIkkwvjCTh798IjeeeRQL36zirNufZ/22pmQXS6RXCe3tycwuB8qAH/e03Dl3j3OuzDlXVlxcnMhdi/SLlHCI60+fzIKrT6SlvZNL7lmqUJdBqy+BvgkY2+1zaXzeXszsDOBbwHznXFtiiicyOMwal8/vrjyBto5OLr13KRtqFeoy+PQl0F8FJpvZRDOLApcAC7uvYGazgP/Gh/nWxBdTJPmmjs7hd1fOobW9k0vvWcp7vQyFKJIsfW22+HHgdnyzxV85575nZrcC5c65hWb2LHAMUB3/ynvOufn726aaLcpQtbKqnsvue5mMSJiHrjqRcYUZyS6S9KKjs4uK6gZWVjXgnH94LZoSIiW05yliAIfPwV1xGDIjLRImPRomIxqOD2Hph7GMhENEw6FDfkbBOT9QTvgQv68Hi0QSbMUmH+pZqSk8dNUcxhYo1Aeac46OLt/jaGeXo9M52tq7WFlVz7INOyhfv4M3Nta976nlRAmHbPcfhazUlN2jj/l+gvwwlm3tnWzbGdvdlUbtzja2NcX47rkz+NQHxx54Jz1QoIv0A4X64XPOUdsUY922JjbtaPF9BzXF2NboX2t3ttHY1kGsw3e6FotPbR2d+x0OMhwypo7Opmx8AbPH53NsaR7RlBDtnV3xye1+v+vp5F3Xy2a+r6GW9k5a2ztpiXXR0t5JS6yD1vYu2ru6aO/Y8/22ji6a2jrY0ewHq6lrbmd7fNSyaEqIoswohVmpFO7qwTQryrwZo5g1ruexkQ9EgS7ST1ZsqufT9y4lOy2iUN9HU1sH25tifnjG5l3DNMbY2tDG+tom1m1rYl1NE41tHXt9LyVkFGZFKcpKpTArlezUlN2dre163VVtkhIyQiEjJT5iV0rImDwym5lj88hMTW5nsp1djpCR8O4sFOgi/Wh5ZT2X3adQB1i3rYknV1Tz9IrNvFlZ3+M6ZjAmL52JRZl7TaX5GRRnpZKTnqLujPdDgS7Sz4ZrqMc6unhnSyPPVGzhqRWbWbWlEYBjS3P5yJQRlOSmk5sRIS89Ql6Gr1/Oy4hovNvDoEAXGQC7Qj0nPcKDXwpWqHd1OV7fuIO3qhtZW9PEum07WbutiY3bm+ly/qr7gxMKmDd9FB+bMYox6tCs3yjQRQZI0EJ94/ZmFiyr5I+vVVK5owWA9EiYiUWZTCrOZFJRJkeMyOKkI4rUh/wAUaCLDKBdoR4OGd+YN4VPlY0dUv2qN8c6eHL5ZhYsq+SltbWYwclHFHHh7FJOmFTAqJw01XEnkQJdZICt3trIv/5pBa+s387MsXl897wZzBiTm+xi9aq1vZMlq2p4Ynk1z721heZYJ+MKMrhwdimfnF2qKpRBRIEukgTOOf78+ib+Y9Fb1DbFuPyE8Xz9o0eTmxFJdtFwztHY1sHSNbU8sbyaZyu20BTrpCDTt5Gef2wJx08oGFK/LIaL/QV6chtqigSYmXHBcaWcPnUktz3zDr95aT2LllfzuZMm8OGji5lRktvvgdkS6+TplZsp37B9r0G4axrbaG3vAiAvI8L8mSWcfUwJcyYVkBJOaCesMoB0hS4yQFZW1XPrYxW8vG47APkZEU6ZXMypk4s4dXIRo3MTU63hnOO19+pYsGwjj79ZTWNbBzlpKYzKTds98PauQbinjMrhxCMKd/dpIoOfqlxEBpFtO9t4cfU2/vpODc+/u42aRt/b9MyxeXxydinzP1By0NUyHZ1drNrSyF/fqWHBskrW1jSRHglz1jGjuGj2WE6YqOqToFCgiwxSzjne3tzI4lVbefT1KlZtaSQaDnHmtJF8cvYYPjS5eK8qkK54HyPbm2Is31TPGxvreOO9OpZvqt/dCdUHJ+Rz4exSzv5ACVlJfvxdEk+BLjIEOOdYWdXAgmWVPPrGJnY0t5OfESEjmkJLeyfN8c6huouGQ0wryWHm2DxmjcvjuHH5Q77tu+yfboqKDAFmxowxucwYk8u/fnwqi1dt5ZmKLTgH6dEQGdEU0iO+f+6stBSml+QydXS2HqOX3RToIoNQNCXEx6aP4mPTRyW7KDKE6Na2iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCYikPfpvZjXAhoP4ShGwrZ+KM9gMl2MdLscJw+dYh8txQvKOdbxzrrinBUkL9INlZuW99V8QNMPlWIfLccLwOdbhcpwwOI9VVS4iIgGhQBcRCYihFOj3JLsAA2i4HOtwOU4YPsc6XI4TBuGxDpk6dBER2b+hdIUuIiL7oUAXEQmIIRHoZjbPzFaZ2Woz+2ayy5MoZjbWzBabWYWZrTSzr8bnF5jZM2b2bvw1P9llTRQzC5vZ62b2ePzzRDN7OX5uf29m0WSX8XCZWZ6ZLTCzt83sLTM7Majn1MxuiP+3u8LMHjSztKCcUzP7lZltNbMV3eb1eB7NuyN+zP8ws+OSUeZBH+hmFgbuBM4CpgGXmtm05JYqYTqArznnpgFzgGvix/ZN4Dnn3GTgufjnoPgq8Fa3zz8EbnPOHQnsAL6YlFIl1s+Ap5xzU4Bj8ccbuHNqZmOA64Ey59wMIAxcQnDO6f3AvH3m9XYezwImx6ergLsGqIx7GfSBDhwPrHbOrXXOxYCHgHOTXKaEcM5VO+dei79vxP+PPwZ/fA/EV3sAOC8pBUwwMysFzgbui3824DRgQXyVIX+sZpYLfAj4JYBzLuacqyOg5xQ/jGW6maUAGUA1ATmnzrm/Adv3md3beTwX+I3zlgJ5ZjZ6QArazVAI9DHAxm6fK+PzAsXMJgCzgJeBkc656viizcDIZJUrwW4H/hnYNXR9IVDnnOuIfw7CuZ0I1AC/jlct3WdmmQTwnDrnNgH/CbyHD/J6YBnBO6fd9XYeB0VODYVADzwzywL+CPyTc66h+zLn25UO+balZnYOsNU5tyzZZelnKcBxwF3OuVlAE/tUrwTonObjr0wnAiVAJu+vogiswXgeh0KgbwLGdvtcGp8XCGYWwYf575xzf4rP3rLr51r8dWuyypdAJwPzzWw9vtrsNHxdc1785zoE49xWApXOuZfjnxfgAz6I5/QMYJ1zrsY51w78CX+eg3ZOu+vtPA6KnBoKgf4qMDl+5zyKv+myMMllSoh4HfIvgbeccz/ttmgh8Nn4+88Cjw502RLNOfcvzrlS59wE/Dn8i3PuMmAxcGF8tSF/rM65zcBGMzs6Put0oIIAnlN8VcscM8uI/7e861gDdU730dt5XAh8Jt7aZQ5Q361qZuA45wb9BHwceAdYA3wr2eVJ4HGdgv/J9g/gjfj0cXzd8nPAu8CzQEGyy5rg454LPB5/Pwl4BVgNPAykJrt8CTi+mUB5/Lw+AuQH9ZwC3wHeBlYAvwVSg3JOgQfx9wba8b+8vtjbeQQM3xpvDbAc3/JnwMusR/9FRAJiKFS5iIhIHyjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIB8X8PGhMV02wFGQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lines = f1_df.plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc182b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = lines.get_figure()\n",
    "fig.savefig(\"f1_similarity.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f63d18f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f1_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             opt_epoch \u001b[38;5;241m=\u001b[39m i\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_epoch, opt_f1, opt_sim\n\u001b[0;32m---> 15\u001b[0m find_optimal_epoch(\u001b[43mf1_df\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f1_df' is not defined"
     ]
    }
   ],
   "source": [
    "def find_optimal_epoch(df, f1_threshold=0.20, sim_threshold=0.9):\n",
    "    opt_epoch = 0\n",
    "    max_diff = float(\"inf\")\n",
    "    opt_f1 = 0\n",
    "    opt_sim = 0\n",
    "    for i, row in df.iterrows():\n",
    "        if max_diff > (abs(row['f1'] - row['similarity'])) and row['f1'] >= f1_threshold and row['similarity'] < sim_threshold:\n",
    "            max_diff = abs(row['f1'] - row['similarity'])\n",
    "            opt_f1 = row['f1']\n",
    "            opt_sim = row['similarity']\n",
    "            opt_epoch = i\n",
    "    \n",
    "    return opt_epoch, opt_f1, opt_sim\n",
    "\n",
    "find_optimal_epoch(f1_df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c4ebb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.26646</td>\n",
       "      <td>0.999887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f1  similarity\n",
       "1  0.26646    0.999887"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_df[f1_df['f1'] == max(f1_df['f1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e8130fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.175315</td>\n",
       "      <td>0.709099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f1  similarity\n",
       "105  0.175315    0.709099"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_df[f1_df['similarity'] == min(f1_df['similarity'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50a87638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1            0.231589\n",
       "similarity    0.948035\n",
       "Name: 31, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_df.loc[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8838e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[1, 31, 49, 105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3caa3c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_df.to_json('f1_sim_metrics.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb950975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:   0%|                                         | 0/6 [00:00<?, ?it/s]/mnt/nkees_playground/dialogue-text-summarization-dokument/.venv/lib/python3.9/site-packages/transformers/generation_stopping_criteria.py:93: UserWarning: You set different `max_length` for stopping criteria and `max_length` parameter\n",
      "  warnings.warn(\n",
      "/mnt/nkees_playground/dialogue-text-summarization-dokument/.venv/lib/python3.9/site-packages/transformers/generation_utils.py:1777: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  next_indices = next_tokens // vocab_size\n",
      "Generating: 100%|█████████████████████████████████| 6/6 [01:31<00:00, 15.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "rouge-1:\tP: 17.0049\tR: 43.0558\tF1: 22.9382\n",
      "rouge-2:\tP: 5.9923\tR: 15.3044\tF1: 8.0482\n",
      "rouge-3:\tP: 2.9329\tR: 8.0459\tF1: 4.0103\n",
      "rouge-4:\tP: 1.4760\tR: 4.3141\tF1: 2.0407\n",
      "rouge-l:\tP: 18.9232\tR: 41.9821\tF1: 24.9188\n",
      "rouge-w:\tP: 12.7741\tR: 21.3141\tF1: 14.5787\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "checkpoints_dir = os.path.join('models', 'penalty_salesforce_5')\n",
    "checkpoint = os.path.join(checkpoints_dir, 'checkpoint_49.pt')\n",
    "\n",
    "weights = torch.load(checkpoint)\n",
    "model.load_state_dict(weights['model_state_dict'])\n",
    "scores = evaluate(args, model, (dev_examples, dev_features), dump_pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e159b6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'f': 0.21585215999246082,\n",
       "  'p': 0.1624548306332973,\n",
       "  'r': 0.3965837710635994},\n",
       " 'rouge-2': {'f': 0.07785077023145705,\n",
       "  'p': 0.05907409987050643,\n",
       "  'r': 0.14399209288349424},\n",
       " 'rouge-3': {'f': 0.03978412044147189,\n",
       "  'p': 0.02985041774070357,\n",
       "  'r': 0.0772432379143444},\n",
       " 'rouge-4': {'f': 0.02060074586505667,\n",
       "  'p': 0.015414395415322926,\n",
       "  'r': 0.04084784697951765},\n",
       " 'rouge-l': {'f': 0.23458035796771126,\n",
       "  'p': 0.18044662831416589,\n",
       "  'r': 0.38855928524324124},\n",
       " 'rouge-w': {'f': 0.137749636094388,\n",
       "  'p': 0.12311769448212143,\n",
       "  'r': 0.1976042579095233}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30837194",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = os.path.join('models', 'penalty_salesforce_5', 'checkpoints', 'checkpoint_53.pt')\n",
    "weights = torch.load(checkpoint)\n",
    "model.load_state_dict(weights['model_state_dict'])\n",
    "pred, pred_kp = predict(args, model, (dev_examples, dev_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4101d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = evaluate(args, model, source='test', dump_pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fda1fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = load_examples(args, train_path)\n",
    "train_features = convert_examples_to_features(args, model.module.config, model.module.tokenizer, train_examples)\n",
    "dev_examples = load_examples(args, args.dev_file_path)\n",
    "dev_features = convert_examples_to_features(args, model.module.config, model.module.tokenizer, dev_examples)\n",
    "dev_data = (dev_examples, dev_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3950e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.training import train\n",
    "train(model, args, train_examples, dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1ee25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from transformers.generation_beam_search import BeamSearchScorer\n",
    "lines = inspect.getsource(model.module.encoder_p1.forward)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aab747",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "    \n",
    "# encoder_outputs, source_mask = self.encode(source_ids, source_mask)\n",
    "decoding_p1, decoding_p2 = model(\n",
    "    source_ids, source_mask, inference=True,\n",
    "    num_beams=args.beam,\n",
    "    max_length=args.test_target_max_len,\n",
    "    no_repeat_ngram_size=args.no_repeat_ngram_size,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95dce167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tnguyen/dialogue-text-summarization-dokument/.venv/lib/python3.6/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    }
   ],
   "source": [
    "#dev_examples, dev_features = dev_data\n",
    "eval_dataloader = get_eval_dataloader(dev_features, args.eval_batch_size)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "pred = {} #[None] * len(dev_examples)\n",
    "pred_kp = {}\n",
    "\n",
    "batch = next(iter(eval_dataloader))\n",
    "item_dict = get_eval_batch_data(batch)\n",
    "IDs, example_indices, source_ids, source_mask = item_dict[\"ID\"], item_dict[\"example_indices\"], item_dict[\"source_ids\"], item_dict[\"source_mask\"]\n",
    "\n",
    "with torch.no_grad():\n",
    "    target_ids = model.generator.generate(input_ids = source_ids, attention_mask = source_mask,\n",
    "                                                     num_beams = args.beam,\n",
    "                                                     max_length = args.test_target_max_len,\n",
    "                                                     no_repeat_ngram_size = args.no_repeat_ngram_size,\n",
    "                                                     early_stopping = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d811812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ids = target_ids.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa4f3de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "answer = model.tokenizer.decode(target_ids[i].tolist(), skip_special_tokens=True, clean_up_tokenization_spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cb4ddcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All office communications are restricted to e-mail correspondence and official memos. The use of instant message programs by employees during working hours is strictly prohibited. Any employee who uses instant messaging will be placed on probation or face termination.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80aba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "file_path = args.test_file_path\n",
    "dev_examples = load_examples(args, file_path)\n",
    "dev_features = convert_examples_to_features(args, model.module.config, model.module.tokenizer, dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bec81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred = predict(args, model, (dev_examples, dev_features))\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2325956",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae6e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_examples, dev_features = dev_data\n",
    "from torch import nn\n",
    "#model = nn.DataParallel(model).to('cuda')\n",
    "model.cuda()\n",
    "train_dataloader = get_train_dataloader(dev_features, args.eval_batch_size)\n",
    "batch = next(iter(train_dataloader))\n",
    "item_dict = get_train_batch_data(batch)\n",
    "source_ids, source_mask  = item_dict[\"source_ids\"], item_dict[\"source_mask\"] \n",
    "target_ids_p1, target_labels_p1, func_labels_p1 = item_dict[\"target_ids_p1\"], item_dict[\"target_labels_p1\"], item_dict[\"func_label_p1\"]\n",
    "target_ids_p2, target_labels_p2, func_labels_p2 = item_dict[\"target_ids_p2\"], item_dict[\"target_labels_p2\"], item_dict[\"func_label_p2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11fe87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_p1, outputs_p2, encoder_outputs_p1, encoder_outputs_p2 = model(\n",
    "        source_ids, source_mask, inference=False,\n",
    "        target_ids_p1=target_ids_p1, target_ids_p2=target_ids_p2,\n",
    "        target_labels_p1=target_labels_p1, target_labels_p2=target_labels_p2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3ada0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(encoder_outputs_p1.last_hidden_state, encoder_outputs_p2.last_hidden_state).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe06fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(outputs_p1.logits, outputs_p2.logits).mean()\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cd7338",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_encoder_p2_k_proj = model.encoder_p2.self_attn.k_proj.weight\n",
    "weight_encoder_p1_k_proj = model.encoder_p1.self_attn.k_proj.weight\n",
    "print('Heads having equal weights:', torch.equal(weight_encoder_p1_k_proj, weight_encoder_p2_k_proj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732e11c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_p1 = forward(model.generator, input_ids=None,\n",
    "            attention_mask=source_mask,\n",
    "            encoder_outputs=encoder_outputs_p1,\n",
    "            decoder_input_ids=target_ids_p1,\n",
    "            labels=target_labels_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace84522",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_p1 = model.generator(input_ids=None,\n",
    "            attention_mask=source_mask,\n",
    "            encoder_outputs=encoder_outputs_p1,\n",
    "            decoder_input_ids=target_ids_p1,\n",
    "            labels=target_labels_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ed6371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "train_batch_size = int(args.train_batch_size / args.gradient_accumulation_steps)\n",
    "num_train_steps = int(len(train_features) / train_batch_size / args.gradient_accumulation_steps * args.num_train_epochs)\n",
    "optimizer = AdamW(model.parameters(), lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "\n",
    "t_total = num_train_steps\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(t_total * args.warmup_proportion), num_training_steps=t_total)\n",
    "\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  Num examples = %d\", len(train_features))\n",
    "logger.info(\"  Batch size = %d\", train_batch_size)\n",
    "logger.info(\"  Num steps = %d\", num_train_steps)\n",
    "\n",
    "train_dataloader = get_train_dataloader(train_features, train_batch_size)\n",
    "model.cuda()\n",
    "model.zero_grad()\n",
    "model.train()\n",
    "\n",
    "num_updates = 0\n",
    "best_em = 0.0\n",
    "patience = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9248a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "if not os.path.exists(args.output_dir):\n",
    "    os.mkdir(args.output_dir)\n",
    "\n",
    "with open(os.path.join(args.output_dir, \"{}.log\".format(args.model_name.replace(\"/\", \"-\"))), 'w') as f_log:\n",
    "    loss_over_epochs = []\n",
    "    N = len(train_dataloader)\n",
    "    for epoch in trange(int(args.num_train_epochs), desc=\"Epoch\"):\n",
    "        running_loss = 0\n",
    "        train_loss_tracker_gen, train_loss_tracker_func = [], []\n",
    "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "            loss = 0\n",
    "            item_dict = get_train_batch_data(batch)\n",
    "            source_ids, source_mask = item_dict[\"source_ids\"], item_dict[\"source_mask\"] \n",
    "            target_ids_p1, target_labels_p1, func_labels_p1 = item_dict[\"target_ids_p1\"], item_dict[\"target_labels_p1\"], item_dict[\"func_label_p1\"]\n",
    "            target_ids_p2, target_labels_p2, func_labels_p2 = item_dict[\"target_ids_p2\"], item_dict[\"target_labels_p2\"], item_dict[\"func_label_p2\"]\n",
    "            \n",
    "            encoder_outputs_p1, encoder_outputs_p2 = model(source_ids, source_mask)\n",
    "            batch_size = encoder_outputs_p1[0].size(0)\n",
    "            outputs_p1 = model.generator(input_ids=None,\n",
    "                        attention_mask=source_mask,\n",
    "                        encoder_outputs=(encoder_outputs_p1,),\n",
    "                        decoder_input_ids=target_ids_p1,\n",
    "                        labels=target_labels_p1)\n",
    "            outputs_p2 = model.generator(input_ids=None,\n",
    "                        attention_mask=source_mask,\n",
    "                        encoder_outputs=(encoder_outputs_p2,),\n",
    "                        decoder_input_ids=target_ids_p2,\n",
    "                        labels=target_labels_p2)\n",
    "            \n",
    "            loss_gen = max(outputs_p1[0], outputs_p2[0])\n",
    "            \n",
    "            loss = loss + loss_gen\n",
    "            train_loss_tracker_gen.append(loss_gen.item())\n",
    "\n",
    "            if args.gradient_accumulation_steps > 1:\n",
    "                loss = loss / args.gradient_accumulation_steps\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        running_loss /= N\n",
    "        loss_over_epochs.append(running_loss)\n",
    "        patience, best_em, num_updates = check_accumulation_step(\n",
    "            args, step, model, optimizer,\n",
    "            scheduler, num_updates, f_log, dev_data, patience, best_em\n",
    "        )\n",
    "        \n",
    "        if patience > args.patience:\n",
    "            print(\"[INFO] Ran out of patience...\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06976d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss_over_epochs)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39329dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.Series(loss_over_epochs)\n",
    "df.plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bad5336",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43af3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]['1#0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c877c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples[0].context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2070345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataloader = get_eval_dataloader(train_features, args.eval_batch_size)\n",
    "train_dataloader = get_train_dataloader(train_features, train_batch_size)\n",
    "batch_train = next(iter(train_dataloader))\n",
    "batch_eval = next(iter(eval_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2b28d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#item_dict = get_eval_batch_data(batch_eval)\n",
    "#IDs, example_indices, source_ids, source_mask = item_dict[\"ID\"], item_dict[\"example_indices\"], item_dict[\"source_ids\"], item_dict[\"source_mask\"]\n",
    "item_dict = get_train_batch_data(batch_train)\n",
    "source_ids, source_mask = item_dict[\"source_ids\"], item_dict[\"source_mask\"] \n",
    "target_ids_p1, target_labels_p1, func_labels_p1 = item_dict[\"target_ids_p1\"], item_dict[\"target_labels_p1\"], item_dict[\"func_label_p1\"]\n",
    "target_ids_p2, target_labels_p2, func_labels_p2 = item_dict[\"target_ids_p2\"], item_dict[\"target_labels_p2\"], item_dict[\"func_label_p2\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c110409",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states, attention_mask= model.encode(input_ids=source_ids, attention_mask=source_mask)\n",
    "\n",
    "encoder_outputs_p1 = model.encode_head(hidden_states, attention_mask, model.encoder_p1)\n",
    "encoder_outputs_p2 = model.encode_head(hidden_states, attention_mask, model.encoder_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee17e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(encoder_outputs_p1[0] - encoder_outputs_p2[0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c72c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_p1 = model.decode_head(model.decoder_p1, input_ids=None,\n",
    "                            attention_mask=source_mask,\n",
    "                            encoder_outputs=(encoder_outputs_p1,),\n",
    "                            decoder_input_ids=target_ids_p1)\n",
    "decoded_p2 = model.decode_head(model.decoder_p2, input_ids=None,\n",
    "                    attention_mask=source_mask,\n",
    "                    encoder_outputs=(encoder_outputs_p2,),\n",
    "                    decoder_input_ids=target_ids_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8f92de",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_p2[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f800bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_repeat_ngram_size = args.no_repeat_ngram_size\n",
    "\n",
    "decoding_p1, decoding_p2 = model.generate(input_ids=source_ids, attention_mask=source_mask,\n",
    "                                        num_beams=args.beam,\n",
    "                                        max_length=args.test_target_max_len,\n",
    "                                        no_repeat_ngram_size = no_repeat_ngram_size,\n",
    "                                        early_stopping=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ffde00",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2664fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states, attention_mask = model.encode(input_ids=source_ids, attention_mask=source_mask)\n",
    "\n",
    "encoder_outputs_p1 = model.encode_head(hidden_states, attention_mask, model.encoder_p1)\n",
    "\n",
    "decoded_p1 = model.decode_head(model.decoder_p1, input_ids=source_ids,\n",
    "                    attention_mask=source_mask,\n",
    "                    encoder_outputs=(encoder_outputs_p1,),\n",
    "                    decoder_input_ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62ffcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_p1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466fbb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_p1, decoding_p2 = model.generate(input_ids=source_ids, attention_mask=source_mask,\n",
    "                                                    num_beams=args.beam,\n",
    "                                                    max_length=args.test_target_max_len,\n",
    "                                                    no_repeat_ngram_size = no_repeat_ngram_size,\n",
    "                                                    early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f4a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_repeat_ngram_size = args.no_repeat_ngram_size\n",
    "model.eval()\n",
    "decoding_p1, decoding_p2 = model(input_ids=source_ids, attention_mask=source_mask,\n",
    "                                                    num_beams=args.beam,\n",
    "                                                    max_length=args.test_target_max_len,\n",
    "                                                    no_repeat_ngram_size = no_repeat_ngram_size,\n",
    "                                                    early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860216f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5c66ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_dict = get_train_batch_data(batch_train)\n",
    "target_ids_p1, target_labels_p1, func_labels_p1 = item_dict[\"target_ids_p1\"], item_dict[\"target_labels_p1\"], item_dict[\"func_label_p1\"]\n",
    "target_ids_p2, target_labels_p2, func_labels_p2 = item_dict[\"target_ids_p2\"], item_dict[\"target_labels_p2\"], item_dict[\"func_label_p2\"]\n",
    "source_ids, source_mask  = item_dict[\"source_ids\"], item_dict[\"source_mask\"] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186509be",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs_p1, encoder_outputs_p2 = model(source_ids, source_mask)\n",
    "\n",
    "outputs_p1 = model.generator(input_ids=None,\n",
    "            attention_mask=source_mask,\n",
    "            encoder_outputs=(encoder_outputs_p1,),\n",
    "            decoder_input_ids=target_ids_p1,\n",
    "            labels=target_labels_p1)\n",
    "\n",
    "outputs_p2 = model.generator(input_ids=None,\n",
    "            attention_mask=source_mask,\n",
    "            encoder_outputs=(encoder_outputs_p2,),\n",
    "            decoder_input_ids=target_ids_p2,\n",
    "            labels=target_labels_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d500a67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_p1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bab7f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_encode_p1 = generator_encode(source_ids, model, encoder_outputs_p1)\n",
    "generator_encode_p2 = generator_encode(source_ids, model, encoder_outputs_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f335b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_decode_p1 = generator_decode(target_ids_p1,\n",
    "                                       generator_encode_p1,\n",
    "                                       source_mask,\n",
    "                                       model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33167f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_p1 = get_loss(target_labels_p1, generator_decode_p1, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30096aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_p1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aa3faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states, attention_mask = model.encode(source_ids, source_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da716764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bart.modeling_bart import shift_tokens_right\n",
    "from transformers.modeling_outputs import Seq2SeqModelOutput, Seq2SeqLMOutput\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "def generator_encode(input_ids, model, encoder_outputs):\n",
    "    decoder_input_ids = shift_tokens_right(\n",
    "            input_ids, model.config.pad_token_id, model.config.decoder_start_token_id\n",
    "    )\n",
    "    \n",
    "    output_attentions = model.config.output_attentions\n",
    "    output_hidden_states = model.config.output_hidden_states\n",
    "    use_cache = model.config.use_cache\n",
    "    return_dict = model.config.use_return_dict\n",
    "    if encoder_outputs is None:\n",
    "        encoder_outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "    # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\n",
    "    if return_dict and not isinstance(encoder_outputs, BaseModelOutput):\n",
    "        encoder_outputs = BaseModelOutput(\n",
    "            last_hidden_state=encoder_outputs[0],\n",
    "            hidden_states=encoder_outputs[1] if len(encoder_outputs) > 1 else None,\n",
    "            attentions=encoder_outputs[2] if len(encoder_outputs) > 2 else None,\n",
    "        )\n",
    "        \n",
    "    return encoder_outputs\n",
    "\n",
    "def generator_decode(decoder_input_ids, encoder_outputs, attention_mask, model):\n",
    "    output_attentions = model.config.output_attentions\n",
    "    output_hidden_states = model.config.output_hidden_states\n",
    "    use_cache = model.config.use_cache\n",
    "    return_dict = model.config.use_return_dict\n",
    "    # decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\n",
    "    decoder_outputs = model.generator.model.decoder(\n",
    "        input_ids=decoder_input_ids,\n",
    "        attention_mask=None,\n",
    "        encoder_hidden_states=encoder_outputs[0],\n",
    "        encoder_attention_mask=attention_mask,\n",
    "        head_mask=None,\n",
    "        cross_attn_head_mask=None,\n",
    "        past_key_values=None,\n",
    "        inputs_embeds=None,\n",
    "        use_cache=use_cache,\n",
    "        output_attentions=output_attentions,\n",
    "        output_hidden_states=output_hidden_states,\n",
    "        return_dict=return_dict,\n",
    "    )\n",
    "\n",
    "    if not return_dict:\n",
    "        return decoder_outputs + encoder_outputs\n",
    "    \n",
    "    return Seq2SeqModelOutput(\n",
    "        last_hidden_state=decoder_outputs.last_hidden_state,\n",
    "        past_key_values=decoder_outputs.past_key_values,\n",
    "        decoder_hidden_states=decoder_outputs.hidden_states,\n",
    "        decoder_attentions=decoder_outputs.attentions,\n",
    "        cross_attentions=decoder_outputs.cross_attentions,\n",
    "        encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n",
    "        encoder_hidden_states=encoder_outputs.hidden_states,\n",
    "        encoder_attentions=encoder_outputs.attentions,\n",
    "    )\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "def get_loss(labels, outputs, model):  \n",
    "    return_dict = model.config.use_return_dict\n",
    "    decoder_input_ids = shift_tokens_right(\n",
    "            labels, model.config.pad_token_id, model.config.decoder_start_token_id\n",
    "        )\n",
    "    lm_logits = model.generator.lm_head(outputs[0]) + model.generator.final_logits_bias\n",
    "\n",
    "    masked_lm_loss = None\n",
    "    if labels is not None:\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        masked_lm_loss = loss_fct(lm_logits.view(-1, model.config.vocab_size), labels.view(-1))\n",
    "\n",
    "    if not return_dict:\n",
    "        output = (lm_logits,) + outputs[1:]\n",
    "        return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n",
    "\n",
    "    return Seq2SeqLMOutput(\n",
    "        loss=masked_lm_loss,\n",
    "        logits=lm_logits,\n",
    "        past_key_values=outputs.past_key_values,\n",
    "        decoder_hidden_states=outputs.decoder_hidden_states,\n",
    "        decoder_attentions=outputs.decoder_attentions,\n",
    "        cross_attentions=outputs.cross_attentions,\n",
    "        encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n",
    "        encoder_hidden_states=outputs.encoder_hidden_states,\n",
    "        encoder_attentions=outputs.encoder_attentions,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daaf940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205407b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states, attention_mask = model.encode(source_ids, source_mask)\n",
    "embed_p1 = model.encode_head(hidden_states, attention_mask, model.head_p1)\n",
    "embed_p2 = model.encode_head(hidden_states, attention_mask, model.head_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1991b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_p1 = generator_encode(input_ids=None,\n",
    "                            attention_mask=source_mask,\n",
    "                            encoder_outputs=(embed_p1,),\n",
    "                            decoder_input_ids=target_ids_p1,\n",
    "                            labels=target_labels_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0fc9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = source_ids.shape[0]\n",
    "\n",
    "decoding_p1 = model.decode(embed_p1, source_mask, batch_size, source_ids, num_beams=args.beam, max_length=args.test_target_max_len, no_repeat_ngram_size = args.no_repeat_ngram_size, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b9fec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoding_p2 = model.decode(embed_p2, source_mask, batch_size, source_ids, num_beams=args.beam, max_length=args.test_target_max_len, no_repeat_ngram_size = args.no_repeat_ngram_size, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f8a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f95ab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_p1 = decoding_p1.to('cpu')\n",
    "decoding_p2 = decoding_p2.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76761728",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = {}\n",
    "from evaluate import gen_keyphrase_summary\n",
    "for i in range(len(example_indices)):\n",
    "    if IDs[i] in pred.keys():\n",
    "        continue\n",
    "\n",
    "    answer_p1 = model.tokenizer.decode(decoding_p1[i].tolist(), skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    answer_p2 = model.tokenizer.decode(decoding_p2[i].tolist(), skip_special_tokens=True, clean_up_tokenization_spaces=False) \n",
    "    if args.gen_keyphrase_summary:\n",
    "        keyphrase_p1, summary_p1 = gen_keyphrase_summary(answer_p1) \n",
    "        keyphrase_p2, summary_p2 = gen_keyphrase_summary(answer_p2) \n",
    "\n",
    "        #pred_kp[IDs[i]] ={'Person1': keyphrase_p1.strip(), 'Person2': keyphrase_p2.strip()}\n",
    "        #pred[IDs[i]] ={'Person1': summary_p1.strip(), 'Person2': summary_p2.strip()}\n",
    "        print(summary_p1.strip())\n",
    "        print(summary_p2.strip())\n",
    "    else:\n",
    "        pred[IDs[i]] ={'Person1': answer_p1.strip(), 'Person2': answer_p2.strip()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce74e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
