{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e862c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def read_json(file_path):\n",
    "    json_arr = []\n",
    "    with open(file_path) as file:\n",
    "        jsn = json.load(file)\n",
    "    return jsn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d50e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/DialogSum_Data'\n",
    "json_paths = [os.path.join(data_path, f'{split}.json') for split in ['train', 'test', 'val']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74067ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, val_data = (read_json(path) for path in json_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f11b1c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsum_test_path = './data/SAMsum_data/text_test.source'\n",
    "with open(samsum_test_path, 'r') as file:\n",
    "    samsum_lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28cd599f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hannah: Hey, do you have Betty's number? # Amanda: Lemme check # Hannah: <file_gif> # Amanda: Sorry, can't find it. # Amanda: Ask Larry # Amanda: He called her last time we were at the park together # Hannah: I don't know him well # Hannah: <file_gif> # Amanda: Don't be shy, he's very nice # Hannah: If you say so.. # Hannah: I'd rather you texted him # Amanda: Just text him ðŸ™‚ # Hannah: Urgh.. Alright # Hannah: Bye # Amanda: Bye bye\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "tmp_content = samsum_lines[0].split(\" }  # \")[1].replace(\"\\n\", \" \")\n",
    "#tmp_content\n",
    "re.sub(\"\\s+\", \" \", tmp_content).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00a3a8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Person1: Ms. Dawson, I need you to take a dictation for me. # Person2: Yes, sir... # Person1: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready? # Person2: Yes, sir. Go ahead. # Person1: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited. # Person2: Sir, does this apply to intra-office communications only? Or will it also restrict external communications? # Person1: It should apply to all communications, not only in this office between employees, but also any outside communications. # Person2: But sir, many employees use Instant Messaging to communicate with their clients. # Person1: They will just have to change their communication methods. I don't want any - one using Instant Messaging in this office. It wastes too much time! Now, please continue with the memo. Where were we? # Person2: This applies to internal and external communications. # Person1: Yes. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. Any questions regarding this new policy may be directed to department heads. # Person2: Is that all? # Person1: Yes. Please get this memo typed up and distributed to all employees before 4 pm.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]['dialogue'].replace('#', '').replace('\\n', ' # ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0525d4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dataset in [('train', train_data), ('test', test_data), ('val', val_data)]:\n",
    "    dlgs = [(data['dialogue'].replace('#', '').replace('\\n', ' # ') + '\\n') for data in dataset]\n",
    "    out_path = os.path.join(data_path, f'text_{name}.source')\n",
    "    with open(out_path, 'w') as file:\n",
    "        file.writelines(dlgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc877339",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlgs = [(\" }  # \" + data['dialogue'].replace('#', '')).replace('\\n', ' # ') for data in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9eda6141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" }  # Person1: Ms. Dawson, I need you to take a dictation for me. # Person2: Yes, sir... # Person1: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready? # Person2: Yes, sir. Go ahead. # Person1: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited. # Person2: Sir, does this apply to intra-office communications only? Or will it also restrict external communications? # Person1: It should apply to all communications, not only in this office between employees, but also any outside communications. # Person2: But sir, many employees use Instant Messaging to communicate with their clients. # Person1: They will just have to change their communication methods. I don't want any - one using Instant Messaging in this office. It wastes too much time! Now, please continue with the memo. Where were we? # Person2: This applies to internal and external communications. # Person1: Yes. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. Any questions regarding this new policy may be directed to department heads. # Person2: Is that all? # Person1: Yes. Please get this memo typed up and distributed to all employees before 4 pm.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e540639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text_file_path = \"./data/DialogSum_Data/text_test.source\"\n",
    "input_list = open(input_text_file_path, encoding=\"utf-8\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2a4ec8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Person1: Ms. Dawson, I need you to take a dictation for me. # Person2: Yes, sir... # Person1: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready? # Person2: Yes, sir. Go ahead. # Person1: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited. # Person2: Sir, does this apply to intra-office communications only? Or will it also restrict external communications? # Person1: It should apply to all communications, not only in this office between employees, but also any outside communications. # Person2: But sir, many employees use Instant Messaging to communicate with their clients. # Person1: They will just have to change their communication methods. I don't want any - one using Instant Messaging in this office. It wastes too much time! Now, please continue with the memo. Where were we? # Person2: This applies to internal and external communications. # Person1: Yes. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. Any questions regarding this new policy may be directed to department heads. # Person2: Is that all? # Person1: Yes. Please get this memo typed up and distributed to all employees before 4 pm.\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c145fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4f42b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dialogue_coreference.dialogue_coreference import NeuralCoreferenceProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e854111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:23,756 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2022-03-29 14:44:23,806 - INFO - allennlp.common.params - id = lm-masked-language-model\n",
      "2022-03-29 14:44:23,806 - INFO - allennlp.common.params - registered_model_name = masked_language_model\n",
      "2022-03-29 14:44:23,807 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:23,808 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:23,809 - INFO - allennlp.common.params - display_name = BERT-based Masked Language Model\n",
      "2022-03-29 14:44:23,810 - INFO - allennlp.common.params - task_id = masked-language-modeling\n",
      "2022-03-29 14:44:23,811 - INFO - allennlp.common.params - model_usage.archive_file = bert-masked-lm-2020-10-07.tar.gz\n",
      "2022-03-29 14:44:23,812 - INFO - allennlp.common.params - model_usage.training_config = lm/bidirectional_language_model.jsonnet\n",
      "2022-03-29 14:44:23,812 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 14:44:23,813 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:23,814 - INFO - allennlp.common.params - model_details.description = The `MaskedLanguageModel` embeds some input tokens (including some which are masked), contextualizes them, then predicts targets for the masked tokens, computing a loss against known targets.\n",
      "2022-03-29 14:44:23,815 - INFO - allennlp.common.params - model_details.short_description = BERT-based masked language model\n",
      "2022-03-29 14:44:23,816 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-03-29 14:44:23,816 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 14:44:23,817 - INFO - allennlp.common.params - model_details.date = 2020-10-07\n",
      "2022-03-29 14:44:23,818 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:23,819 - INFO - allennlp.common.params - model_details.model_type = BERT\n",
      "2022-03-29 14:44:23,820 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Devlin2019BERTPO,\n",
      "title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},\n",
      "author={J. Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-03-29 14:44:23,820 - INFO - allennlp.common.params - model_details.paper.title = BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n",
      "2022-03-29 14:44:23,821 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:52967399\n",
      "2022-03-29 14:44:23,822 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:23,822 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:23,823 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:23,823 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:23,824 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:23,825 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:23,825 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:23,826 - INFO - allennlp.common.params - metrics.model_performance_measures = Perplexity\n",
      "2022-03-29 14:44:23,826 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:23,827 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:23,828 - INFO - allennlp.common.params - evaluation_data.dataset = BooksCorpus (800M words) and English Wikipedia (2,500M words).\n",
      "2022-03-29 14:44:23,828 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:23,829 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:23,830 - INFO - allennlp.common.params - training_data.dataset = BooksCorpus (800M words) and English Wikipedia (2,500M words).\n",
      "2022-03-29 14:44:23,830 - INFO - allennlp.common.params - training_data.motivation = Document-level corpus is used rather than shuffled sentence-level corpus, to extract long contiguous sequences.\n",
      "2022-03-29 14:44:23,831 - INFO - allennlp.common.params - training_data.preprocessing = For Wikipedia, text passages are extracted and lists, tables, and headers are ignored.\n",
      "2022-03-29 14:44:23,832 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 14:44:23,833 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:23,834 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = BERT demonstrates gender bias in that it thinks the doctor is more likely a man ('his') than a woman ('her'). An important issue in NLP is how to understand and address such biases in our linguistic models.\n",
      "2022-03-29 14:44:23,835 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = NOTE: This was developed for use in a demo, not for training.  It's possible that it will still work for training a masked LM, but it is very likely that some other code would be much more efficient for that.  This `does` compute correct gradients of the loss, because we use that in our demo, so in principle it should be able to train a model, we just don't necessarily endorse that use.\n",
      "2022-03-29 14:44:23,872 - INFO - allennlp.common.params - id = structured-prediction-biaffine-parser\n",
      "2022-03-29 14:44:23,873 - INFO - allennlp.common.params - registered_model_name = biaffine_parser\n",
      "2022-03-29 14:44:23,874 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:23,874 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:23,875 - INFO - allennlp.common.params - display_name = Deep Biaffine Attention for Neural Dependency Parsing\n",
      "2022-03-29 14:44:23,875 - INFO - allennlp.common.params - task_id = dependency-parsing\n",
      "2022-03-29 14:44:23,876 - INFO - allennlp.common.params - model_usage.archive_file = biaffine-dependency-parser-ptb-2020.04.06.tar.gz\n",
      "2022-03-29 14:44:23,877 - INFO - allennlp.common.params - model_usage.training_config = structured_prediction/dependency_parser.jsonnet\n",
      "2022-03-29 14:44:23,877 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 14:44:23,878 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:23,879 - INFO - allennlp.common.params - model_details.description = This dependency parser follows the model of [Deep Biaffine Attention for Neural Dependency Parsing (Dozat and Manning, 2016)](https://api.semanticscholar.org/CorpusID:7942973) .\n",
      "\n",
      "Word representations are generated using a bidirectional LSTM, followed by separate biaffine classifiers for pairs of words, predicting whether a directed arc exists between the two words and the dependency label the arc should have. Decoding can either be done greedily, or the optimal Minimum Spanning Tree can be decoded using Edmond's algorithm by viewing the dependency tree as a MST on a fully connected graph, where nodes are words and edges are scored dependency arcs.\n",
      "2022-03-29 14:44:23,879 - INFO - allennlp.common.params - model_details.short_description = A neural model for dependency parsing using biaffine classifiers on top of a bidirectional LSTM.\n",
      "2022-03-29 14:44:23,880 - INFO - allennlp.common.params - model_details.developed_by = Dozat et al\n",
      "2022-03-29 14:44:23,881 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 14:44:23,881 - INFO - allennlp.common.params - model_details.date = 2020-04-06\n",
      "2022-03-29 14:44:23,882 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:23,882 - INFO - allennlp.common.params - model_details.model_type = None\n",
      "2022-03-29 14:44:23,883 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Dozat2017DeepBA,\n",
      "title={Deep Biaffine Attention for Neural Dependency Parsing},\n",
      "author={Timothy Dozat and Christopher D. Manning},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01734}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:23,884 - INFO - allennlp.common.params - model_details.paper.title = Deep Biaffine Attention for Neural Dependency Parsing (Dozat and Manning, 2016)\n",
      "2022-03-29 14:44:23,884 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:7942973\n",
      "2022-03-29 14:44:23,885 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:23,885 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:23,886 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:23,886 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:23,886 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:23,887 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:23,887 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:23,888 - INFO - allennlp.common.params - metrics.model_performance_measures = Attachment scores and exact matches (UAS, LAS, UEM, LEM)\n",
      "2022-03-29 14:44:23,888 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:23,889 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:23,889 - INFO - allennlp.common.params - evaluation_data.dataset.name = PTB 3.0\n",
      "2022-03-29 14:44:23,890 - INFO - allennlp.common.params - evaluation_data.dataset.notes = The dependency parser was evaluated on the Penn Tree Bank dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can download the PTB data from the LDC website.\n",
      "2022-03-29 14:44:23,890 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = /path/to/dataset\n",
      "2022-03-29 14:44:23,890 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "2022-03-29 14:44:23,891 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:23,891 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:23,891 - INFO - allennlp.common.params - training_data.dataset.name = PTB 3.0\n",
      "2022-03-29 14:44:23,892 - INFO - allennlp.common.params - training_data.dataset.notes = The dependency parser was evaluated on the Penn Tree Bank dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can download the PTB data from the LDC website.\n",
      "2022-03-29 14:44:23,892 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/to/dataset\n",
      "2022-03-29 14:44:23,892 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "2022-03-29 14:44:23,893 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:23,893 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:23,894 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = The parser achieves 95.57% and 94.44% unlabeled and labeled attachement score using gold POS tags. For predicted POS tags, it achieves 94.81% UAS and 92.86% LAS respectively.\n",
      "2022-03-29 14:44:23,894 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:23,895 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:23,895 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:23,928 - INFO - allennlp.common.params - id = vqa-vilbert\n",
      "2022-03-29 14:44:23,929 - INFO - allennlp.common.params - registered_model_name = vqa_vilbert\n",
      "2022-03-29 14:44:23,929 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:23,930 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:23,930 - INFO - allennlp.common.params - display_name = ViLBERT - Visual Question Answering\n",
      "2022-03-29 14:44:23,930 - INFO - allennlp.common.params - task_id = vqa\n",
      "2022-03-29 14:44:23,931 - INFO - allennlp.common.params - model_usage.archive_file = vilbert-vqa-pretrained.2021-03-15.tar.gz\n",
      "2022-03-29 14:44:23,931 - INFO - allennlp.common.params - model_usage.training_config = vision/vilbert_vqa_pretrained.jsonnet\n",
      "2022-03-29 14:44:23,932 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 14:44:23,932 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:23,933 - INFO - allennlp.common.params - model_details.description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "2022-03-29 14:44:23,933 - INFO - allennlp.common.params - model_details.short_description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "2022-03-29 14:44:23,934 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-03-29 14:44:23,934 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 14:44:23,934 - INFO - allennlp.common.params - model_details.date = 2021-03-15\n",
      "2022-03-29 14:44:23,935 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 14:44:23,935 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-03-29 14:44:23,936 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "}\n",
      "2022-03-29 14:44:23,936 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-03-29 14:44:23,937 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-03-29 14:44:23,937 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:23,938 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:23,938 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-03-29 14:44:23,939 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:23,939 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:23,940 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:23,940 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:23,941 - INFO - allennlp.common.params - metrics.model_performance_measures = F1-metric and VQA score\n",
      "2022-03-29 14:44:23,942 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:23,942 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:23,943 - INFO - allennlp.common.params - evaluation_data.dataset.name = VQA dataset\n",
      "2022-03-29 14:44:23,943 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n",
      "2022-03-29 14:44:23,943 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = balanced_real_val\n",
      "2022-03-29 14:44:23,944 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://visualqa.org/\n",
      "2022-03-29 14:44:23,944 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:23,944 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:23,945 - INFO - allennlp.common.params - training_data.dataset.name = VQA dataset\n",
      "2022-03-29 14:44:23,945 - INFO - allennlp.common.params - training_data.dataset.notes = Training requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:23,946 - INFO - allennlp.common.params - training_data.dataset.processed_url = balanced_real_train\n",
      "2022-03-29 14:44:23,946 - INFO - allennlp.common.params - training_data.dataset.url = https://visualqa.org/\n",
      "2022-03-29 14:44:23,946 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:23,947 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:23,947 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 40%\n",
      "VQA: 54%.\n",
      "These scores do not match the performance in the VilBERT paper. Please contact us if you want to match those scores!\n",
      "2022-03-29 14:44:23,948 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:23,948 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:23,949 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:23,981 - INFO - allennlp.common.params - id = roberta-sst\n",
      "2022-03-29 14:44:23,982 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-03-29 14:44:23,982 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:23,983 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:23,983 - INFO - allennlp.common.params - display_name = RoBERTa large\n",
      "2022-03-29 14:44:23,984 - INFO - allennlp.common.params - task_id = sentiment-analysis\n",
      "2022-03-29 14:44:23,984 - INFO - allennlp.common.params - model_usage.archive_file = stanford-sentiment-treebank-roberta.2021-03-11.tar.gz\n",
      "2022-03-29 14:44:23,985 - INFO - allennlp.common.params - model_usage.training_config = classification/stanford_sentiment_treebank_roberta.jsonnet\n",
      "2022-03-29 14:44:23,985 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.4.0 allennlp-models==2.4.0\n",
      "2022-03-29 14:44:23,985 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:23,986 - INFO - allennlp.common.params - model_details.description = This model is trained on RoBERTa large with the binary classification setting of the Stanford Sentiment Treebank. It achieves 95.11% accuracy on the test set.\n",
      "2022-03-29 14:44:23,987 - INFO - allennlp.common.params - model_details.short_description = RoBERTa-based binary classifier for Stanford Sentiment Treebank\n",
      "2022-03-29 14:44:23,987 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-03-29 14:44:23,987 - INFO - allennlp.common.params - model_details.contributed_by = Zhaofeng Wu\n",
      "2022-03-29 14:44:23,988 - INFO - allennlp.common.params - model_details.date = 2020-06-08\n",
      "2022-03-29 14:44:23,988 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:23,989 - INFO - allennlp.common.params - model_details.model_type = RoBERTa large\n",
      "2022-03-29 14:44:23,989 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 14:44:23,990 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-03-29 14:44:23,990 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 14:44:23,991 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:23,991 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:23,992 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:23,992 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:23,993 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:23,993 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:23,994 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:23,994 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 14:44:23,995 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:23,995 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:23,996 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Sentiment Treebank\n",
      "2022-03-29 14:44:23,996 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/test.txt\n",
      "2022-03-29 14:44:23,997 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "2022-03-29 14:44:23,997 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:23,997 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:23,998 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Sentiment Treebank\n",
      "2022-03-29 14:44:23,998 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/train.txt\n",
      "2022-03-29 14:44:23,999 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "2022-03-29 14:44:23,999 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:23,999 - INFO - allennlp.common.params - training_data.preprocessing = Binary classification setting\n",
      "2022-03-29 14:44:24,000 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Accuracy: 95.11% on SST test set.\n",
      "2022-03-29 14:44:24,000 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:24,001 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:24,001 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:24,033 - INFO - allennlp.common.params - id = pair-classification-roberta-mnli\n",
      "2022-03-29 14:44:24,034 - INFO - allennlp.common.params - registered_model_name = basic_classifier\n",
      "2022-03-29 14:44:24,035 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:24,035 - INFO - allennlp.common.params - registered_predictor_name = textual_entailment\n",
      "2022-03-29 14:44:24,036 - INFO - allennlp.common.params - display_name = RoBERTa MNLI\n",
      "2022-03-29 14:44:24,036 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-03-29 14:44:24,037 - INFO - allennlp.common.params - model_usage.archive_file = mnli-roberta.2021-03-11.tar.gz\n",
      "2022-03-29 14:44:24,037 - INFO - allennlp.common.params - model_usage.training_config = pair_classification/mnli_roberta.jsonnet\n",
      "2022-03-29 14:44:24,038 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 14:44:24,038 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:24,039 - INFO - allennlp.common.params - model_details.description = This `Model` implements a basic text classifier. The text is embedded into a text field using a RoBERTa-large model. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space.\n",
      "2022-03-29 14:44:24,040 - INFO - allennlp.common.params - model_details.short_description = RoBERTa finetuned on MNLI.\n",
      "2022-03-29 14:44:24,040 - INFO - allennlp.common.params - model_details.developed_by = Liu et al\n",
      "2022-03-29 14:44:24,041 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 14:44:24,041 - INFO - allennlp.common.params - model_details.date = 2020-07-29\n",
      "2022-03-29 14:44:24,041 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:24,042 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:24,042 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 14:44:24,043 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-03-29 14:44:24,043 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 14:44:24,044 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:24,044 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:24,045 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:24,045 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:24,046 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:24,046 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:24,047 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:24,047 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 14:44:24,048 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:24,048 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:24,049 - INFO - allennlp.common.params - evaluation_data.dataset.name = Multi-genre Natural Language Inference (MultiNLI) dev set\n",
      "2022-03-29 14:44:24,049 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/multinli/multinli_1.0_dev_mismatched.jsonl\n",
      "2022-03-29 14:44:24,050 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://cims.nyu.edu/~sbowman/multinli/\n",
      "2022-03-29 14:44:24,050 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:24,051 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:24,051 - INFO - allennlp.common.params - training_data.dataset.name = Multi-genre Natural Language Inference (MultiNLI) train set\n",
      "2022-03-29 14:44:24,052 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/multinli/multinli_1.0_train.jsonl\n",
      "2022-03-29 14:44:24,052 - INFO - allennlp.common.params - training_data.dataset.url = https://cims.nyu.edu/~sbowman/multinli/\n",
      "2022-03-29 14:44:24,052 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:24,053 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:24,053 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 14:44:24,054 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:24,054 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:24,055 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:24,088 - INFO - allennlp.common.params - id = structured-prediction-constituency-parser\n",
      "2022-03-29 14:44:24,088 - INFO - allennlp.common.params - registered_model_name = constituency_parser\n",
      "2022-03-29 14:44:24,089 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:24,089 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:24,090 - INFO - allennlp.common.params - display_name = Constituency Parser with ELMo embeddings\n",
      "2022-03-29 14:44:24,090 - INFO - allennlp.common.params - task_id = constituency-parsing\n",
      "2022-03-29 14:44:24,091 - INFO - allennlp.common.params - model_usage.archive_file = elmo-constituency-parser-2020.02.10.tar.gz\n",
      "2022-03-29 14:44:24,092 - INFO - allennlp.common.params - model_usage.training_config = structured-prediction/constituency_parser_elmo.jsonnet\n",
      "2022-03-29 14:44:24,092 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 14:44:24,092 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:24,093 - INFO - allennlp.common.params - model_details.description = This is an implementation of a minimal neural model for constituency parsing based on an independent scoring of labels and spans. This `SpanConstituencyParser` simply encodes a sequence of text with a stacked `Seq2SeqEncoder`, extracts span representations using a `SpanExtractor`, and then predicts a label for each span in the sequence. These labels are non-terminal nodes in a constituency parse tree, which we then greedily reconstruct. The model uses ELMo embeddings, which are completely character-based and improves single model performance from 92.6 F1 to 94.11 F1 on the Penn Treebank, a 20% relative error reduction.\n",
      "2022-03-29 14:44:24,094 - INFO - allennlp.common.params - model_details.short_description = Constituency parser with character-based ELMo embeddings\n",
      "2022-03-29 14:44:24,094 - INFO - allennlp.common.params - model_details.developed_by = Joshi et al\n",
      "2022-03-29 14:44:24,095 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 14:44:24,095 - INFO - allennlp.common.params - model_details.date = 2020-02-10\n",
      "2022-03-29 14:44:24,096 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:24,096 - INFO - allennlp.common.params - model_details.model_type = Seq2SeqEncoder\n",
      "2022-03-29 14:44:24,096 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Joshi2018ExtendingAP,\n",
      "title={Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples},\n",
      "author={V. Joshi and Matthew E. Peters and Mark Hopkins},\n",
      "booktitle={ACL},\n",
      "year={2018}}\n",
      "\n",
      "2022-03-29 14:44:24,097 - INFO - allennlp.common.params - model_details.paper.title = Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples\n",
      "2022-03-29 14:44:24,097 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:21712653\n",
      "2022-03-29 14:44:24,098 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:24,098 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:24,099 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:24,099 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:24,100 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:24,100 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:24,101 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:24,102 - INFO - allennlp.common.params - metrics.model_performance_measures = Precision, Recall and F1-score for parse trees (EVALB_bracketing_scorer)\n",
      "2022-03-29 14:44:24,102 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:24,102 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:24,103 - INFO - allennlp.common.params - evaluation_data.dataset.name = PTB 3.0\n",
      "2022-03-29 14:44:24,104 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 14:44:24,104 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = /path/do/dataset\n",
      "2022-03-29 14:44:24,104 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "2022-03-29 14:44:24,105 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:24,105 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:24,106 - INFO - allennlp.common.params - training_data.dataset.name = PTB 3.0\n",
      "2022-03-29 14:44:24,106 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:24,106 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/do/dataset\n",
      "2022-03-29 14:44:24,107 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "2022-03-29 14:44:24,107 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:24,107 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:24,108 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = 94.11 F1 score\n",
      "2022-03-29 14:44:24,108 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:24,109 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:24,109 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:24,143 - INFO - allennlp.common.params - id = tagging-elmo-crf-tagger\n",
      "2022-03-29 14:44:24,144 - INFO - allennlp.common.params - registered_model_name = crf_tagger\n",
      "2022-03-29 14:44:24,144 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:24,145 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:24,145 - INFO - allennlp.common.params - display_name = ELMo-based Named Entity Recognition\n",
      "2022-03-29 14:44:24,146 - INFO - allennlp.common.params - task_id = ner\n",
      "2022-03-29 14:44:24,146 - INFO - allennlp.common.params - model_usage.archive_file = ner-elmo.2021-02-12.tar.gz\n",
      "2022-03-29 14:44:24,147 - INFO - allennlp.common.params - model_usage.training_config = tagging/ner_elmo.jsonnet\n",
      "2022-03-29 14:44:24,147 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 14:44:24,148 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:24,149 - INFO - allennlp.common.params - model_details.description = This model is the baseline model described in [Semi-supervised sequence tagging with bidirectional language models](https://api.semanticscholar.org/CorpusID:7197241). It uses a Gated Recurrent Unit (GRU) character encoder as well as a GRU phrase encoder, and it starts with pretrained GloVe vectors for its token embeddings. It was trained on the CoNLL-2003 NER dataset.\n",
      "2022-03-29 14:44:24,149 - INFO - allennlp.common.params - model_details.short_description = NER tagger using a Gated Recurrent Unit (GRU) character encoder as well as a GRU phrase encoder, with GloVe embeddings.\n",
      "2022-03-29 14:44:24,150 - INFO - allennlp.common.params - model_details.developed_by = Peters et al\n",
      "2022-03-29 14:44:24,150 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 14:44:24,151 - INFO - allennlp.common.params - model_details.date = 2020-02-10\n",
      "2022-03-29 14:44:24,151 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:24,151 - INFO - allennlp.common.params - model_details.model_type = Gated Recurrent Unit (GRU)\n",
      "2022-03-29 14:44:24,152 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Peters2017SemisupervisedST,\n",
      "title={Semi-supervised sequence tagging with bidirectional language models},\n",
      "author={Matthew E. Peters and Waleed Ammar and Chandra Bhagavatula and R. Power},\n",
      "booktitle={ACL},\n",
      "year={2017}}\n",
      "\n",
      "2022-03-29 14:44:24,152 - INFO - allennlp.common.params - model_details.paper.title = Semi-supervised sequence tagging with bidirectional language models\n",
      "2022-03-29 14:44:24,153 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:7197241\n",
      "2022-03-29 14:44:24,153 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:24,153 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:24,154 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:24,154 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:24,155 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:24,155 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:24,156 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:24,156 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "2022-03-29 14:44:24,157 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:24,157 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:24,158 - INFO - allennlp.common.params - evaluation_data.dataset.name = CoNLL-2003 NER dataset\n",
      "2022-03-29 14:44:24,158 - INFO - allennlp.common.params - evaluation_data.dataset.notes = The NER model was evaluated on the CoNLL-2003 NER dataset. Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-03-29 14:44:24,159 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = path/to/dataset\n",
      "2022-03-29 14:44:24,159 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://www.clips.uantwerpen.be/conll2003/ner/\n",
      "2022-03-29 14:44:24,159 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:24,160 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:24,160 - INFO - allennlp.common.params - training_data.dataset.name = CoNLL-2003 NER dataset\n",
      "2022-03-29 14:44:24,161 - INFO - allennlp.common.params - training_data.dataset.notes = The NER model was trained on the CoNLL-2003 NER dataset. Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-03-29 14:44:24,161 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/to/dataset\n",
      "2022-03-29 14:44:24,162 - INFO - allennlp.common.params - training_data.dataset.url = https://www.clips.uantwerpen.be/conll2003/ner/\n",
      "2022-03-29 14:44:24,162 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:24,162 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:24,163 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Achieves 99% accuracy and 96% F1 on the CoNLL-2003 validation set.\n",
      "2022-03-29 14:44:24,163 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:24,164 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:24,164 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = This model is based on ELMo. ELMo is not deterministic, meaning that you will see slight differences every time you run it. Also, ELMo likes to be warmed up, so we recommend processing dummy input before processing real workloads with it.\n",
      "2022-03-29 14:44:24,198 - INFO - allennlp.common.params - id = tagging-fine-grained-crf-tagger\n",
      "2022-03-29 14:44:24,198 - INFO - allennlp.common.params - registered_model_name = crf_tagger\n",
      "2022-03-29 14:44:24,199 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:24,199 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:24,200 - INFO - allennlp.common.params - display_name = Fine Grained Named Entity Recognition\n",
      "2022-03-29 14:44:24,200 - INFO - allennlp.common.params - task_id = ner\n",
      "2022-03-29 14:44:24,201 - INFO - allennlp.common.params - model_usage.archive_file = fine-grained-ner.2021-02-11.tar.gz\n",
      "2022-03-29 14:44:24,202 - INFO - allennlp.common.params - model_usage.training_config = tagging/fine-grained-ner.jsonnet\n",
      "2022-03-29 14:44:24,202 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 14:44:24,202 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:24,203 - INFO - allennlp.common.params - model_details.description = This model identifies a broad range of 16 semantic types in the input text. It is a reimplementation of Lample (2016) and uses a biLSTM with a CRF layer, character embeddings and ELMo embeddings.\n",
      "2022-03-29 14:44:24,204 - INFO - allennlp.common.params - model_details.short_description = This model identifies a broad range of 16 semantic types in the input text. It is a reimplementation of Lample (2016) and uses a biLSTM with a CRF layer, character embeddings and ELMo embeddings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:24,204 - INFO - allennlp.common.params - model_details.developed_by = Lample et al\n",
      "2022-03-29 14:44:24,205 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 14:44:24,205 - INFO - allennlp.common.params - model_details.date = 2020-06-24\n",
      "2022-03-29 14:44:24,205 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:24,206 - INFO - allennlp.common.params - model_details.model_type = BiLSTM\n",
      "2022-03-29 14:44:24,206 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Lample2016NeuralAF,\n",
      "title={Neural Architectures for Named Entity Recognition},\n",
      "author={Guillaume Lample and Miguel Ballesteros and Sandeep Subramanian and K. Kawakami and Chris Dyer},\n",
      "journal={ArXiv},\n",
      "year={2016},\n",
      "volume={abs/1603.01360}}\n",
      "\n",
      "2022-03-29 14:44:24,207 - INFO - allennlp.common.params - model_details.paper.title = Neural Architectures for Named Entity Recognition\n",
      "2022-03-29 14:44:24,207 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:6042994\n",
      "2022-03-29 14:44:24,208 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:24,208 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:24,209 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:24,209 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:24,210 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:24,210 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:24,211 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:24,212 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "2022-03-29 14:44:24,212 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:24,213 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:24,213 - INFO - allennlp.common.params - evaluation_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 14:44:24,214 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-03-29 14:44:24,214 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = /path/do/dataset\n",
      "2022-03-29 14:44:24,214 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 14:44:24,215 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:24,215 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:24,216 - INFO - allennlp.common.params - training_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 14:44:24,216 - INFO - allennlp.common.params - training_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-03-29 14:44:24,216 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/do/dataset\n",
      "2022-03-29 14:44:24,217 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 14:44:24,217 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:24,217 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:24,218 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "Accuracy: 97%\n",
      "F1: 88%\n",
      "2022-03-29 14:44:24,218 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:24,219 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:24,219 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:24,252 - INFO - allennlp.common.params - id = tagging-fine-grained-transformer-crf-tagger\n",
      "2022-03-29 14:44:24,253 - INFO - allennlp.common.params - registered_model_name = crf_tagger\n",
      "2022-03-29 14:44:24,253 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:24,254 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:24,255 - INFO - allennlp.common.params - display_name = Fine Grained Named Entity Recognition with Transformer\n",
      "2022-03-29 14:44:24,255 - INFO - allennlp.common.params - task_id = ner\n",
      "2022-03-29 14:44:24,256 - INFO - allennlp.common.params - model_usage.archive_file = fgner-transformer.2021-02-11.tar.gz\n",
      "2022-03-29 14:44:24,256 - INFO - allennlp.common.params - model_usage.training_config = tagging/fgner_transformer.jsonnet\n",
      "2022-03-29 14:44:24,257 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 14:44:24,257 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:24,258 - INFO - allennlp.common.params - model_details.description = Fine-grained NER model\n",
      "2022-03-29 14:44:24,259 - INFO - allennlp.common.params - model_details.short_description = Fine-grained NER model\n",
      "2022-03-29 14:44:24,259 - INFO - allennlp.common.params - model_details.developed_by = None\n",
      "2022-03-29 14:44:24,260 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 14:44:24,260 - INFO - allennlp.common.params - model_details.date = 2020-07-14\n",
      "2022-03-29 14:44:24,261 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:24,261 - INFO - allennlp.common.params - model_details.model_type = Transformer\n",
      "2022-03-29 14:44:24,262 - INFO - allennlp.common.params - model_details.paper = None\n",
      "2022-03-29 14:44:24,262 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:24,263 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:24,264 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:24,264 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:24,265 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:24,265 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:24,266 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:24,266 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "2022-03-29 14:44:24,267 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:24,267 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:24,268 - INFO - allennlp.common.params - evaluation_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 14:44:24,268 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-03-29 14:44:24,268 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 14:44:24,269 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:24,269 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:24,270 - INFO - allennlp.common.params - training_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 14:44:24,270 - INFO - allennlp.common.params - training_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-03-29 14:44:24,270 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 14:44:24,271 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:24,271 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:24,272 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "Accuracy: 98%\n",
      "F1: 88%\n",
      "2022-03-29 14:44:24,273 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:24,274 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:24,274 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:24,304 - INFO - allennlp.common.params - id = mc-roberta-commonsenseqa\n",
      "2022-03-29 14:44:24,305 - INFO - allennlp.common.params - registered_model_name = transformer_mc\n",
      "2022-03-29 14:44:24,305 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:24,306 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:24,307 - INFO - allennlp.common.params - display_name = RoBERTa Common Sense QA\n",
      "2022-03-29 14:44:24,307 - INFO - allennlp.common.params - task_id = mc\n",
      "2022-03-29 14:44:24,308 - INFO - allennlp.common.params - model_usage.archive_file = commonsenseqa.2020-07-08.tar.gz\n",
      "2022-03-29 14:44:24,309 - INFO - allennlp.common.params - model_usage.training_config = mc/commonsenseqa.jsonnet\n",
      "2022-03-29 14:44:24,310 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 14:44:24,310 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:24,311 - INFO - allennlp.common.params - model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n",
      "2022-03-29 14:44:24,312 - INFO - allennlp.common.params - model_details.short_description = RoBERTa-based multiple choice model for CommonSenseQA.\n",
      "2022-03-29 14:44:24,313 - INFO - allennlp.common.params - model_details.developed_by = Liu et al\n",
      "2022-03-29 14:44:24,313 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 14:44:24,314 - INFO - allennlp.common.params - model_details.date = 2020-07-08\n",
      "2022-03-29 14:44:24,314 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:24,315 - INFO - allennlp.common.params - model_details.model_type = RoBERTa large\n",
      "2022-03-29 14:44:24,315 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 14:44:24,316 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-03-29 14:44:24,316 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 14:44:24,316 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:24,317 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:24,317 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:24,318 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:24,318 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:24,319 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:24,319 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:24,320 - INFO - allennlp.common.params - metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n",
      "2022-03-29 14:44:24,320 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:24,320 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:24,321 - INFO - allennlp.common.params - evaluation_data.dataset.name = CommonSenseQA (validation set)\n",
      "2022-03-29 14:44:24,321 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 14:44:24,322 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/jonathanherzig/commonsenseqa\n",
      "2022-03-29 14:44:24,322 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:24,322 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:24,323 - INFO - allennlp.common.params - training_data.dataset.name = CommonSenseQA (train set)\n",
      "2022-03-29 14:44:24,323 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 14:44:24,324 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/jonathanherzig/commonsenseqa\n",
      "2022-03-29 14:44:24,324 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:24,324 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:24,325 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 14:44:24,325 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:24,326 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:24,326 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:24,359 - INFO - allennlp.common.params - id = pair-classification-roberta-snli\n",
      "2022-03-29 14:44:24,360 - INFO - allennlp.common.params - registered_model_name = basic_classifier\n",
      "2022-03-29 14:44:24,360 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:24,361 - INFO - allennlp.common.params - registered_predictor_name = textual_entailment\n",
      "2022-03-29 14:44:24,361 - INFO - allennlp.common.params - display_name = RoBERTa SNLI\n",
      "2022-03-29 14:44:24,362 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-03-29 14:44:24,363 - INFO - allennlp.common.params - model_usage.archive_file = snli-roberta.2021-03-11.tar.gz\n",
      "2022-03-29 14:44:24,363 - INFO - allennlp.common.params - model_usage.training_config = pair_classification/snli_roberta.jsonnet\n",
      "2022-03-29 14:44:24,364 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 14:44:24,364 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:24,365 - INFO - allennlp.common.params - model_details.description = This `Model` implements a basic text classifier. The text is embedded into a text field using a RoBERTa-large model. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space.\n",
      "2022-03-29 14:44:24,366 - INFO - allennlp.common.params - model_details.short_description = RoBERTa finetuned on SNLI.\n",
      "2022-03-29 14:44:24,366 - INFO - allennlp.common.params - model_details.developed_by = Liu et al\n",
      "2022-03-29 14:44:24,367 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 14:44:24,367 - INFO - allennlp.common.params - model_details.date = 2020-07-29\n",
      "2022-03-29 14:44:24,368 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:24,368 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-03-29 14:44:24,369 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 14:44:24,369 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-03-29 14:44:24,370 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 14:44:24,370 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:24,371 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:24,371 - INFO - allennlp.common.params - intended_use.primary_uses = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:24,371 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:24,372 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:24,372 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:24,373 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:24,373 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 14:44:24,373 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:24,374 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:24,374 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n",
      "2022-03-29 14:44:24,375 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "2022-03-29 14:44:24,375 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 14:44:24,376 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:24,376 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:24,377 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-03-29 14:44:24,377 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-03-29 14:44:24,377 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 14:44:24,378 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:24,378 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:24,379 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Net Neutral: 0.49562665820121765, Fraction Neutral: 0.5068705677986145, Threshold:0.5: 0.47600528597831726, Threshold:0.7: 0.3036800026893616\n",
      "2022-03-29 14:44:24,379 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:24,380 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:24,380 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:24,413 - INFO - allennlp.common.params - id = nlvr2-vilbert\n",
      "2022-03-29 14:44:24,413 - INFO - allennlp.common.params - registered_model_name = nlvr2\n",
      "2022-03-29 14:44:24,414 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:24,415 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:24,415 - INFO - allennlp.common.params - display_name = Visual Entailment - NLVR2\n",
      "2022-03-29 14:44:24,416 - INFO - allennlp.common.params - task_id = nlvr2\n",
      "2022-03-29 14:44:24,416 - INFO - allennlp.common.params - model_usage.archive_file = vilbert-nlvr2-head-2021.06.01.tar.gz\n",
      "2022-03-29 14:44:24,417 - INFO - allennlp.common.params - model_usage.training_config = vilbert_nlvr2_pretrained.jsonnet\n",
      "2022-03-29 14:44:24,417 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp>=2.5.1 allennlp-models>=2.5.1\n",
      "2022-03-29 14:44:24,418 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:24,418 - INFO - allennlp.common.params - model_details.description = This model uses a VilBERT-based backbone with an NLVR2-specific model head. The image features are obtained using the ResNet backbone and Faster RCNN (region detection).\n",
      "2022-03-29 14:44:24,419 - INFO - allennlp.common.params - model_details.short_description = ViLBERT-based model for Visual Entailment.\n",
      "2022-03-29 14:44:24,420 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-03-29 14:44:24,420 - INFO - allennlp.common.params - model_details.contributed_by = Jacob Morrison\n",
      "2022-03-29 14:44:24,421 - INFO - allennlp.common.params - model_details.date = 2021-05-27\n",
      "2022-03-29 14:44:24,421 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 14:44:24,421 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-03-29 14:44:24,422 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "2022-03-29 14:44:24,422 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-03-29 14:44:24,423 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-03-29 14:44:24,423 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:24,424 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:24,425 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-03-29 14:44:24,425 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:24,426 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:24,426 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:24,426 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:24,427 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and F1-score\n",
      "2022-03-29 14:44:24,427 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:24,428 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:24,428 - INFO - allennlp.common.params - evaluation_data.dataset.name = Natural Language for Visual Reasoning For Real dev set\n",
      "2022-03-29 14:44:24,429 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste.\n",
      "2022-03-29 14:44:24,429 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/lil-lab/nlvr/tree/master/nlvr2\n",
      "2022-03-29 14:44:24,429 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:24,430 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:24,430 - INFO - allennlp.common.params - training_data.dataset.name = Natural Language for Visual Reasoning For Real train set\n",
      "2022-03-29 14:44:24,431 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/lil-lab/nlvr/tree/master/nlvr2\n",
      "2022-03-29 14:44:24,431 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:24,431 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:24,432 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 33.7%\n",
      "Accuracy: 50.8%.\n",
      "These scores do not match the performance in the 12-in-1 paper because this was trained as a standalone task, not as part of a multitask setup. Please contact us if you want to match those scores!\n",
      "2022-03-29 14:44:24,432 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:24,433 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:24,433 - INFO - allennlp.common.params - model_caveats_and_recommendations = None\n",
      "2022-03-29 14:44:24,465 - INFO - allennlp.common.params - id = nlvr2-vilbert\n",
      "2022-03-29 14:44:24,466 - INFO - allennlp.common.params - registered_model_name = nlvr2\n",
      "2022-03-29 14:44:24,467 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:24,467 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:24,468 - INFO - allennlp.common.params - display_name = Visual Entailment - NLVR2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:24,468 - INFO - allennlp.common.params - task_id = nlvr2\n",
      "2022-03-29 14:44:24,469 - INFO - allennlp.common.params - model_usage.archive_file = vilbert-nlvr2-2021.06.01.tar.gz\n",
      "2022-03-29 14:44:24,469 - INFO - allennlp.common.params - model_usage.training_config = vilbert_nlvr2_pretrained.jsonnet\n",
      "2022-03-29 14:44:24,470 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp>=2.5.1 allennlp-models>=2.5.1\n",
      "2022-03-29 14:44:24,471 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:24,471 - INFO - allennlp.common.params - model_details.description = This model is based on the ViLBERT multitask architecture. The image features are obtained using the ResNet backbone and Faster RCNN (region detection).\n",
      "2022-03-29 14:44:24,472 - INFO - allennlp.common.params - model_details.short_description = ViLBERT-based model for Visual Entailment.\n",
      "2022-03-29 14:44:24,472 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-03-29 14:44:24,473 - INFO - allennlp.common.params - model_details.contributed_by = Jacob Morrison\n",
      "2022-03-29 14:44:24,473 - INFO - allennlp.common.params - model_details.date = 2021-05-27\n",
      "2022-03-29 14:44:24,474 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 14:44:24,474 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-03-29 14:44:24,475 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "2022-03-29 14:44:24,475 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-03-29 14:44:24,476 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-03-29 14:44:24,476 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:24,476 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:24,477 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-03-29 14:44:24,477 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:24,478 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:24,478 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:24,479 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:24,479 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and F1-score\n",
      "2022-03-29 14:44:24,480 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:24,480 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:24,481 - INFO - allennlp.common.params - evaluation_data.dataset.name = Natural Language for Visual Reasoning For Real dev set\n",
      "2022-03-29 14:44:24,481 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste.\n",
      "2022-03-29 14:44:24,481 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/lil-lab/nlvr/tree/master/nlvr2\n",
      "2022-03-29 14:44:24,482 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:24,482 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:24,483 - INFO - allennlp.common.params - training_data.dataset.name = Natural Language for Visual Reasoning For Real train set\n",
      "2022-03-29 14:44:24,483 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/lil-lab/nlvr/tree/master/nlvr2\n",
      "2022-03-29 14:44:24,484 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:24,484 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:24,485 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 33.7%\n",
      "Accuracy: 50.8%.\n",
      "These scores do not match the performance in the 12-in-1 paper because this was trained as a standalone task, not as part of a multitask setup. Please contact us if you want to match those scores!\n",
      "2022-03-29 14:44:24,485 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:24,486 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:24,486 - INFO - allennlp.common.params - model_caveats_and_recommendations = None\n",
      "2022-03-29 14:44:24,519 - INFO - allennlp.common.params - id = pair-classification-esim\n",
      "2022-03-29 14:44:24,519 - INFO - allennlp.common.params - registered_model_name = esim\n",
      "2022-03-29 14:44:24,520 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:24,520 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:24,521 - INFO - allennlp.common.params - display_name = Enhanced LSTM for Natural Language Inference\n",
      "2022-03-29 14:44:24,521 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-03-29 14:44:24,522 - INFO - allennlp.common.params - model_usage.archive_file = esim-elmo-2020.11.11.tar.gz\n",
      "2022-03-29 14:44:24,523 - INFO - allennlp.common.params - model_usage.training_config = esim.jsonnet\n",
      "2022-03-29 14:44:24,523 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 14:44:24,524 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:24,524 - INFO - allennlp.common.params - model_details.description = This `Model` implements the ESIM model, which is a sequential neural inference model based on chain LSTMs.\n",
      "2022-03-29 14:44:24,525 - INFO - allennlp.common.params - model_details.short_description = Enhanced LSTM trained on SNLI.\n",
      "2022-03-29 14:44:24,525 - INFO - allennlp.common.params - model_details.developed_by = Chen et al\n",
      "2022-03-29 14:44:24,526 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 14:44:24,526 - INFO - allennlp.common.params - model_details.date = 2020-04-09\n",
      "2022-03-29 14:44:24,527 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:24,527 - INFO - allennlp.common.params - model_details.model_type = LSTM\n",
      "2022-03-29 14:44:24,528 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Chen2017EnhancedLF,\n",
      "title={Enhanced LSTM for Natural Language Inference},\n",
      "author={Qian Chen and Xiao-Dan Zhu and Z. Ling and Si Wei and Hui Jiang and Diana Inkpen},\n",
      "booktitle={ACL},\n",
      "year={2017}}\n",
      "\n",
      "2022-03-29 14:44:24,528 - INFO - allennlp.common.params - model_details.paper.title = Enhanced LSTM for Natural Language Inference\n",
      "2022-03-29 14:44:24,528 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:34032948\n",
      "2022-03-29 14:44:24,529 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:24,529 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:24,530 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:24,530 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:24,531 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:24,531 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:24,532 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:24,532 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 14:44:24,533 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:24,533 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:24,534 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:24,534 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "2022-03-29 14:44:24,535 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 14:44:24,535 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:24,535 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:24,536 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-03-29 14:44:24,537 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-03-29 14:44:24,537 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 14:44:24,537 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:24,538 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:24,538 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 14:44:24,539 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:24,539 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:24,540 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:24,572 - INFO - allennlp.common.params - id = glove-sst\n",
      "2022-03-29 14:44:24,573 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-03-29 14:44:24,573 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:24,574 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:24,574 - INFO - allennlp.common.params - display_name = GLoVe-LSTM\n",
      "2022-03-29 14:44:24,575 - INFO - allennlp.common.params - task_id = sentiment-analysis\n",
      "2022-03-29 14:44:24,575 - INFO - allennlp.common.params - model_usage.archive_file = basic_stanford_sentiment_treebank-2020.06.09.tar.gz\n",
      "2022-03-29 14:44:24,576 - INFO - allennlp.common.params - model_usage.training_config = classification/basic_stanford_sentiment_treebank.jsonnet\n",
      "2022-03-29 14:44:24,576 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 14:44:24,577 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:24,577 - INFO - allennlp.common.params - model_details.description = This model uses GloVe embeddings and is trained on the binary classification setting of the Stanford Sentiment Treebank. It achieves about 87% on the test set.\n",
      "2022-03-29 14:44:24,578 - INFO - allennlp.common.params - model_details.short_description = LSTM binary classifier with GloVe embeddings.\n",
      "2022-03-29 14:44:24,578 - INFO - allennlp.common.params - model_details.developed_by = None\n",
      "2022-03-29 14:44:24,579 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 14:44:24,579 - INFO - allennlp.common.params - model_details.date = 2020-06-09\n",
      "2022-03-29 14:44:24,580 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:24,580 - INFO - allennlp.common.params - model_details.model_type = LSTM\n",
      "2022-03-29 14:44:24,581 - INFO - allennlp.common.params - model_details.paper = None\n",
      "2022-03-29 14:44:24,581 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:24,582 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:24,582 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:24,583 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:24,583 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:24,584 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:24,584 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:24,584 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 14:44:24,585 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:24,585 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:24,586 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Sentiment Treebank\n",
      "2022-03-29 14:44:24,586 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/test.txt\n",
      "2022-03-29 14:44:24,587 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "2022-03-29 14:44:24,587 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:24,587 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:24,588 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Sentiment Treebank\n",
      "2022-03-29 14:44:24,588 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/train.txt\n",
      "2022-03-29 14:44:24,589 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "2022-03-29 14:44:24,589 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:24,589 - INFO - allennlp.common.params - training_data.preprocessing = Binary classification setting\n",
      "2022-03-29 14:44:24,590 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Accuracy: 87% on SST test set.\n",
      "2022-03-29 14:44:24,590 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:24,591 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:24,592 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:24,623 - INFO - allennlp.common.params - id = generation-bart\n",
      "2022-03-29 14:44:24,623 - INFO - allennlp.common.params - registered_model_name = bart\n",
      "2022-03-29 14:44:24,624 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:24,624 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:24,625 - INFO - allennlp.common.params - display_name = BART\n",
      "2022-03-29 14:44:24,625 - INFO - allennlp.common.params - task_id = None\n",
      "2022-03-29 14:44:24,626 - INFO - allennlp.common.params - model_usage.archive_file = bart-2020.07.25.tar.gz\n",
      "2022-03-29 14:44:24,626 - INFO - allennlp.common.params - model_usage.training_config = generation/bart_cnn_dm.jsonnet\n",
      "2022-03-29 14:44:24,627 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 14:44:24,627 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:24,628 - INFO - allennlp.common.params - model_details.description = The BART model here uses a language modeling head, and therefore can be used for generation. The BART encoder, implemented as a `Seq2SeqEncoder`, which assumes it operates on already embedded inputs.  This means that we remove the token and position embeddings from BART in this module.  For the typical use case of using BART to encode inputs to your model (where we include the token and position embeddings from BART), you should use `PretrainedTransformerEmbedder(bart_model_name, sub_module=\"encoder\")` instead of this.\n",
      "2022-03-29 14:44:24,629 - INFO - allennlp.common.params - model_details.short_description = BART with a language model head for generation.\n",
      "2022-03-29 14:44:24,629 - INFO - allennlp.common.params - model_details.developed_by = Lewis et al\n",
      "2022-03-29 14:44:24,630 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 14:44:24,630 - INFO - allennlp.common.params - model_details.date = 2020-07-25\n",
      "2022-03-29 14:44:24,631 - INFO - allennlp.common.params - model_details.version = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:24,632 - INFO - allennlp.common.params - model_details.model_type = BART\n",
      "2022-03-29 14:44:24,633 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lewis2020BARTDS,\n",
      "title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},\n",
      "author={M. Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and A. Mohamed and Omer Levy and Ves Stoyanov and L. Zettlemoyer},\n",
      "booktitle={ACL},\n",
      "year={2020}}\n",
      "\n",
      "2022-03-29 14:44:24,633 - INFO - allennlp.common.params - model_details.paper.title = BART: Denosing Sequence-to-Sequence Pre-training for Natural Language Generation,Translation, and Comprehension\n",
      "2022-03-29 14:44:24,634 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:204960716\n",
      "2022-03-29 14:44:24,635 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:24,635 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:24,636 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:24,636 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:24,637 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:24,638 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:24,638 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:24,639 - INFO - allennlp.common.params - metrics.model_performance_measures = ROUGE and BLEU\n",
      "2022-03-29 14:44:24,639 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:24,640 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:24,640 - INFO - allennlp.common.params - evaluation_data.dataset.name = CNN/DailyMail\n",
      "2022-03-29 14:44:24,641 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 14:44:24,641 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/abisee/cnn-dailymail\n",
      "2022-03-29 14:44:24,642 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:24,642 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:24,643 - INFO - allennlp.common.params - training_data.dataset.name = CNN/DailyMail\n",
      "2022-03-29 14:44:24,644 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 14:44:24,644 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/abisee/cnn-dailymail\n",
      "2022-03-29 14:44:24,645 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:24,645 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:24,646 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 14:44:24,646 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:24,647 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:24,647 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:24,678 - INFO - allennlp.common.params - id = mc-roberta-piqa\n",
      "2022-03-29 14:44:24,678 - INFO - allennlp.common.params - registered_model_name = transformer_mc\n",
      "2022-03-29 14:44:24,679 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:24,680 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:24,680 - INFO - allennlp.common.params - display_name = Physical Interaction Question Answering\n",
      "2022-03-29 14:44:24,681 - INFO - allennlp.common.params - task_id = mc\n",
      "2022-03-29 14:44:24,681 - INFO - allennlp.common.params - model_usage.archive_file = piqa.2020-07-08.tar.gz\n",
      "2022-03-29 14:44:24,682 - INFO - allennlp.common.params - model_usage.training_config = mc/piqa.jsonnet\n",
      "2022-03-29 14:44:24,682 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 14:44:24,683 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:24,684 - INFO - allennlp.common.params - model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n",
      "2022-03-29 14:44:24,684 - INFO - allennlp.common.params - model_details.short_description = RoBERTa-based multiple choice model for PIQA.\n",
      "2022-03-29 14:44:24,685 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-03-29 14:44:24,685 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 14:44:24,686 - INFO - allennlp.common.params - model_details.date = 2020-07-08\n",
      "2022-03-29 14:44:24,686 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:24,687 - INFO - allennlp.common.params - model_details.model_type = RoBERTa large\n",
      "2022-03-29 14:44:24,687 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 14:44:24,688 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-03-29 14:44:24,688 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 14:44:24,688 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:24,688 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:24,689 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:24,690 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:24,690 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:24,690 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:24,691 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:24,691 - INFO - allennlp.common.params - metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n",
      "2022-03-29 14:44:24,692 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:24,692 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:24,693 - INFO - allennlp.common.params - evaluation_data.dataset.name = PIQA (validation set)\n",
      "2022-03-29 14:44:24,693 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 14:44:24,693 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://yonatanbisk.com/piqa/\n",
      "2022-03-29 14:44:24,694 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:24,694 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:24,695 - INFO - allennlp.common.params - training_data.dataset.name = PIQA (train set)\n",
      "2022-03-29 14:44:24,695 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 14:44:24,696 - INFO - allennlp.common.params - training_data.dataset.url = https://yonatanbisk.com/piqa/\n",
      "2022-03-29 14:44:24,696 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:24,696 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:24,697 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 14:44:24,697 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:24,698 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:24,698 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:24,733 - INFO - allennlp.common.params - id = rc-bidaf\n",
      "2022-03-29 14:44:24,733 - INFO - allennlp.common.params - registered_model_name = bidaf\n",
      "2022-03-29 14:44:24,734 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:24,734 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:24,735 - INFO - allennlp.common.params - display_name = BiDAF\n",
      "2022-03-29 14:44:24,736 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-03-29 14:44:24,736 - INFO - allennlp.common.params - model_usage.archive_file = bidaf-model-2020.03.19.tar.gz\n",
      "2022-03-29 14:44:24,737 - INFO - allennlp.common.params - model_usage.training_config = rc/bidaf.jsonnet\n",
      "2022-03-29 14:44:24,737 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 14:44:24,738 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:24,739 - INFO - allennlp.common.params - model_details.description = This is an implementation of the BiDAF model with GloVe embeddings. The basic layout is pretty simple: encode words as a combination of word embeddings and a character-level encoder, pass the word representations through a bi-LSTM/GRU, use a matrix of attentions to put question information into the passage word representations (this is the only part that is at all non-standard), pass this through another few layers of bi-LSTMs/GRUs, and do a softmax over span start and span end.\n",
      "2022-03-29 14:44:24,739 - INFO - allennlp.common.params - model_details.short_description = BiDAF model with GloVe embeddings.\n",
      "2022-03-29 14:44:24,740 - INFO - allennlp.common.params - model_details.developed_by = Seo et al\n",
      "2022-03-29 14:44:24,740 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 14:44:24,741 - INFO - allennlp.common.params - model_details.date = 2020-03-19\n",
      "2022-03-29 14:44:24,741 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:24,742 - INFO - allennlp.common.params - model_details.model_type = BiDAF\n",
      "2022-03-29 14:44:24,742 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Seo2017BidirectionalAF,\n",
      "title={Bidirectional Attention Flow for Machine Comprehension},\n",
      "author={Minjoon Seo and Aniruddha Kembhavi and Ali Farhadi and Hannaneh Hajishirzi},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01603}}\n",
      "\n",
      "2022-03-29 14:44:24,742 - INFO - allennlp.common.params - model_details.paper.title = Bidirectional Attention Flow for Machine Comprehension\n",
      "2022-03-29 14:44:24,743 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:8535316\n",
      "2022-03-29 14:44:24,743 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:24,743 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:24,744 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:24,744 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:24,745 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:24,745 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:24,745 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:24,746 - INFO - allennlp.common.params - metrics.model_performance_measures = Start, end, and overall span accuracy, Exact Match, F1 score\n",
      "2022-03-29 14:44:24,746 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:24,747 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:24,747 - INFO - allennlp.common.params - evaluation_data.dataset.name = SQuAD dev set\n",
      "2022-03-29 14:44:24,748 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v1.1.json\n",
      "2022-03-29 14:44:24,748 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "2022-03-29 14:44:24,748 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:24,749 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:24,750 - INFO - allennlp.common.params - training_data.dataset.name = SQuAD training set\n",
      "2022-03-29 14:44:24,750 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v1.1.json\n",
      "2022-03-29 14:44:24,750 - INFO - allennlp.common.params - training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "2022-03-29 14:44:24,751 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:24,751 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:24,752 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "Start accuracy: 61%\n",
      "End accuracy: 66%\n",
      "Overall span accuracy: 52%\n",
      "Exact match: 66%\n",
      "F1: 76%\n",
      "2022-03-29 14:44:24,752 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:24,752 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:24,753 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:24,788 - INFO - allennlp.common.params - id = pair-classification-adversarial-binary-gender-bias-mitigated-roberta-snli\n",
      "2022-03-29 14:44:24,788 - INFO - allennlp.common.params - registered_model_name = adversarial_bias_mitigator\n",
      "2022-03-29 14:44:24,789 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:24,790 - INFO - allennlp.common.params - registered_predictor_name = textual_entailment\n",
      "2022-03-29 14:44:24,790 - INFO - allennlp.common.params - display_name = Adversarial Binary Gender Bias-Mitigated RoBERTa SNLI\n",
      "2022-03-29 14:44:24,791 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-03-29 14:44:24,792 - INFO - allennlp.common.params - model_usage.archive_file = adversarial-binary-gender-bias-mitigated-snli-roberta.2021-06-17.tar.gz\n",
      "2022-03-29 14:44:24,792 - INFO - allennlp.common.params - model_usage.training_config = pair_classification/adversarial_binary_gender_bias_mitigated_snli_roberta.jsonnet\n",
      "2022-03-29 14:44:24,793 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp allennlp-models\n",
      "2022-03-29 14:44:24,793 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:24,794 - INFO - allennlp.common.params - model_details.description = This `Model` implements a basic text classifier and feedforward regression adversary with an adversarial bias mitigator wrapper. The text is embedded into a text field using a RoBERTa-large model. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space. Subsequently, a `FeedForwardRegressionAdversary` attempts to recover the coefficient of the static text embedding in the binary gender bias subspace. While the adversary's parameter updates are computed normally, the predictor's parameters are updated such that the predictor will not aid the adversary and will make it more difficult for the adversary to recover protected variables.\n",
      "2022-03-29 14:44:24,794 - INFO - allennlp.common.params - model_details.short_description = RoBERTa finetuned on SNLI with adversarial binary gender bias mitigation.\n",
      "2022-03-29 14:44:24,795 - INFO - allennlp.common.params - model_details.developed_by = Zhang at al\n",
      "2022-03-29 14:44:24,795 - INFO - allennlp.common.params - model_details.contributed_by = Arjun Subramonian\n",
      "2022-03-29 14:44:24,795 - INFO - allennlp.common.params - model_details.date = 2021-06-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:24,796 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:24,796 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-03-29 14:44:24,797 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Zhang2018MitigatingUB,\n",
      "title={Mitigating Unwanted Biases with Adversarial Learning},\n",
      "author={B. H. Zhang and B. Lemoine and Margaret Mitchell},\n",
      "journal={Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},\n",
      "year={2018}\n",
      "}\n",
      "2022-03-29 14:44:24,797 - INFO - allennlp.common.params - model_details.paper.title = Mitigating Unwanted Biases with Adversarial Learning\n",
      "2022-03-29 14:44:24,797 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:9424845\n",
      "2022-03-29 14:44:24,798 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:24,798 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:24,799 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:24,799 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:24,799 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:24,800 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:24,800 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:24,801 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy, Net Neutral, Fraction Neutral, Threshold:tau\n",
      "2022-03-29 14:44:24,801 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:24,802 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:24,802 - INFO - allennlp.common.params - evaluation_data.dataset.name = On Measuring and Mitigating Biased Gender-Occupation Inferences SNLI Dataset\n",
      "2022-03-29 14:44:24,803 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://storage.googleapis.com/allennlp-public-models/binary-gender-bias-mitigated-snli-dataset.jsonl\n",
      "2022-03-29 14:44:24,803 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/sunipa/On-Measuring-and-Mitigating-Biased-Inferences-of-Word-Embeddings\n",
      "2022-03-29 14:44:24,804 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:24,804 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:24,805 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-03-29 14:44:24,805 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-03-29 14:44:24,805 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 14:44:24,806 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:24,806 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:24,807 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Net Neutral: 0.613096454815352, Fraction Neutral: 0.6704967487937075, Threshold:0.5: 0.6637061892722586, Threshold:0.7: 0.49490217463150243\n",
      "2022-03-29 14:44:24,807 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:24,808 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = Adversarial binary gender bias mitigation has been applied to this model. Nonetheless, the model will contain residual biases and bias mitigation does not guarantee entirely bias-free inferences.\n",
      "2022-03-29 14:44:24,809 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:24,841 - INFO - allennlp.common.params - id = rc-nmn\n",
      "2022-03-29 14:44:24,842 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-03-29 14:44:24,842 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:24,843 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:24,844 - INFO - allennlp.common.params - display_name = Neural Module Network (NMN)\n",
      "2022-03-29 14:44:24,844 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-03-29 14:44:24,845 - INFO - allennlp.common.params - model_usage.archive_file = drop-nmn-2020.04.04.tar.gz\n",
      "2022-03-29 14:44:24,845 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-03-29 14:44:24,846 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 14:44:24,846 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:24,847 - INFO - allennlp.common.params - model_details.description = A neural module network trained on DROP.\n",
      "2022-03-29 14:44:24,847 - INFO - allennlp.common.params - model_details.short_description = A neural module network trained on DROP.\n",
      "2022-03-29 14:44:24,848 - INFO - allennlp.common.params - model_details.developed_by = Andreas et al\n",
      "2022-03-29 14:44:24,849 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 14:44:24,849 - INFO - allennlp.common.params - model_details.date = 2020-04-04\n",
      "2022-03-29 14:44:24,850 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:24,850 - INFO - allennlp.common.params - model_details.model_type = Neural Module Network\n",
      "2022-03-29 14:44:24,851 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Andreas2016NeuralMN,\n",
      "title={Neural Module Networks},\n",
      "author={Jacob Andreas and Marcus Rohrbach and Trevor Darrell and D. Klein},\n",
      "journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n",
      "year={2016},\n",
      "pages={39-48}}\n",
      "\n",
      "2022-03-29 14:44:24,851 - INFO - allennlp.common.params - model_details.paper.title = Neural Module Networks\n",
      "2022-03-29 14:44:24,852 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:5276660\n",
      "2022-03-29 14:44:24,853 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:24,853 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:24,854 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:24,854 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:24,855 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:24,855 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:24,856 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:24,856 - INFO - allennlp.common.params - metrics.model_performance_measures = None\n",
      "2022-03-29 14:44:24,857 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:24,857 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:24,858 - INFO - allennlp.common.params - evaluation_data.dataset = None\n",
      "2022-03-29 14:44:24,858 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:24,858 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:24,859 - INFO - allennlp.common.params - training_data.dataset.name = DROP\n",
      "2022-03-29 14:44:24,859 - INFO - allennlp.common.params - training_data.dataset.url = https://allennlp.org/drop\n",
      "2022-03-29 14:44:24,860 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:24,860 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:24,861 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 14:44:24,861 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:24,862 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:24,862 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:24,892 - INFO - allennlp.common.params - id = structured-prediction-srl\n",
      "2022-03-29 14:44:24,892 - INFO - allennlp.common.params - registered_model_name = srl\n",
      "2022-03-29 14:44:24,893 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:24,894 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:24,894 - INFO - allennlp.common.params - display_name = Open Information Extraction\n",
      "2022-03-29 14:44:24,895 - INFO - allennlp.common.params - task_id = srl\n",
      "2022-03-29 14:44:24,895 - INFO - allennlp.common.params - model_usage.archive_file = openie-model.2020.03.26.tar.gz\n",
      "2022-03-29 14:44:24,896 - INFO - allennlp.common.params - model_usage.training_config = structured-prediction/srl.jsonnet\n",
      "2022-03-29 14:44:24,896 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 14:44:24,897 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:24,898 - INFO - allennlp.common.params - model_details.description = A reimplementation of a deep BiLSTM sequence prediction model (Stanovsky et al., 2018).\n",
      "2022-03-29 14:44:24,898 - INFO - allennlp.common.params - model_details.short_description = A reimplementation of a deep BiLSTM sequence prediction model (Stanovsky et al., 2018)\n",
      "2022-03-29 14:44:24,898 - INFO - allennlp.common.params - model_details.developed_by = Stanovsky et al\n",
      "2022-03-29 14:44:24,899 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 14:44:24,899 - INFO - allennlp.common.params - model_details.date = 2020-03-26\n",
      "2022-03-29 14:44:24,900 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:24,900 - INFO - allennlp.common.params - model_details.model_type = BiLSTM\n",
      "2022-03-29 14:44:24,901 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Stanovsky2018SupervisedOI,\n",
      "title={Supervised Open Information Extraction},\n",
      "author={Gabriel Stanovsky and Julian Michael and Luke Zettlemoyer and I. Dagan},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2018}}\n",
      "\n",
      "2022-03-29 14:44:24,901 - INFO - allennlp.common.params - model_details.paper.title = Supervised Open Information Extraction\n",
      "2022-03-29 14:44:24,902 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:44145304\n",
      "2022-03-29 14:44:24,902 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:24,903 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:24,904 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:24,904 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:24,905 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:24,905 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:24,906 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:24,906 - INFO - allennlp.common.params - metrics.model_performance_measures = CoNLL SRL metrics\n",
      "2022-03-29 14:44:24,907 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:24,907 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:24,908 - INFO - allennlp.common.params - evaluation_data.dataset.name = OIE2016, WEB and NYT, PENN\n",
      "2022-03-29 14:44:24,908 - INFO - allennlp.common.params - evaluation_data.dataset.notes = The Open Information extractor was evaluated on the OIE2016 corpus. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can get the data on the corpus homepage.\n",
      "2022-03-29 14:44:24,908 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/gabrielStanovsky/oie-benchmark\n",
      "2022-03-29 14:44:24,909 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:24,909 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:24,910 - INFO - allennlp.common.params - training_data.dataset.name = All Words Open IE\n",
      "2022-03-29 14:44:24,910 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/gabrielStanovsky/supervised-oie/tree/master/data\n",
      "2022-03-29 14:44:24,910 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:24,911 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:24,911 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 14:44:24,912 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:24,912 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:24,913 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:24,942 - INFO - allennlp.common.params - id = mc-roberta-swag\n",
      "2022-03-29 14:44:24,943 - INFO - allennlp.common.params - registered_model_name = transformer_mc\n",
      "2022-03-29 14:44:24,943 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:24,944 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:24,944 - INFO - allennlp.common.params - display_name = RoBERTa SWAG\n",
      "2022-03-29 14:44:24,945 - INFO - allennlp.common.params - task_id = mc\n",
      "2022-03-29 14:44:24,946 - INFO - allennlp.common.params - model_usage.archive_file = swag.2020-07-08.tar.gz\n",
      "2022-03-29 14:44:24,946 - INFO - allennlp.common.params - model_usage.training_config = mc/swag.jsonnet\n",
      "2022-03-29 14:44:24,946 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 14:44:24,947 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:24,948 - INFO - allennlp.common.params - model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n",
      "2022-03-29 14:44:24,948 - INFO - allennlp.common.params - model_details.short_description = RoBERTa-based multiple choice model for SWAG.\n",
      "2022-03-29 14:44:24,949 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-03-29 14:44:24,949 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 14:44:24,950 - INFO - allennlp.common.params - model_details.date = 2020-07-08\n",
      "2022-03-29 14:44:24,951 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:24,951 - INFO - allennlp.common.params - model_details.model_type = RoBERTa large\n",
      "2022-03-29 14:44:24,952 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 14:44:24,952 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-03-29 14:44:24,953 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 14:44:24,953 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:24,954 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:24,954 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:24,955 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:24,955 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:24,956 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:24,956 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:24,956 - INFO - allennlp.common.params - metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:24,957 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:24,957 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:24,958 - INFO - allennlp.common.params - evaluation_data.dataset.name = SWAG (validation set)\n",
      "2022-03-29 14:44:24,958 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 14:44:24,958 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://rowanzellers.com/swag/\n",
      "2022-03-29 14:44:24,959 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:24,959 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:24,960 - INFO - allennlp.common.params - training_data.dataset.name = SWAG (train set)\n",
      "2022-03-29 14:44:24,960 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 14:44:24,960 - INFO - allennlp.common.params - training_data.dataset.url = https://rowanzellers.com/swag/\n",
      "2022-03-29 14:44:24,961 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:24,961 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:24,961 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 14:44:24,962 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:24,962 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:24,963 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:24,995 - INFO - allennlp.common.params - id = ve-vilbert\n",
      "2022-03-29 14:44:24,996 - INFO - allennlp.common.params - registered_model_name = ve_vilbert\n",
      "2022-03-29 14:44:24,996 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:24,997 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:24,997 - INFO - allennlp.common.params - display_name = Visual Entailment\n",
      "2022-03-29 14:44:24,998 - INFO - allennlp.common.params - task_id = ve\n",
      "2022-03-29 14:44:24,998 - INFO - allennlp.common.params - model_usage.archive_file = visual-entailment-torchvision-2021.03.04.tar.gz\n",
      "2022-03-29 14:44:24,999 - INFO - allennlp.common.params - model_usage.training_config = vilbert_ve_pretrained.jsonnet\n",
      "2022-03-29 14:44:24,999 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 14:44:25,000 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:25,001 - INFO - allennlp.common.params - model_details.description = This model is based on the ViLBERT architecture. The image features are obtained using the ResNet backbone and Faster RCNN (region detection).\n",
      "2022-03-29 14:44:25,001 - INFO - allennlp.common.params - model_details.short_description = ViLBERT-based model for Visual Entailment.\n",
      "2022-03-29 14:44:25,001 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-03-29 14:44:25,002 - INFO - allennlp.common.params - model_details.contributed_by = Akshita Bhagia\n",
      "2022-03-29 14:44:25,002 - INFO - allennlp.common.params - model_details.date = 2021-03-04\n",
      "2022-03-29 14:44:25,003 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 14:44:25,003 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-03-29 14:44:25,004 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "2022-03-29 14:44:25,005 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-03-29 14:44:25,005 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-03-29 14:44:25,006 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:25,007 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:25,007 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-03-29 14:44:25,008 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:25,008 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:25,008 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:25,009 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:25,009 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and F1-score\n",
      "2022-03-29 14:44:25,010 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:25,010 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:25,011 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Natural Language Inference - Visual Entailment(SNLI-VE) dev set\n",
      "2022-03-29 14:44:25,011 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste.\n",
      "2022-03-29 14:44:25,011 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/necla-ml/SNLI-VE\n",
      "2022-03-29 14:44:25,011 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:25,012 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:25,012 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference - Visual Entailment(SNLI-VE) train set\n",
      "2022-03-29 14:44:25,013 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/necla-ml/SNLI-VE\n",
      "2022-03-29 14:44:25,013 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:25,013 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:25,014 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 14:44:25,014 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:25,015 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:25,015 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = This model is trained on the original SNLI-VE dataset. [Subsequent work](https://api.semanticscholar.org/CorpusID:215415945) has found that an estimated 31% of `neutral` labels in the dataset are incorrect. The `e-SNLI-VE-2.0` dataset contains the re-annotated validation and test sets.\n",
      "2022-03-29 14:44:25,044 - INFO - allennlp.common.params - id = rc-transformer-qa\n",
      "2022-03-29 14:44:25,045 - INFO - allennlp.common.params - registered_model_name = transformer_qa\n",
      "2022-03-29 14:44:25,045 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:25,046 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:25,047 - INFO - allennlp.common.params - display_name = Transformer QA\n",
      "2022-03-29 14:44:25,047 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-03-29 14:44:25,048 - INFO - allennlp.common.params - model_usage.archive_file = transformer-qa.2021-02-11.tar.gz\n",
      "2022-03-29 14:44:25,048 - INFO - allennlp.common.params - model_usage.training_config = rc/transformer_qa.jsonnet\n",
      "2022-03-29 14:44:25,049 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 14:44:25,049 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:25,050 - INFO - allennlp.common.params - model_details.description = The model implements a reading comprehension model patterned after the proposed model in [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al, 2018)](https://api.semanticscholar.org/CorpusID:52967399), with improvements borrowed from the SQuAD model in the transformers project. It predicts start tokens and end tokens with a linear layer on top of word piece embeddings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:25,050 - INFO - allennlp.common.params - model_details.short_description = A reading comprehension model patterned after the proposed model in Devlin et al, with improvements borrowed from the SQuAD model in the transformers project\n",
      "2022-03-29 14:44:25,051 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-03-29 14:44:25,051 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld and Evan Pete Walsh\n",
      "2022-03-29 14:44:25,052 - INFO - allennlp.common.params - model_details.date = 2020-10-03\n",
      "2022-03-29 14:44:25,052 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 14:44:25,053 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-03-29 14:44:25,053 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and L. Zettlemoyer and V. Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 14:44:25,054 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach\n",
      "2022-03-29 14:44:25,054 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 14:44:25,054 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:25,055 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:25,055 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:25,055 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:25,056 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:25,056 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:25,057 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:25,057 - INFO - allennlp.common.params - metrics.model_performance_measures = F1-score, Span Accuracy, Exact Match\n",
      "2022-03-29 14:44:25,057 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:25,058 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:25,058 - INFO - allennlp.common.params - evaluation_data.dataset.name = SQuAD dev set\n",
      "2022-03-29 14:44:25,059 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v2.0.json\n",
      "2022-03-29 14:44:25,059 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/2.0/dev/\n",
      "2022-03-29 14:44:25,059 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:25,060 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:25,060 - INFO - allennlp.common.params - training_data.dataset.name = SQuAD training set\n",
      "2022-03-29 14:44:25,061 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v2.0.json\n",
      "2022-03-29 14:44:25,061 - INFO - allennlp.common.params - training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/2.0/dev/\n",
      "2022-03-29 14:44:25,061 - INFO - allennlp.common.params - training_data.motivation = For the pretrained RoBERTa model, document-level corpora were used rather than a shuffled sentence-level corpus such as the Billion Word Benchmark (Chelba et al., 2013) in order to extract long contiguous sequences\n",
      "2022-03-29 14:44:25,062 - INFO - allennlp.common.params - training_data.preprocessing = For the pretrained RoBERTa model, only the text passages were extracted from English Wikipedia; lists, tables, and headers were ignored.\n",
      "2022-03-29 14:44:25,062 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 88%\n",
      "Exact match: 84%\n",
      "These are metrics using the official evaluation. Note that the metrics that the model produces while training are calculated on a per-instance basis only. Since there could be more than one instance per question, these metrics are not the official numbers on the SQuAD task. To get official numbers, run the evaluation script at allennlp_models/rc/tools/transformer_qa_eval.py.\n",
      "2022-03-29 14:44:25,063 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:25,063 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:25,064 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:25,097 - INFO - allennlp.common.params - id = semparse-text-to-sql\n",
      "2022-03-29 14:44:25,098 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-03-29 14:44:25,098 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:25,098 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:25,099 - INFO - allennlp.common.params - display_name = Text to SQL (ATIS)\n",
      "2022-03-29 14:44:25,099 - INFO - allennlp.common.params - task_id = semparse-text-to-sql\n",
      "2022-03-29 14:44:25,100 - INFO - allennlp.common.params - model_usage.archive_file = https://allennlp.s3.amazonaws.com/models/atis-parser-2020.02.10.tar.gz\n",
      "2022-03-29 14:44:25,100 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-03-29 14:44:25,101 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 14:44:25,101 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:25,102 - INFO - allennlp.common.params - model_details.description = This model is an implementation of an encoder-decoder architecture with LSTMs and constrained type decoding trained on the ATIS dataset. This model is still a proof-of-concept of what you can do with semantic parsing in AllenNLP and its performance is not state-of-the-art (this naive model gets around 40% exact denotation accuracy on the contextual ATIS dataset).\n",
      "2022-03-29 14:44:25,102 - INFO - allennlp.common.params - model_details.short_description = This model is an implementation of an encoder-decoder architecture with LSTMs and constrained type decoding trained on the ATIS dataset.\n",
      "2022-03-29 14:44:25,103 - INFO - allennlp.common.params - model_details.developed_by = Dasigi et al\n",
      "2022-03-29 14:44:25,103 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 14:44:25,104 - INFO - allennlp.common.params - model_details.date = 2020-02-10\n",
      "2022-03-29 14:44:25,104 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:25,104 - INFO - allennlp.common.params - model_details.model_type = None\n",
      "2022-03-29 14:44:25,105 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-03-29 14:44:25,105 - INFO - allennlp.common.params - model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "2022-03-29 14:44:25,106 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "2022-03-29 14:44:25,106 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:25,106 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:25,107 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:25,107 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:25,108 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:25,108 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:25,109 - INFO - allennlp.common.params - factors.evaluation_factors = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:25,109 - INFO - allennlp.common.params - metrics.model_performance_measures = 1. `exact_match`; the percentage of the time that our best output action sequence matches the SQL query exactly.\n",
      "2. `denotation_acc`; the percentage of examples where we get the correct denotation.\n",
      "3. `valid_sql_query`; the percentage of time that decoding actually produces avalid SQL query.\n",
      "4. `action_similarity`; how similar the action sequence predicted is to the actual action sequence.\n",
      "2022-03-29 14:44:25,110 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:25,110 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:25,111 - INFO - allennlp.common.params - evaluation_data.dataset.name = ATIS\n",
      "2022-03-29 14:44:25,111 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 14:44:25,112 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://api.semanticscholar.org/CorpusID:1094063\n",
      "2022-03-29 14:44:25,112 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:25,113 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:25,114 - INFO - allennlp.common.params - training_data.dataset.name = ATIS\n",
      "2022-03-29 14:44:25,114 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 14:44:25,114 - INFO - allennlp.common.params - training_data.dataset.url = https://api.semanticscholar.org/CorpusID:1094063\n",
      "2022-03-29 14:44:25,115 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:25,115 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:25,116 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 14:44:25,116 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:25,116 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:25,117 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:25,148 - INFO - allennlp.common.params - id = lm-next-token-lm-gpt2\n",
      "2022-03-29 14:44:25,148 - INFO - allennlp.common.params - registered_model_name = next_token_lm\n",
      "2022-03-29 14:44:25,148 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:25,149 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:25,149 - INFO - allennlp.common.params - display_name = GPT2-based Next Token Language Model\n",
      "2022-03-29 14:44:25,150 - INFO - allennlp.common.params - task_id = language-modeling\n",
      "2022-03-29 14:44:25,150 - INFO - allennlp.common.params - model_usage.archive_file = gpt2-next-word-lm-2020.06.30.tar.gz\n",
      "2022-03-29 14:44:25,151 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-03-29 14:44:25,151 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 14:44:25,152 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:25,152 - INFO - allennlp.common.params - model_details.description = This is the public 345M parameter OpenAI GPT-2 language model for generating sentences. The model embeds some input tokens, contextualizes them, then predicts the next word, computing a loss against known target. \n",
      "If `BeamSearch` is given, this model will predict a sequence of next tokens.\n",
      "2022-03-29 14:44:25,153 - INFO - allennlp.common.params - model_details.short_description = OpenAI's GPT-2 language model that generates the next token.\n",
      "2022-03-29 14:44:25,153 - INFO - allennlp.common.params - model_details.developed_by = Radford et al\n",
      "2022-03-29 14:44:25,154 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 14:44:25,154 - INFO - allennlp.common.params - model_details.date = 2020-06-30\n",
      "2022-03-29 14:44:25,155 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:25,155 - INFO - allennlp.common.params - model_details.model_type = GPT2\n",
      "2022-03-29 14:44:25,156 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Radford2019LanguageMA,\n",
      "title={Language Models are Unsupervised Multitask Learners},\n",
      "author={A. Radford and Jeffrey Wu and R. Child and David Luan and Dario Amodei and Ilya Sutskever},\n",
      "year={2019}}\n",
      "\n",
      "2022-03-29 14:44:25,156 - INFO - allennlp.common.params - model_details.paper.title = Language Models are Unsupervised Multitask Learners\n",
      "2022-03-29 14:44:25,157 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:160025533\n",
      "2022-03-29 14:44:25,158 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:25,158 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:25,159 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:25,160 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:25,160 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:25,161 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:25,162 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:25,162 - INFO - allennlp.common.params - metrics.model_performance_measures = Perplexity\n",
      "2022-03-29 14:44:25,163 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:25,163 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:25,164 - INFO - allennlp.common.params - evaluation_data.dataset.name = WebText corpus\n",
      "2022-03-29 14:44:25,164 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/openai/gpt-2-output-dataset\n",
      "2022-03-29 14:44:25,165 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:25,165 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:25,166 - INFO - allennlp.common.params - training_data.dataset.name = WebText corpus\n",
      "2022-03-29 14:44:25,166 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/openai/gpt-2-output-dataset\n",
      "2022-03-29 14:44:25,167 - INFO - allennlp.common.params - training_data.motivation = WebText emphasizes document quality. Only human-curated/filtered documents are scraped. Reddit outbound links which receive at least 3 karma points are taken as a proxy for human filtered webpages that are interesting.\n",
      "2022-03-29 14:44:25,167 - INFO - allennlp.common.params - training_data.preprocessing = Dragnet and [Newspaper](https://github.com/codelucas/newspaper) content extractors are used. Wikipedia articles are removed.\n",
      "2022-03-29 14:44:25,167 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 14:44:25,168 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:25,168 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:25,169 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:25,201 - INFO - allennlp.common.params - id = semparse-nlvr\n",
      "2022-03-29 14:44:25,202 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-03-29 14:44:25,202 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:25,203 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:25,203 - INFO - allennlp.common.params - display_name = NLVR Semantic Parsing\n",
      "2022-03-29 14:44:25,203 - INFO - allennlp.common.params - task_id = semparse-nlvr\n",
      "2022-03-29 14:44:25,204 - INFO - allennlp.common.params - model_usage.archive_file = https://allennlp.s3.amazonaws.com/models/nlvr-erm-model-2020.02.10-rule-vocabulary-updated.tar.gz\n",
      "2022-03-29 14:44:25,204 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-03-29 14:44:25,205 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:25,205 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:25,206 - INFO - allennlp.common.params - model_details.description = The model is a semantic parser trained on Cornell NLVR.\n",
      "2022-03-29 14:44:25,207 - INFO - allennlp.common.params - model_details.short_description = The model is a semantic parser trained on Cornell NLVR.\n",
      "2022-03-29 14:44:25,207 - INFO - allennlp.common.params - model_details.developed_by = Dasigi et al\n",
      "2022-03-29 14:44:25,208 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 14:44:25,208 - INFO - allennlp.common.params - model_details.date = None\n",
      "2022-03-29 14:44:25,209 - INFO - allennlp.common.params - model_details.version = None\n",
      "2022-03-29 14:44:25,209 - INFO - allennlp.common.params - model_details.model_type = None\n",
      "2022-03-29 14:44:25,210 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-03-29 14:44:25,210 - INFO - allennlp.common.params - model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "2022-03-29 14:44:25,210 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "2022-03-29 14:44:25,211 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:25,211 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:25,212 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:25,212 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:25,213 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:25,213 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:25,214 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:25,214 - INFO - allennlp.common.params - metrics.model_performance_measures = Denotation accuracy and consistency\n",
      "2022-03-29 14:44:25,215 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:25,215 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:25,216 - INFO - allennlp.common.params - evaluation_data.dataset.name = Cornell NLVR\n",
      "2022-03-29 14:44:25,216 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 14:44:25,217 - INFO - allennlp.common.params - evaluation_data.dataset.url = http://lil.nlp.cornell.edu/nlvr/\n",
      "2022-03-29 14:44:25,217 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:25,217 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:25,218 - INFO - allennlp.common.params - training_data.dataset.name = Cornell NLVR\n",
      "2022-03-29 14:44:25,218 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 14:44:25,219 - INFO - allennlp.common.params - training_data.dataset.url = http://lil.nlp.cornell.edu/nlvr/\n",
      "2022-03-29 14:44:25,219 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:25,219 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:25,220 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 14:44:25,220 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:25,220 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:25,221 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:25,254 - INFO - allennlp.common.params - id = coref-spanbert\n",
      "2022-03-29 14:44:25,255 - INFO - allennlp.common.params - registered_model_name = coref\n",
      "2022-03-29 14:44:25,255 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:25,256 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:25,256 - INFO - allennlp.common.params - display_name = Coreference Resolution\n",
      "2022-03-29 14:44:25,257 - INFO - allennlp.common.params - task_id = coref\n",
      "2022-03-29 14:44:25,258 - INFO - allennlp.common.params - model_usage.archive_file = coref-spanbert-large-2021.03.10.tar.gz\n",
      "2022-03-29 14:44:25,258 - INFO - allennlp.common.params - model_usage.training_config = coref/coref_spanbert_large.jsonnet\n",
      "2022-03-29 14:44:25,259 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 14:44:25,259 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:25,260 - INFO - allennlp.common.params - model_details.description = The basic outline of this model is to get an embedded representation of each span in the document. These span representations are scored  and used to prune away spans that are unlikely to occur in a coreference  cluster. For the remaining spans, the model decides which antecedent span (if any) they are coreferent with. The resulting coreference links, after applying transitivity, imply a clustering of the spans in the document. The GloVe embeddings in the original paper have been substituted with SpanBERT embeddings.\n",
      "2022-03-29 14:44:25,260 - INFO - allennlp.common.params - model_details.short_description = Higher-order coref with coarse-to-fine inference (with SpanBERT embeddings).\n",
      "2022-03-29 14:44:25,261 - INFO - allennlp.common.params - model_details.developed_by = Lee et al\n",
      "2022-03-29 14:44:25,262 - INFO - allennlp.common.params - model_details.contributed_by = Zhaofeng Wu\n",
      "2022-03-29 14:44:25,262 - INFO - allennlp.common.params - model_details.date = 2020-02-27\n",
      "2022-03-29 14:44:25,263 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 14:44:25,263 - INFO - allennlp.common.params - model_details.model_type = SpanBERT\n",
      "2022-03-29 14:44:25,264 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lee2018HigherorderCR,\n",
      "title={Higher-order Coreference Resolution with Coarse-to-fine Inference},\n",
      "author={Kenton Lee and Luheng He and L. Zettlemoyer},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2018}}\n",
      "\n",
      "2022-03-29 14:44:25,264 - INFO - allennlp.common.params - model_details.paper.title = Higher-order Coreference Resolution with Coarse-to-fine Inference\n",
      "2022-03-29 14:44:25,265 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:4891749\n",
      "2022-03-29 14:44:25,265 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:25,266 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:25,266 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:25,267 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:25,267 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:25,267 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:25,268 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:25,268 - INFO - allennlp.common.params - metrics.model_performance_measures = CoNLL coref scores and Mention Recall\n",
      "2022-03-29 14:44:25,269 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:25,269 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:25,269 - INFO - allennlp.common.params - evaluation_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 14:44:25,270 - INFO - allennlp.common.params - evaluation_data.dataset.notes = The Coreference model was evaluated on the CoNLL 2012 dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. To compile the data in the right format for evaluating the Coreference model, please see scripts/compile_coref_data.sh. This script requires the Ontonotes 5.0 dataset, available on the LDC website.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:25,270 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = /path/to/dataset\n",
      "2022-03-29 14:44:25,270 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 14:44:25,271 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:25,271 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:25,272 - INFO - allennlp.common.params - training_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 14:44:25,272 - INFO - allennlp.common.params - training_data.dataset.notes = The Coreference model was evaluated on the CoNLL 2012 dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. To compile the data in the right format for evaluating the Coreference model, please see scripts/compile_coref_data.sh. This script requires the Ontonotes 5.0 dataset, available on the LDC website.\n",
      "2022-03-29 14:44:25,272 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/to/dataset\n",
      "2022-03-29 14:44:25,272 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 14:44:25,273 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:25,273 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:25,274 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 14:44:25,274 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:25,274 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:25,275 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:25,308 - INFO - allennlp.common.params - id = vgqa-vilbert\n",
      "2022-03-29 14:44:25,308 - INFO - allennlp.common.params - registered_model_name = vqa_vilbert_from_huggingface\n",
      "2022-03-29 14:44:25,309 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:25,309 - INFO - allennlp.common.params - registered_predictor_name = vgqa_vilbert\n",
      "2022-03-29 14:44:25,310 - INFO - allennlp.common.params - display_name = ViLBERT - Visual Genome Question Answering\n",
      "2022-03-29 14:44:25,310 - INFO - allennlp.common.params - task_id = vgqa\n",
      "2022-03-29 14:44:25,311 - INFO - allennlp.common.params - model_usage.archive_file = vilbert-vgqa-pretrained.2021-05-10.tar.gz\n",
      "2022-03-29 14:44:25,312 - INFO - allennlp.common.params - model_usage.training_config = vision/vilbert_vgqa_pretrained.jsonnet\n",
      "2022-03-29 14:44:25,312 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.5.0 allennlp-models==2.5.0\n",
      "2022-03-29 14:44:25,313 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:25,313 - INFO - allennlp.common.params - model_details.description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "2022-03-29 14:44:25,314 - INFO - allennlp.common.params - model_details.short_description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "2022-03-29 14:44:25,315 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-03-29 14:44:25,315 - INFO - allennlp.common.params - model_details.contributed_by = Jacob Morrison\n",
      "2022-03-29 14:44:25,316 - INFO - allennlp.common.params - model_details.date = 2021-05-07\n",
      "2022-03-29 14:44:25,316 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 14:44:25,317 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-03-29 14:44:25,318 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "}\n",
      "2022-03-29 14:44:25,318 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-03-29 14:44:25,319 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-03-29 14:44:25,319 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:25,319 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:25,320 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-03-29 14:44:25,320 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:25,321 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:25,321 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:25,321 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:25,322 - INFO - allennlp.common.params - metrics.model_performance_measures = F1-metric and VQA score\n",
      "2022-03-29 14:44:25,322 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:25,323 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:25,323 - INFO - allennlp.common.params - evaluation_data.dataset.name = VGQA dataset\n",
      "2022-03-29 14:44:25,324 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n",
      "2022-03-29 14:44:25,324 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://visualgenome.org/static/data/dataset/question_answers.json.zip!question_answers.json[:5000]\n",
      "2022-03-29 14:44:25,324 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://visualgenome.org/\n",
      "2022-03-29 14:44:25,324 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:25,325 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:25,325 - INFO - allennlp.common.params - training_data.dataset.name = VGQA dataset\n",
      "2022-03-29 14:44:25,326 - INFO - allennlp.common.params - training_data.dataset.notes = Training requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n",
      "2022-03-29 14:44:25,326 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://visualgenome.org/static/data/dataset/question_answers.json.zip!question_answers.json[5000:]\n",
      "2022-03-29 14:44:25,326 - INFO - allennlp.common.params - training_data.dataset.url = https://visualgenome.org/\n",
      "2022-03-29 14:44:25,327 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:25,327 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:25,328 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 29.6%\n",
      "VQA: 26.5%.\n",
      "These scores do not match the performance in the VilBERT paper. Please contact us if you want to match those scores!\n",
      "2022-03-29 14:44:25,328 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:25,329 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:25,329 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:25,362 - INFO - allennlp.common.params - id = pair-classification-binary-gender-bias-mitigated-roberta-snli\n",
      "2022-03-29 14:44:25,363 - INFO - allennlp.common.params - registered_model_name = bias_mitigator_applicator\n",
      "2022-03-29 14:44:25,363 - INFO - allennlp.common.params - model_class = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:25,364 - INFO - allennlp.common.params - registered_predictor_name = textual_entailment\n",
      "2022-03-29 14:44:25,364 - INFO - allennlp.common.params - display_name = Binary Gender Bias-Mitigated RoBERTa SNLI\n",
      "2022-03-29 14:44:25,365 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-03-29 14:44:25,365 - INFO - allennlp.common.params - model_usage.archive_file = binary-gender-bias-mitigated-snli-roberta.2021-05-20.tar.gz\n",
      "2022-03-29 14:44:25,366 - INFO - allennlp.common.params - model_usage.training_config = pair_classification/binary_gender_bias_mitigated_snli_roberta.jsonnet\n",
      "2022-03-29 14:44:25,366 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.5.0 allennlp-models==2.5.0\n",
      "2022-03-29 14:44:25,367 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:25,367 - INFO - allennlp.common.params - model_details.description = This `Model` implements a basic text classifier with a bias mitigator applicator wrapper. The text is embedded into a text field using a RoBERTa-large model. Following the static embedding layer, the embeddings are projected onto the subspace orthogonal to the binary gender bias subspace. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space.\n",
      "2022-03-29 14:44:25,368 - INFO - allennlp.common.params - model_details.short_description = RoBERTa finetuned on SNLI with binary gender bias mitigation.\n",
      "2022-03-29 14:44:25,368 - INFO - allennlp.common.params - model_details.developed_by = Dev at al\n",
      "2022-03-29 14:44:25,369 - INFO - allennlp.common.params - model_details.contributed_by = Arjun Subramonian\n",
      "2022-03-29 14:44:25,369 - INFO - allennlp.common.params - model_details.date = 2021-05-20\n",
      "2022-03-29 14:44:25,370 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:25,370 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-03-29 14:44:25,370 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Dev2020OnMA,\n",
      "title={On Measuring and Mitigating Biased Inferences of Word Embeddings},\n",
      "author={Sunipa Dev and Tao Li and J. M. Phillips and Vivek Srikumar},\n",
      "journal={Proceedings of the AAAI Conference on Artificial Intelligence},\n",
      "year={2020},\n",
      "volume={34},\n",
      "number={05},\n",
      "pages={7659-7666},\n",
      "DOI={10.1609/aaai.v34i05.6267}\n",
      "\n",
      "2022-03-29 14:44:25,371 - INFO - allennlp.common.params - model_details.paper.title = On Measuring and Mitigating Biased Inferences of Word Embeddings\n",
      "2022-03-29 14:44:25,371 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:201670701\n",
      "2022-03-29 14:44:25,372 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:25,372 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:25,372 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:25,373 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:25,373 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:25,374 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:25,374 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:25,375 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy, Net Neutral, Fraction Neutral, Threshold:tau\n",
      "2022-03-29 14:44:25,375 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:25,376 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:25,376 - INFO - allennlp.common.params - evaluation_data.dataset.name = On Measuring and Mitigating Biased Gender-Occupation Inferences SNLI Dataset\n",
      "2022-03-29 14:44:25,377 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://storage.googleapis.com/allennlp-public-models/binary-gender-bias-mitigated-snli-dataset.jsonl\n",
      "2022-03-29 14:44:25,377 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/sunipa/On-Measuring-and-Mitigating-Biased-Inferences-of-Word-Embeddings\n",
      "2022-03-29 14:44:25,378 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:25,378 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:25,379 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-03-29 14:44:25,379 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-03-29 14:44:25,380 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 14:44:25,380 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:25,380 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:25,381 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Net Neutral: 0.6417539715766907, Fraction Neutral: 0.7002295255661011, Threshold:0.5: 0.6902161836624146, Threshold:0.7: 0.49243637919425964\n",
      "2022-03-29 14:44:25,381 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:25,382 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = Binary gender bias mitigation has been applied to this model. Nonetheless, the model will contain residual biases and bias mitigation does not guarantee entirely bias-free inferences.\n",
      "2022-03-29 14:44:25,382 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:25,415 - INFO - allennlp.common.params - id = rc-bidaf-elmo\n",
      "2022-03-29 14:44:25,415 - INFO - allennlp.common.params - registered_model_name = bidaf\n",
      "2022-03-29 14:44:25,416 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:25,416 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:25,417 - INFO - allennlp.common.params - display_name = ELMo-BiDAF\n",
      "2022-03-29 14:44:25,417 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-03-29 14:44:25,418 - INFO - allennlp.common.params - model_usage.archive_file = bidaf-elmo.2021-02-11.tar.gz\n",
      "2022-03-29 14:44:25,419 - INFO - allennlp.common.params - model_usage.training_config = rc/bidaf_elmo.jsonnet\n",
      "2022-03-29 14:44:25,419 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 14:44:25,420 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:25,421 - INFO - allennlp.common.params - model_details.description = This is an implementation of the BiDAF model with ELMo embeddings. The basic layout is pretty simple: encode words as a combination of word embeddings and a character-level encoder, pass the word representations through a bi-LSTM/GRU, use a matrix of attentions to put question information into the passage word representations (this is the only part that is at all non-standard), pass this through another few layers of bi-LSTMs/GRUs, and do a softmax over span start and span end.\n",
      "2022-03-29 14:44:25,421 - INFO - allennlp.common.params - model_details.short_description = BiDAF model with ELMo embeddings instead of GloVe.\n",
      "2022-03-29 14:44:25,422 - INFO - allennlp.common.params - model_details.developed_by = Seo et al\n",
      "2022-03-29 14:44:25,422 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 14:44:25,423 - INFO - allennlp.common.params - model_details.date = 2020-03-19\n",
      "2022-03-29 14:44:25,425 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:25,425 - INFO - allennlp.common.params - model_details.model_type = BiDAF\n",
      "2022-03-29 14:44:25,426 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Seo2017BidirectionalAF,\n",
      "title={Bidirectional Attention Flow for Machine Comprehension},\n",
      "author={Minjoon Seo and Aniruddha Kembhavi and Ali Farhadi and Hannaneh Hajishirzi},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01603}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:25,426 - INFO - allennlp.common.params - model_details.paper.title = Bidirectional Attention Flow for Machine Comprehension\n",
      "2022-03-29 14:44:25,427 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:8535316\n",
      "2022-03-29 14:44:25,427 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:25,428 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:25,429 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:25,429 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:25,430 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:25,430 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:25,431 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:25,432 - INFO - allennlp.common.params - metrics.model_performance_measures = Start, end and overall span accuracy, Exact Match, F1 score\n",
      "2022-03-29 14:44:25,432 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:25,434 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:25,435 - INFO - allennlp.common.params - evaluation_data.dataset.name = SQuAD dev set\n",
      "2022-03-29 14:44:25,435 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v1.1.json\n",
      "2022-03-29 14:44:25,436 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "2022-03-29 14:44:25,436 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:25,437 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:25,437 - INFO - allennlp.common.params - training_data.dataset.name = SQuAD training set\n",
      "2022-03-29 14:44:25,438 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v1.1.json\n",
      "2022-03-29 14:44:25,438 - INFO - allennlp.common.params - training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "2022-03-29 14:44:25,439 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:25,439 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:25,439 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "Start accuracy: 66%\n",
      "End accuracy: 69%\n",
      "Overall span accuracy: 57%\n",
      "Exact match: 71%\n",
      "F1: 80%\n",
      "2022-03-29 14:44:25,440 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:25,440 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:25,441 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = This model is based on ELMo. ELMo is not deterministic, meaning that you will see slight differences every time you run it. Also, ELMo likes to be warmed up, so we recommend processing dummy input before processing real workloads with it.\n",
      "2022-03-29 14:44:25,471 - INFO - allennlp.common.params - id = structured-prediction-srl-bert\n",
      "2022-03-29 14:44:25,472 - INFO - allennlp.common.params - registered_model_name = srl_bert\n",
      "2022-03-29 14:44:25,472 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:25,473 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:25,474 - INFO - allennlp.common.params - display_name = SRL BERT\n",
      "2022-03-29 14:44:25,474 - INFO - allennlp.common.params - task_id = srl\n",
      "2022-03-29 14:44:25,475 - INFO - allennlp.common.params - model_usage.archive_file = structured-prediction-srl-bert.2020.12.15.tar.gz\n",
      "2022-03-29 14:44:25,476 - INFO - allennlp.common.params - model_usage.training_config = structured_prediction/bert_base_srl.jsonnet\n",
      "2022-03-29 14:44:25,476 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 14:44:25,477 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:25,477 - INFO - allennlp.common.params - model_details.description = An implementation of a BERT based model (Shi et al, 2019) with some modifications (no additional parameters apart from a linear classification layer), which is currently the state of the art single model for English PropBank SRL (Newswire sentences). It achieves 86.49 test F1 on the Ontonotes 5.0 dataset.\n",
      "2022-03-29 14:44:25,478 - INFO - allennlp.common.params - model_details.short_description = A BERT based model (Shi et al, 2019) with some modifications (no additional parameters apart from a linear classification layer)\n",
      "2022-03-29 14:44:25,478 - INFO - allennlp.common.params - model_details.developed_by = Shi et al\n",
      "2022-03-29 14:44:25,479 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 14:44:25,479 - INFO - allennlp.common.params - model_details.date = 2020-09-03\n",
      "2022-03-29 14:44:25,480 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:25,480 - INFO - allennlp.common.params - model_details.model_type = BERT\n",
      "2022-03-29 14:44:25,481 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Shi2019SimpleBM,\n",
      "title={Simple BERT Models for Relation Extraction and Semantic Role Labeling},\n",
      "author={Peng Shi and Jimmy Lin},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1904.05255}}\n",
      "\n",
      "2022-03-29 14:44:25,481 - INFO - allennlp.common.params - model_details.paper.title = Simple BERT Models for Relation Extraction and Semantic Role Labeling\n",
      "2022-03-29 14:44:25,482 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:131773936\n",
      "2022-03-29 14:44:25,482 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:25,483 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:25,484 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:25,484 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:25,485 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:25,485 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:25,486 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:25,487 - INFO - allennlp.common.params - metrics.model_performance_measures = Precision, recall and F1-score\n",
      "2022-03-29 14:44:25,487 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:25,487 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:25,488 - INFO - allennlp.common.params - evaluation_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 14:44:25,488 - INFO - allennlp.common.params - evaluation_data.dataset.notes = We cannot release this data due to licensing restrictions.\n",
      "2022-03-29 14:44:25,489 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 14:44:25,489 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:25,489 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:25,490 - INFO - allennlp.common.params - training_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 14:44:25,490 - INFO - allennlp.common.params - training_data.dataset.notes = We cannot release this data due to licensing restrictions.\n",
      "2022-03-29 14:44:25,491 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 14:44:25,491 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:25,491 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:25,492 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = 86.49 test F1 on the Ontonotes 5.0 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:25,492 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:25,493 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:25,494 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:25,526 - INFO - allennlp.common.params - id = semparse-wikitables\n",
      "2022-03-29 14:44:25,527 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-03-29 14:44:25,527 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:25,528 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:25,528 - INFO - allennlp.common.params - display_name = WikiTables Semantic Parsing\n",
      "2022-03-29 14:44:25,529 - INFO - allennlp.common.params - task_id = semparse-tabular\n",
      "2022-03-29 14:44:25,529 - INFO - allennlp.common.params - model_usage.archive_file = wikitables-model-2020.02.10.tar.gz\n",
      "2022-03-29 14:44:25,530 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-03-29 14:44:25,530 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 14:44:25,531 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:25,532 - INFO - allennlp.common.params - model_details.description = The model is a semantic parser trained on WikiTableQuestions.\n",
      "2022-03-29 14:44:25,532 - INFO - allennlp.common.params - model_details.short_description = The model is a semantic parser trained on WikiTableQuestions.\n",
      "2022-03-29 14:44:25,533 - INFO - allennlp.common.params - model_details.developed_by = Dasigi et al\n",
      "2022-03-29 14:44:25,533 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 14:44:25,534 - INFO - allennlp.common.params - model_details.date = 2020-02-10\n",
      "2022-03-29 14:44:25,534 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:25,535 - INFO - allennlp.common.params - model_details.model_type = None\n",
      "2022-03-29 14:44:25,535 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-03-29 14:44:25,536 - INFO - allennlp.common.params - model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "2022-03-29 14:44:25,537 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "2022-03-29 14:44:25,537 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:25,538 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:25,538 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:25,539 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:25,539 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:25,540 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:25,540 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:25,541 - INFO - allennlp.common.params - metrics.model_performance_measures = 1. `lf_retrieval_acc`; the percentage of the time that our best output action sequence is in the set of action sequences provided by offline search.\n",
      "2. `denotation_acc`; the percentage of examples where we get the correct denotation.\n",
      "3. `lf_percent`; the percentage of time that decoding actually produces a finished logical form\n",
      "2022-03-29 14:44:25,541 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:25,542 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:25,542 - INFO - allennlp.common.params - evaluation_data.dataset.name = WikiTableQuestions\n",
      "2022-03-29 14:44:25,543 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 14:44:25,543 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://ppasupat.github.io/WikiTableQuestions/\n",
      "2022-03-29 14:44:25,543 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:25,544 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:25,544 - INFO - allennlp.common.params - training_data.dataset.name = WikiTableQuestions\n",
      "2022-03-29 14:44:25,545 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 14:44:25,545 - INFO - allennlp.common.params - training_data.dataset.url = https://ppasupat.github.io/WikiTableQuestions/\n",
      "2022-03-29 14:44:25,545 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:25,546 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:25,546 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 14:44:25,546 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:25,547 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:25,548 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:25,580 - INFO - allennlp.common.params - id = pair-classification-decomposable-attention-elmo\n",
      "2022-03-29 14:44:25,581 - INFO - allennlp.common.params - registered_model_name = decomposable_attention\n",
      "2022-03-29 14:44:25,581 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:25,582 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:25,582 - INFO - allennlp.common.params - display_name = ELMo-based Decomposable Attention\n",
      "2022-03-29 14:44:25,583 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-03-29 14:44:25,584 - INFO - allennlp.common.params - model_usage.archive_file = decomposable-attention-elmo-2020.04.09.tar.gz\n",
      "2022-03-29 14:44:25,584 - INFO - allennlp.common.params - model_usage.training_config = decomposable_attention_elmo.jsonnet\n",
      "2022-03-29 14:44:25,585 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 14:44:25,585 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:25,586 - INFO - allennlp.common.params - model_details.description = This `Model` implements the Decomposable Attention model described in [A Decomposable Attention Model for Natural Language Inference](https://api.semanticscholar.org/CorpusID:8495258) by Parikh et al., 2016, with some optional enhancements before the decomposable attention actually happens.  Parikh's original model allowed for computing an \"intra-sentence\" attention before doing the decomposable entailment step.  We generalize this to any `Seq2SeqEncoder` that can be applied to the premise and/or the hypothesis before computing entailment.\n",
      "\n",
      "The basic outline of this model is to get an embedded representation of each word in thepremise and hypothesis, align words between the two, compare the aligned phrases, and make a final entailment decision based on this aggregated comparison.  Each step in this process uses a feedforward network to modify the representation.\n",
      "\n",
      "This model uses ELMo embeddings.\n",
      "2022-03-29 14:44:25,586 - INFO - allennlp.common.params - model_details.short_description = The decomposable attention model (Parikh et al, 2017) combined with ELMo embeddings trained on SNLI.\n",
      "2022-03-29 14:44:25,587 - INFO - allennlp.common.params - model_details.developed_by = Parikh et al\n",
      "2022-03-29 14:44:25,587 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 14:44:25,588 - INFO - allennlp.common.params - model_details.date = 2020-04-09\n",
      "2022-03-29 14:44:25,589 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:25,589 - INFO - allennlp.common.params - model_details.model_type = Seq2Seq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:25,590 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Parikh2016ADA,\n",
      "title={A Decomposable Attention Model for Natural Language Inference},\n",
      "author={Ankur P. Parikh and Oscar T{\"a}ckstr{\"o}m and Dipanjan Das and Jakob Uszkoreit},\n",
      "journal={ArXiv},\n",
      "year={2016},\n",
      "volume={abs/1606.01933}}\n",
      "\n",
      "2022-03-29 14:44:25,590 - INFO - allennlp.common.params - model_details.paper.title = A Decomposable Attention Model for Natural Language Inference\n",
      "2022-03-29 14:44:25,591 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:8495258\n",
      "2022-03-29 14:44:25,591 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:25,592 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:25,593 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:25,593 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:25,594 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:25,595 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:25,595 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:25,595 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 14:44:25,596 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:25,596 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:25,597 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n",
      "2022-03-29 14:44:25,597 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "2022-03-29 14:44:25,597 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 14:44:25,598 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:25,598 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:25,598 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-03-29 14:44:25,599 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-03-29 14:44:25,599 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 14:44:25,599 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:25,600 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:25,600 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 14:44:25,601 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:25,601 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:25,602 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:25,635 - INFO - allennlp.common.params - id = pair-classification-roberta-rte\n",
      "2022-03-29 14:44:25,635 - INFO - allennlp.common.params - registered_model_name = basic_classifier\n",
      "2022-03-29 14:44:25,636 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:25,637 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:25,637 - INFO - allennlp.common.params - display_name = RoBERTa RTE\n",
      "2022-03-29 14:44:25,638 - INFO - allennlp.common.params - task_id = pair_classification\n",
      "2022-03-29 14:44:25,638 - INFO - allennlp.common.params - model_usage.archive_file = superglue-rte-roberta.2021-04-09.tar.gz\n",
      "2022-03-29 14:44:25,639 - INFO - allennlp.common.params - model_usage.training_config = pair-classification/superglue_rte_roberta.jsonnet\n",
      "2022-03-29 14:44:25,639 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.3.1 allennlp-models==2.3.1\n",
      "2022-03-29 14:44:25,640 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:25,641 - INFO - allennlp.common.params - model_details.description = The model implements a pair classification model patterned after the proposed model in [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al, 2018)](https://api.semanticscholar.org/CorpusID:52967399), fine-tuned on the MultiNLI corpus. It predicts labels with a linear layer on top of word piece embeddings.\n",
      "2022-03-29 14:44:25,641 - INFO - allennlp.common.params - model_details.short_description = A pair classification model patterned after the proposed model in Devlin et al, fine-tuned on the SuperGLUE RTE corpus\n",
      "2022-03-29 14:44:25,642 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-03-29 14:44:25,642 - INFO - allennlp.common.params - model_details.contributed_by = Jacob Morrison\n",
      "2022-03-29 14:44:25,643 - INFO - allennlp.common.params - model_details.date = 2021-04-09\n",
      "2022-03-29 14:44:25,643 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:25,644 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-03-29 14:44:25,645 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and L. Zettlemoyer and V. Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 14:44:25,645 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach\n",
      "2022-03-29 14:44:25,646 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 14:44:25,646 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:25,647 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:25,647 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:25,648 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:25,649 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:25,649 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:25,650 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:25,651 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 14:44:25,651 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:25,652 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:25,652 - INFO - allennlp.common.params - evaluation_data.dataset.name = SuperGLUE Recognizing Textual Entailment validation set\n",
      "2022-03-29 14:44:25,653 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://dl.fbaipublicfiles.com/glue/superglue/data/v2/RTE.zip!RTE/val.jsonl\n",
      "2022-03-29 14:44:25,653 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://super.gluebenchmark.com/tasks\n",
      "2022-03-29 14:44:25,653 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:25,654 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:25,654 - INFO - allennlp.common.params - training_data.dataset.name = SuperGLUE Recognizing Textual Entailment training set\n",
      "2022-03-29 14:44:25,655 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://dl.fbaipublicfiles.com/glue/superglue/data/v2/RTE.zip!RTE/train.jsonl\n",
      "2022-03-29 14:44:25,655 - INFO - allennlp.common.params - training_data.dataset.url = https://super.gluebenchmark.com/tasks\n",
      "2022-03-29 14:44:25,655 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:25,656 - INFO - allennlp.common.params - training_data.preprocessing = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:25,656 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Accuracy: 89.9% on the SuperGLUE RTE validation dataset.\n",
      "2022-03-29 14:44:25,656 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:25,657 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:25,657 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:25,715 - INFO - allennlp.common.params - id = evaluate_rc-lerc\n",
      "2022-03-29 14:44:25,715 - INFO - allennlp.common.params - registered_model_name = lerc\n",
      "2022-03-29 14:44:25,716 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:25,716 - INFO - allennlp.common.params - registered_predictor_name = lerc\n",
      "2022-03-29 14:44:25,717 - INFO - allennlp.common.params - display_name = Learned Evaluation for Reading Comprehension (LERC)\n",
      "2022-03-29 14:44:25,717 - INFO - allennlp.common.params - task_id = evaluate_rc\n",
      "2022-03-29 14:44:25,718 - INFO - allennlp.common.params - model_usage.archive_file = lerc-2020-11-18.tar.gz\n",
      "2022-03-29 14:44:25,719 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-03-29 14:44:25,719 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 14:44:25,720 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:25,720 - INFO - allennlp.common.params - model_details.description = LERC is a BERT model that is trained to mimic human judgement scores on candidate answers in the MOCHA dataset. LERC outputs scores that range from 1 to 5, however, to stay consistent with metrics such as BLEU and ROUGE, we normalize the output of LERC to be between 0 and 1 in this demo.\n",
      "2022-03-29 14:44:25,721 - INFO - allennlp.common.params - model_details.short_description = A BERT model that scores candidate answers from 0 to 1.\n",
      "2022-03-29 14:44:25,721 - INFO - allennlp.common.params - model_details.developed_by = Chen et al\n",
      "2022-03-29 14:44:25,722 - INFO - allennlp.common.params - model_details.contributed_by = Anthony Chen\n",
      "2022-03-29 14:44:25,722 - INFO - allennlp.common.params - model_details.date = 2021-03-10\n",
      "2022-03-29 14:44:25,723 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 14:44:25,723 - INFO - allennlp.common.params - model_details.model_type = BERT\n",
      "2022-03-29 14:44:25,724 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Chen2020MOCHAAD,\n",
      "title={MOCHA: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics},\n",
      "author={Anthony Chen and Gabriel Stanovsky and S. Singh and Matt Gardner},\n",
      "booktitle={EMNLP},\n",
      "year={2020}}\n",
      "\n",
      "2022-03-29 14:44:25,724 - INFO - allennlp.common.params - model_details.paper.title = MOCHA: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics\n",
      "2022-03-29 14:44:25,725 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:222208714\n",
      "2022-03-29 14:44:25,726 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:25,726 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:25,726 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:25,727 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:25,727 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:25,728 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:25,728 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:25,729 - INFO - allennlp.common.params - metrics.model_performance_measures = Pearson Correlation\n",
      "2022-03-29 14:44:25,729 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:25,729 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:25,730 - INFO - allennlp.common.params - evaluation_data.dataset.name = MOCHA\n",
      "2022-03-29 14:44:25,730 - INFO - allennlp.common.params - evaluation_data.dataset.notes = To evaluate this model follow the instructions at https://github.com/anthonywchen/MOCHA.\n",
      "2022-03-29 14:44:25,731 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = None\n",
      "2022-03-29 14:44:25,731 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://allennlp.org/mocha\n",
      "2022-03-29 14:44:25,731 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:25,732 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:25,732 - INFO - allennlp.common.params - training_data.dataset.name = MOCHA\n",
      "2022-03-29 14:44:25,733 - INFO - allennlp.common.params - training_data.dataset.notes = To train this model follow the instructions at https://github.com/anthonywchen/MOCHA.\n",
      "2022-03-29 14:44:25,733 - INFO - allennlp.common.params - training_data.dataset.processed_url = None\n",
      "2022-03-29 14:44:25,733 - INFO - allennlp.common.params - training_data.dataset.url = https://allennlp.org/mocha\n",
      "2022-03-29 14:44:25,733 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:25,734 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:25,734 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 14:44:25,735 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:25,735 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:25,736 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:25,739 - WARNING - allennlp.common.model_card - lerc is not a registered model.\n",
      "2022-03-29 14:44:25,773 - INFO - allennlp.common.params - id = rc-naqanet\n",
      "2022-03-29 14:44:25,773 - INFO - allennlp.common.params - registered_model_name = naqanet\n",
      "2022-03-29 14:44:25,774 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 14:44:25,775 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 14:44:25,775 - INFO - allennlp.common.params - display_name = Numerically Augmented QA Net\n",
      "2022-03-29 14:44:25,776 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-03-29 14:44:25,777 - INFO - allennlp.common.params - model_usage.archive_file = naqanet-2021.02.26.tar.gz\n",
      "2022-03-29 14:44:25,777 - INFO - allennlp.common.params - model_usage.training_config = rc/naqanet.jsonnet\n",
      "2022-03-29 14:44:25,778 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 14:44:25,779 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 14:44:25,780 - INFO - allennlp.common.params - model_details.description = An augmented version of QANet model with some rudimentary numerical reasoning abilities. The main idea here is that instead of just predicting a passage span after doing all of the QANet modeling stuff, we add several different 'answer abilities': predicting a span from the question, predicting a count, or predicting an arithmetic expression.  Near the end of the QANet model, we have a variable that predicts what kind of answer type we need, and each branch has separate modeling logic to predict that answer type.  We then marginalize over all possible ways of getting to the right answer through each of these answer types.\n",
      "2022-03-29 14:44:25,780 - INFO - allennlp.common.params - model_details.short_description = An augmented version of QANet that adds rudimentary numerical reasoning ability, trained on DROP (Dua et al., 2019), as published in the original DROP paper.\n",
      "2022-03-29 14:44:25,781 - INFO - allennlp.common.params - model_details.developed_by = Dua et al\n",
      "2022-03-29 14:44:25,782 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 14:44:25,782 - INFO - allennlp.common.params - model_details.date = 2020-02-19\n",
      "2022-03-29 14:44:25,783 - INFO - allennlp.common.params - model_details.version = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:25,784 - INFO - allennlp.common.params - model_details.model_type = QANet\n",
      "2022-03-29 14:44:25,784 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Dua2019DROPAR,\n",
      "title={DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs},\n",
      "author={Dheeru Dua and Yizhong Wang and Pradeep Dasigi and Gabriel Stanovsky and Sameer Singh and Matt Gardner},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-03-29 14:44:25,785 - INFO - allennlp.common.params - model_details.paper.title = DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs\n",
      "2022-03-29 14:44:25,785 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:67855846\n",
      "2022-03-29 14:44:25,785 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 14:44:25,786 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 14:44:25,786 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 14:44:25,787 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 14:44:25,787 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 14:44:25,787 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 14:44:25,788 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 14:44:25,788 - INFO - allennlp.common.params - metrics.model_performance_measures = Exact Match and F1-score\n",
      "2022-03-29 14:44:25,789 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 14:44:25,789 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 14:44:25,790 - INFO - allennlp.common.params - evaluation_data.dataset.name = DROP\n",
      "2022-03-29 14:44:25,790 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/drop/drop_dataset.zip!drop_dataset/drop_dataset_dev.json\n",
      "2022-03-29 14:44:25,790 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://allennlp.org/drop\n",
      "2022-03-29 14:44:25,791 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 14:44:25,791 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 14:44:25,792 - INFO - allennlp.common.params - training_data.dataset.name = DROP\n",
      "2022-03-29 14:44:25,792 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/drop/drop_dataset.zip!drop_dataset/drop_dataset_train.json\n",
      "2022-03-29 14:44:25,792 - INFO - allennlp.common.params - training_data.dataset.url = https://allennlp.org/drop\n",
      "2022-03-29 14:44:25,793 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 14:44:25,793 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 14:44:25,794 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Validation F1-score: 0.509, Exact Match: 0.473\n",
      "2022-03-29 14:44:25,794 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 14:44:25,794 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 14:44:25,795 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 14:44:25,953 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2022-03-29 14:44:26,221 - INFO - allennlp.common.file_utils - cache of https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2021.03.10.tar.gz is up-to-date\n",
      "2022-03-29 14:44:26,222 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2021.03.10.tar.gz from cache at /home/tnguyen/.allennlp/cache/038f918d294bd1a45e3709dfb22af5277b0be8677f750a85748c39979ce0e549.b897bfe76a04a5f70d6e88762a4d819b4b8b90e45b31b8314e0a6a9630d3f213\n",
      "2022-03-29 14:44:26,224 - INFO - allennlp.models.archival - extracting archive file /home/tnguyen/.allennlp/cache/038f918d294bd1a45e3709dfb22af5277b0be8677f750a85748c39979ce0e549.b897bfe76a04a5f70d6e88762a4d819b4b8b90e45b31b8314e0a6a9630d3f213 to temp dir /tmp/tmp6568mjb_\n",
      "2022-03-29 14:44:37,427 - INFO - allennlp.common.params - dataset_reader.type = coref\n",
      "2022-03-29 14:44:37,428 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-03-29 14:44:37,429 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-03-29 14:44:37,429 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2022-03-29 14:44:37,430 - INFO - allennlp.common.params - dataset_reader.max_span_width = 30\n",
      "2022-03-29 14:44:37,431 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer_mismatched\n",
      "2022-03-29 14:44:37,431 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0\n",
      "2022-03-29 14:44:37,432 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = SpanBERT/spanbert-large-cased\n",
      "2022-03-29 14:44:37,433 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags\n",
      "2022-03-29 14:44:37,433 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512\n",
      "2022-03-29 14:44:37,434 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None\n",
      "2022-03-29 14:44:45,435 - INFO - allennlp.common.params - dataset_reader.wordpiece_modeling_tokenizer = None\n",
      "2022-03-29 14:44:45,436 - INFO - allennlp.common.params - dataset_reader.max_sentences = 110\n",
      "2022-03-29 14:44:45,436 - INFO - allennlp.common.params - dataset_reader.remove_singleton_clusters = False\n",
      "2022-03-29 14:44:45,437 - INFO - allennlp.common.params - validation_dataset_reader.type = coref\n",
      "2022-03-29 14:44:45,438 - INFO - allennlp.common.params - validation_dataset_reader.max_instances = None\n",
      "2022-03-29 14:44:45,438 - INFO - allennlp.common.params - validation_dataset_reader.manual_distributed_sharding = False\n",
      "2022-03-29 14:44:45,439 - INFO - allennlp.common.params - validation_dataset_reader.manual_multiprocess_sharding = False\n",
      "2022-03-29 14:44:45,439 - INFO - allennlp.common.params - validation_dataset_reader.max_span_width = 30\n",
      "2022-03-29 14:44:45,440 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer_mismatched\n",
      "2022-03-29 14:44:45,440 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0\n",
      "2022-03-29 14:44:45,441 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.model_name = SpanBERT/spanbert-large-cased\n",
      "2022-03-29 14:44:45,441 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tags\n",
      "2022-03-29 14:44:45,442 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.max_length = 512\n",
      "2022-03-29 14:44:45,442 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.tokenizer_kwargs = None\n",
      "2022-03-29 14:44:45,444 - INFO - allennlp.common.params - validation_dataset_reader.wordpiece_modeling_tokenizer = None\n",
      "2022-03-29 14:44:45,445 - INFO - allennlp.common.params - validation_dataset_reader.max_sentences = None\n",
      "2022-03-29 14:44:45,445 - INFO - allennlp.common.params - validation_dataset_reader.remove_singleton_clusters = False\n",
      "2022-03-29 14:44:45,446 - INFO - allennlp.common.params - type = from_instances\n",
      "2022-03-29 14:44:45,446 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmp6568mjb_/vocabulary.\n",
      "2022-03-29 14:44:45,448 - INFO - allennlp.common.params - model.type = coref\n",
      "2022-03-29 14:44:45,449 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2022-03-29 14:44:45,449 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n",
      "2022-03-29 14:44:45,450 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer_mismatched\n",
      "2022-03-29 14:44:45,451 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = SpanBERT/spanbert-large-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:45,451 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512\n",
      "2022-03-29 14:44:45,452 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True\n",
      "2022-03-29 14:44:45,452 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True\n",
      "2022-03-29 14:44:45,452 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None\n",
      "2022-03-29 14:44:45,453 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None\n",
      "2022-03-29 14:44:45,453 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.load_weights = True\n",
      "2022-03-29 14:44:45,453 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None\n",
      "2022-03-29 14:44:45,454 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None\n",
      "2022-03-29 14:44:45,454 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None\n",
      "2022-03-29 14:44:45,454 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_token_mode = avg\n",
      "Some weights of BertModel were not initialized from the model checkpoint at SpanBERT/spanbert-large-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2022-03-29 14:44:49,067 - INFO - allennlp.common.params - model.context_layer.type = pass_through\n",
      "2022-03-29 14:44:49,067 - INFO - allennlp.common.params - model.context_layer.input_dim = 1024\n",
      "2022-03-29 14:44:49,068 - INFO - allennlp.common.params - model.mention_feedforward.input_dim = 3092\n",
      "2022-03-29 14:44:49,068 - INFO - allennlp.common.params - model.mention_feedforward.num_layers = 2\n",
      "2022-03-29 14:44:49,069 - INFO - allennlp.common.params - model.mention_feedforward.hidden_dims = 1500\n",
      "2022-03-29 14:44:49,069 - INFO - allennlp.common.params - model.mention_feedforward.activations = relu\n",
      "2022-03-29 14:44:49,069 - INFO - allennlp.common.params - type = relu\n",
      "2022-03-29 14:44:49,070 - INFO - allennlp.common.params - model.mention_feedforward.dropout = 0.3\n",
      "2022-03-29 14:44:49,114 - INFO - allennlp.common.params - model.antecedent_feedforward.input_dim = 9296\n",
      "2022-03-29 14:44:49,115 - INFO - allennlp.common.params - model.antecedent_feedforward.num_layers = 2\n",
      "2022-03-29 14:44:49,115 - INFO - allennlp.common.params - model.antecedent_feedforward.hidden_dims = 1500\n",
      "2022-03-29 14:44:49,116 - INFO - allennlp.common.params - model.antecedent_feedforward.activations = relu\n",
      "2022-03-29 14:44:49,116 - INFO - allennlp.common.params - type = relu\n",
      "2022-03-29 14:44:49,117 - INFO - allennlp.common.params - model.antecedent_feedforward.dropout = 0.3\n",
      "2022-03-29 14:44:49,218 - INFO - allennlp.common.params - model.feature_size = 20\n",
      "2022-03-29 14:44:49,219 - INFO - allennlp.common.params - model.max_span_width = 30\n",
      "2022-03-29 14:44:49,219 - INFO - allennlp.common.params - model.spans_per_word = 0.4\n",
      "2022-03-29 14:44:49,220 - INFO - allennlp.common.params - model.max_antecedents = 50\n",
      "2022-03-29 14:44:49,220 - INFO - allennlp.common.params - model.coarse_to_fine = True\n",
      "2022-03-29 14:44:49,221 - INFO - allennlp.common.params - model.inference_order = 2\n",
      "2022-03-29 14:44:49,221 - INFO - allennlp.common.params - model.lexical_dropout = 0.2\n",
      "2022-03-29 14:44:49,222 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f6e907be910>\n",
      "2022-03-29 14:44:49,283 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2022-03-29 14:44:49,286 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2022-03-29 14:44:49,286 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.0.bias\n",
      "2022-03-29 14:44:49,287 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.0.weight\n",
      "2022-03-29 14:44:49,287 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.1.bias\n",
      "2022-03-29 14:44:49,288 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.1.weight\n",
      "2022-03-29 14:44:49,288 - INFO - allennlp.nn.initializers -    _antecedent_scorer._module.bias\n",
      "2022-03-29 14:44:49,289 - INFO - allennlp.nn.initializers -    _antecedent_scorer._module.weight\n",
      "2022-03-29 14:44:49,289 - INFO - allennlp.nn.initializers -    _attentive_span_extractor._global_attention._module.bias\n",
      "2022-03-29 14:44:49,290 - INFO - allennlp.nn.initializers -    _attentive_span_extractor._global_attention._module.weight\n",
      "2022-03-29 14:44:49,290 - INFO - allennlp.nn.initializers -    _coarse2fine_scorer.bias\n",
      "2022-03-29 14:44:49,291 - INFO - allennlp.nn.initializers -    _coarse2fine_scorer.weight\n",
      "2022-03-29 14:44:49,291 - INFO - allennlp.nn.initializers -    _distance_embedding.weight\n",
      "2022-03-29 14:44:49,292 - INFO - allennlp.nn.initializers -    _endpoint_span_extractor._span_width_embedding.weight\n",
      "2022-03-29 14:44:49,293 - INFO - allennlp.nn.initializers -    _mention_feedforward._module._linear_layers.0.bias\n",
      "2022-03-29 14:44:49,293 - INFO - allennlp.nn.initializers -    _mention_feedforward._module._linear_layers.0.weight\n",
      "2022-03-29 14:44:49,294 - INFO - allennlp.nn.initializers -    _mention_feedforward._module._linear_layers.1.bias\n",
      "2022-03-29 14:44:49,294 - INFO - allennlp.nn.initializers -    _mention_feedforward._module._linear_layers.1.weight\n",
      "2022-03-29 14:44:49,295 - INFO - allennlp.nn.initializers -    _mention_scorer._module.bias\n",
      "2022-03-29 14:44:49,295 - INFO - allennlp.nn.initializers -    _mention_scorer._module.weight\n",
      "2022-03-29 14:44:49,296 - INFO - allennlp.nn.initializers -    _span_updating_gated_sum._gate.bias\n",
      "2022-03-29 14:44:49,296 - INFO - allennlp.nn.initializers -    _span_updating_gated_sum._gate.weight\n",
      "2022-03-29 14:44:49,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
      "2022-03-29 14:44:49,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
      "2022-03-29 14:44:49,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
      "2022-03-29 14:44:49,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
      "2022-03-29 14:44:49,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
      "2022-03-29 14:44:49,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
      "2022-03-29 14:44:49,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
      "2022-03-29 14:44:49,300 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:49,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
      "2022-03-29 14:44:49,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
      "2022-03-29 14:44:49,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
      "2022-03-29 14:44:49,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,302 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,302 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,302 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,303 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
      "2022-03-29 14:44:49,303 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
      "2022-03-29 14:44:49,303 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
      "2022-03-29 14:44:49,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
      "2022-03-29 14:44:49,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
      "2022-03-29 14:44:49,305 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
      "2022-03-29 14:44:49,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
      "2022-03-29 14:44:49,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
      "2022-03-29 14:44:49,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,307 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,307 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,307 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,307 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
      "2022-03-29 14:44:49,308 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
      "2022-03-29 14:44:49,308 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,308 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,309 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,309 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,309 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
      "2022-03-29 14:44:49,310 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
      "2022-03-29 14:44:49,310 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
      "2022-03-29 14:44:49,310 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
      "2022-03-29 14:44:49,310 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
      "2022-03-29 14:44:49,311 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
      "2022-03-29 14:44:49,311 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,311 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,312 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,312 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,312 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
      "2022-03-29 14:44:49,313 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
      "2022-03-29 14:44:49,313 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,313 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,313 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,314 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:49,314 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
      "2022-03-29 14:44:49,314 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
      "2022-03-29 14:44:49,315 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
      "2022-03-29 14:44:49,315 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
      "2022-03-29 14:44:49,315 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
      "2022-03-29 14:44:49,315 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
      "2022-03-29 14:44:49,316 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,316 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,316 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,317 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,317 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
      "2022-03-29 14:44:49,317 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
      "2022-03-29 14:44:49,318 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,318 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,318 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,319 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,319 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.key.bias\n",
      "2022-03-29 14:44:49,319 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.key.weight\n",
      "2022-03-29 14:44:49,320 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.query.bias\n",
      "2022-03-29 14:44:49,320 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.query.weight\n",
      "2022-03-29 14:44:49,320 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.value.bias\n",
      "2022-03-29 14:44:49,321 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.value.weight\n",
      "2022-03-29 14:44:49,321 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,321 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,322 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,322 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,322 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.dense.bias\n",
      "2022-03-29 14:44:49,323 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.dense.weight\n",
      "2022-03-29 14:44:49,323 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,323 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,324 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,324 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,324 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.key.bias\n",
      "2022-03-29 14:44:49,325 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.key.weight\n",
      "2022-03-29 14:44:49,325 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.query.bias\n",
      "2022-03-29 14:44:49,325 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.query.weight\n",
      "2022-03-29 14:44:49,326 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.value.bias\n",
      "2022-03-29 14:44:49,326 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.value.weight\n",
      "2022-03-29 14:44:49,326 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,327 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,327 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,327 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,328 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.dense.bias\n",
      "2022-03-29 14:44:49,328 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.dense.weight\n",
      "2022-03-29 14:44:49,328 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.LayerNorm.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:49,329 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,329 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,329 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,330 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.key.bias\n",
      "2022-03-29 14:44:49,330 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.key.weight\n",
      "2022-03-29 14:44:49,330 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.query.bias\n",
      "2022-03-29 14:44:49,331 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.query.weight\n",
      "2022-03-29 14:44:49,331 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.value.bias\n",
      "2022-03-29 14:44:49,331 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.value.weight\n",
      "2022-03-29 14:44:49,331 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,332 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,332 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,332 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,333 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.dense.bias\n",
      "2022-03-29 14:44:49,333 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.dense.weight\n",
      "2022-03-29 14:44:49,333 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,334 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,334 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,334 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,335 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.key.bias\n",
      "2022-03-29 14:44:49,335 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.key.weight\n",
      "2022-03-29 14:44:49,335 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.query.bias\n",
      "2022-03-29 14:44:49,336 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.query.weight\n",
      "2022-03-29 14:44:49,336 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.value.bias\n",
      "2022-03-29 14:44:49,336 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.value.weight\n",
      "2022-03-29 14:44:49,337 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,337 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,337 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,338 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,338 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.dense.bias\n",
      "2022-03-29 14:44:49,338 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.dense.weight\n",
      "2022-03-29 14:44:49,339 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,339 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,339 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,340 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,340 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.key.bias\n",
      "2022-03-29 14:44:49,340 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.key.weight\n",
      "2022-03-29 14:44:49,341 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.query.bias\n",
      "2022-03-29 14:44:49,341 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.query.weight\n",
      "2022-03-29 14:44:49,341 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.value.bias\n",
      "2022-03-29 14:44:49,342 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.value.weight\n",
      "2022-03-29 14:44:49,342 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,342 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,343 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,343 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.LayerNorm.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:49,343 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.dense.bias\n",
      "2022-03-29 14:44:49,344 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.dense.weight\n",
      "2022-03-29 14:44:49,344 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,344 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,345 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,345 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,345 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.key.bias\n",
      "2022-03-29 14:44:49,346 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.key.weight\n",
      "2022-03-29 14:44:49,346 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.query.bias\n",
      "2022-03-29 14:44:49,346 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.query.weight\n",
      "2022-03-29 14:44:49,347 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.value.bias\n",
      "2022-03-29 14:44:49,347 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.value.weight\n",
      "2022-03-29 14:44:49,347 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,348 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,348 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,348 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,349 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.dense.bias\n",
      "2022-03-29 14:44:49,349 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.dense.weight\n",
      "2022-03-29 14:44:49,350 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,350 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,350 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,351 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,351 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.key.bias\n",
      "2022-03-29 14:44:49,351 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.key.weight\n",
      "2022-03-29 14:44:49,352 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.query.bias\n",
      "2022-03-29 14:44:49,352 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.query.weight\n",
      "2022-03-29 14:44:49,352 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.value.bias\n",
      "2022-03-29 14:44:49,353 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.value.weight\n",
      "2022-03-29 14:44:49,353 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,353 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,354 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,354 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,354 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.dense.bias\n",
      "2022-03-29 14:44:49,355 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.dense.weight\n",
      "2022-03-29 14:44:49,355 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,355 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,356 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,356 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,356 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.key.bias\n",
      "2022-03-29 14:44:49,357 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.key.weight\n",
      "2022-03-29 14:44:49,357 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.query.bias\n",
      "2022-03-29 14:44:49,357 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.query.weight\n",
      "2022-03-29 14:44:49,357 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.value.bias\n",
      "2022-03-29 14:44:49,358 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.value.weight\n",
      "2022-03-29 14:44:49,358 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.intermediate.dense.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:49,358 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,359 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,359 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,359 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.dense.bias\n",
      "2022-03-29 14:44:49,360 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.dense.weight\n",
      "2022-03-29 14:44:49,360 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,360 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,361 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,361 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,361 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
      "2022-03-29 14:44:49,362 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
      "2022-03-29 14:44:49,362 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
      "2022-03-29 14:44:49,362 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
      "2022-03-29 14:44:49,363 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
      "2022-03-29 14:44:49,363 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
      "2022-03-29 14:44:49,363 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,364 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,364 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,364 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,365 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
      "2022-03-29 14:44:49,366 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
      "2022-03-29 14:44:49,366 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,367 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,367 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,367 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,368 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.key.bias\n",
      "2022-03-29 14:44:49,368 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.key.weight\n",
      "2022-03-29 14:44:49,368 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.query.bias\n",
      "2022-03-29 14:44:49,369 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.query.weight\n",
      "2022-03-29 14:44:49,369 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.value.bias\n",
      "2022-03-29 14:44:49,369 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.value.weight\n",
      "2022-03-29 14:44:49,370 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,370 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,370 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,371 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,371 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.dense.bias\n",
      "2022-03-29 14:44:49,371 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.dense.weight\n",
      "2022-03-29 14:44:49,372 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,372 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,373 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,373 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,373 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.key.bias\n",
      "2022-03-29 14:44:49,374 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.key.weight\n",
      "2022-03-29 14:44:49,374 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.query.bias\n",
      "2022-03-29 14:44:49,374 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.query.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:49,375 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.value.bias\n",
      "2022-03-29 14:44:49,375 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.value.weight\n",
      "2022-03-29 14:44:49,375 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,376 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,376 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,376 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,377 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.dense.bias\n",
      "2022-03-29 14:44:49,377 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.dense.weight\n",
      "2022-03-29 14:44:49,377 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,378 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,378 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,378 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,379 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.key.bias\n",
      "2022-03-29 14:44:49,379 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.key.weight\n",
      "2022-03-29 14:44:49,379 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.query.bias\n",
      "2022-03-29 14:44:49,379 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.query.weight\n",
      "2022-03-29 14:44:49,380 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.value.bias\n",
      "2022-03-29 14:44:49,380 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.value.weight\n",
      "2022-03-29 14:44:49,380 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,381 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,381 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,381 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.dense.bias\n",
      "2022-03-29 14:44:49,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.dense.weight\n",
      "2022-03-29 14:44:49,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.key.bias\n",
      "2022-03-29 14:44:49,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.key.weight\n",
      "2022-03-29 14:44:49,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.query.bias\n",
      "2022-03-29 14:44:49,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.query.weight\n",
      "2022-03-29 14:44:49,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.value.bias\n",
      "2022-03-29 14:44:49,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.value.weight\n",
      "2022-03-29 14:44:49,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.dense.bias\n",
      "2022-03-29 14:44:49,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.dense.weight\n",
      "2022-03-29 14:44:49,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:49,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
      "2022-03-29 14:44:49,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
      "2022-03-29 14:44:49,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
      "2022-03-29 14:44:49,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
      "2022-03-29 14:44:49,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
      "2022-03-29 14:44:49,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
      "2022-03-29 14:44:49,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
      "2022-03-29 14:44:49,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,394 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,394 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
      "2022-03-29 14:44:49,394 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
      "2022-03-29 14:44:49,395 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
      "2022-03-29 14:44:49,395 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
      "2022-03-29 14:44:49,395 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
      "2022-03-29 14:44:49,396 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
      "2022-03-29 14:44:49,396 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,396 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,397 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,397 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,397 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
      "2022-03-29 14:44:49,398 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
      "2022-03-29 14:44:49,398 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,398 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,399 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,399 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,399 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
      "2022-03-29 14:44:49,400 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
      "2022-03-29 14:44:49,400 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
      "2022-03-29 14:44:49,400 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
      "2022-03-29 14:44:49,401 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
      "2022-03-29 14:44:49,401 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
      "2022-03-29 14:44:49,401 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,402 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,402 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,402 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,403 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
      "2022-03-29 14:44:49,403 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
      "2022-03-29 14:44:49,403 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,404 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:49,404 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,405 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,405 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
      "2022-03-29 14:44:49,405 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
      "2022-03-29 14:44:49,405 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
      "2022-03-29 14:44:49,406 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
      "2022-03-29 14:44:49,406 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
      "2022-03-29 14:44:49,406 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
      "2022-03-29 14:44:49,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
      "2022-03-29 14:44:49,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
      "2022-03-29 14:44:49,409 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,409 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,409 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,410 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,410 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
      "2022-03-29 14:44:49,410 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
      "2022-03-29 14:44:49,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
      "2022-03-29 14:44:49,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
      "2022-03-29 14:44:49,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
      "2022-03-29 14:44:49,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
      "2022-03-29 14:44:49,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
      "2022-03-29 14:44:49,437 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
      "2022-03-29 14:44:49,437 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,438 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,438 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,438 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,439 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
      "2022-03-29 14:44:49,439 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
      "2022-03-29 14:44:49,439 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
      "2022-03-29 14:44:49,440 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
      "2022-03-29 14:44:49,440 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
      "2022-03-29 14:44:49,440 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
      "2022-03-29 14:44:49,441 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,441 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,441 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,442 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,442 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:44:49,442 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
      "2022-03-29 14:44:49,442 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,443 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,443 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
      "2022-03-29 14:44:49,444 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
      "2022-03-29 14:44:49,444 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
      "2022-03-29 14:44:49,444 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
      "2022-03-29 14:44:49,445 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
      "2022-03-29 14:44:49,445 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
      "2022-03-29 14:44:49,445 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
      "2022-03-29 14:44:49,446 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
      "2022-03-29 14:44:49,446 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
      "2022-03-29 14:44:49,446 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
      "2022-03-29 14:44:49,447 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2022-03-29 14:44:49,447 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2022-03-29 14:44:49,447 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
      "2022-03-29 14:44:49,448 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
      "2022-03-29 14:44:49,448 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.pooler.dense.bias\n",
      "2022-03-29 14:44:49,448 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.pooler.dense.weight\n",
      "2022-03-29 14:44:54,264 - INFO - allennlp.modules.token_embedders.embedding - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.\n",
      "2022-03-29 14:44:54,264 - INFO - allennlp.modules.token_embedders.embedding - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.\n",
      "2022-03-29 14:44:54,807 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmp6568mjb_\n"
     ]
    }
   ],
   "source": [
    "coref_model = NeuralCoreferenceProcessing(gpu_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3631ad13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                    | 87/500 [00:50<04:04,  1.69it/s]/home/tnguyen/miniconda/envs/coref/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:08<00:00,  1.62it/s]\n"
     ]
    }
   ],
   "source": [
    "result = coref_model.process(\"./data/DialogSum_Data/text_test.source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1334845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dot', 'sharp', 'newline', 'semicolon'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f58c57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"} # Person1: Ms. Dawson, I need you to take a dictation for me. # Person2: Yes, sir... # Person1: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready? # Person2: Yes, sir. Go ahead. # Person1: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited. # Person2: Sir, does this apply to intra-office communications only? Or will it also restrict external communications? # Person1: It should apply to all communications, not only in this office between employees, but also any outside communications. # Person2: But sir, many employees use Instant Messaging to communicate with their clients. # Person1: They will just have to change their communication methods. I don't want any - one using Instant Messaging in this office. It wastes too much time! Now, please continue with the memo. Where were we? # Person2: This applies to internal and external communications. # Person1: Yes. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. Any questions regarding this new policy may be directed to department heads. # Person2: Is that all? # Person1: Yes. Please get this memo typed up and distributed to all employees before 4 pm.\",\n",
       " {'top_spans': [[0, 0],\n",
       "   [2, 2],\n",
       "   [2, 5],\n",
       "   [2, 15],\n",
       "   [4, 5],\n",
       "   [7, 7],\n",
       "   [8, 8],\n",
       "   [9, 9],\n",
       "   [11, 11],\n",
       "   [12, 13],\n",
       "   [15, 15],\n",
       "   [18, 18],\n",
       "   [22, 22],\n",
       "   [23, 23],\n",
       "   [25, 25],\n",
       "   [27, 27],\n",
       "   [29, 29],\n",
       "   [30, 30],\n",
       "   [32, 36],\n",
       "   [32, 39],\n",
       "   [38, 39],\n",
       "   [41, 42],\n",
       "   [44, 44],\n",
       "   [45, 45],\n",
       "   [49, 49],\n",
       "   [53, 53],\n",
       "   [59, 59],\n",
       "   [61, 61],\n",
       "   [62, 63],\n",
       "   [64, 64],\n",
       "   [65, 65],\n",
       "   [65, 67],\n",
       "   [67, 67],\n",
       "   [68, 70],\n",
       "   [71, 71],\n",
       "   [72, 72],\n",
       "   [72, 78],\n",
       "   [74, 75],\n",
       "   [74, 78],\n",
       "   [80, 90],\n",
       "   [83, 85],\n",
       "   [87, 87],\n",
       "   [91, 91],\n",
       "   [93, 93],\n",
       "   [96, 96],\n",
       "   [98, 98],\n",
       "   [101, 101],\n",
       "   [102, 102],\n",
       "   [104, 107],\n",
       "   [112, 112],\n",
       "   [114, 114],\n",
       "   [119, 119],\n",
       "   [121, 121],\n",
       "   [123, 123],\n",
       "   [125, 134],\n",
       "   [125, 140],\n",
       "   [131, 132],\n",
       "   [134, 134],\n",
       "   [143, 143],\n",
       "   [146, 146],\n",
       "   [148, 149],\n",
       "   [150, 150],\n",
       "   [151, 152],\n",
       "   [154, 154],\n",
       "   [156, 156],\n",
       "   [156, 157],\n",
       "   [160, 160],\n",
       "   [162, 162],\n",
       "   [165, 165],\n",
       "   [167, 167],\n",
       "   [168, 168],\n",
       "   [168, 170],\n",
       "   [172, 172],\n",
       "   [174, 174],\n",
       "   [176, 178],\n",
       "   [176, 181],\n",
       "   [176, 184],\n",
       "   [179, 179],\n",
       "   [180, 181],\n",
       "   [183, 184],\n",
       "   [186, 186],\n",
       "   [187, 187],\n",
       "   [188, 190],\n",
       "   [194, 194],\n",
       "   [195, 195],\n",
       "   [197, 198],\n",
       "   [202, 202],\n",
       "   [205, 205],\n",
       "   [207, 207],\n",
       "   [208, 208],\n",
       "   [210, 213],\n",
       "   [216, 216],\n",
       "   [220, 227],\n",
       "   [223, 223],\n",
       "   [225, 225],\n",
       "   [226, 227],\n",
       "   [230, 230],\n",
       "   [231, 232],\n",
       "   [235, 235],\n",
       "   [237, 237],\n",
       "   [240, 241],\n",
       "   [243, 244],\n",
       "   [247, 247],\n",
       "   [249, 254],\n",
       "   [252, 254],\n",
       "   [257, 257],\n",
       "   [259, 260],\n",
       "   [263, 263],\n",
       "   [266, 266],\n",
       "   [274, 274],\n",
       "   [276, 277],\n",
       "   [278, 278],\n",
       "   [281, 281],\n",
       "   [283, 284],\n",
       "   [286, 287]],\n",
       "  'antecedent_indices': [[0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51],\n",
       "   [1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    40,\n",
       "    41,\n",
       "    43,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53],\n",
       "   [0,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    43,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54],\n",
       "   [2,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    42,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55],\n",
       "   [1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    40,\n",
       "    41,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56],\n",
       "   [1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    33,\n",
       "    35,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57],\n",
       "   [1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    18,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59],\n",
       "   [1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    33,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60],\n",
       "   [1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    18,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    55,\n",
       "    56,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61],\n",
       "   [1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    33,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    18,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    33,\n",
       "    35,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62],\n",
       "   [1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    34,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64],\n",
       "   [1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    40,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    64],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    18,\n",
       "    20,\n",
       "    21,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    30,\n",
       "    33,\n",
       "    35,\n",
       "    36,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66],\n",
       "   [2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    28,\n",
       "    29,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    35,\n",
       "    36,\n",
       "    40,\n",
       "    41,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    64,\n",
       "    65,\n",
       "    67],\n",
       "   [2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    18,\n",
       "    20,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    35,\n",
       "    36,\n",
       "    41,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68],\n",
       "   [1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    18,\n",
       "    20,\n",
       "    21,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    33,\n",
       "    35,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69],\n",
       "   [1,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    16,\n",
       "    18,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    33,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    44,\n",
       "    45,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    39,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    70],\n",
       "   [2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    20,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    40,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    56,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    70,\n",
       "    71,\n",
       "    72],\n",
       "   [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    18,\n",
       "    20,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    39,\n",
       "    40,\n",
       "    42,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    56,\n",
       "    58,\n",
       "    59,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    70,\n",
       "    72,\n",
       "    73],\n",
       "   [1,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    20,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    58,\n",
       "    59,\n",
       "    61,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74],\n",
       "   [0,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    20,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    34,\n",
       "    40,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    56,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    70,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75],\n",
       "   [2,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    18,\n",
       "    20,\n",
       "    21,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    52,\n",
       "    56,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    64,\n",
       "    67,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76],\n",
       "   [1,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    18,\n",
       "    20,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    35,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    56,\n",
       "    58,\n",
       "    59,\n",
       "    61,\n",
       "    62,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    69,\n",
       "    70,\n",
       "    72,\n",
       "    73,\n",
       "    75,\n",
       "    76,\n",
       "    77],\n",
       "   [2,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    39,\n",
       "    40,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    55,\n",
       "    56,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    77,\n",
       "    78],\n",
       "   [4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    33,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    55,\n",
       "    56,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    64,\n",
       "    67,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79],\n",
       "   [2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    18,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    33,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    56,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80],\n",
       "   [1,\n",
       "    2,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    18,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    29,\n",
       "    33,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    56,\n",
       "    58,\n",
       "    59,\n",
       "    62,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    70,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81],\n",
       "   [2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    33,\n",
       "    35,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    70,\n",
       "    71,\n",
       "    72],\n",
       "   [0,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    31,\n",
       "    33,\n",
       "    35,\n",
       "    36,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    64,\n",
       "    67,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    75,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80],\n",
       "   [3,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    33,\n",
       "    35,\n",
       "    36,\n",
       "    38,\n",
       "    39,\n",
       "    45,\n",
       "    46,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    55,\n",
       "    56,\n",
       "    58,\n",
       "    59,\n",
       "    62,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    78,\n",
       "    79,\n",
       "    80],\n",
       "   [2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    18,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    33,\n",
       "    35,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    70,\n",
       "    72,\n",
       "    74,\n",
       "    75,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    85],\n",
       "   [1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    18,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    35,\n",
       "    40,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    55,\n",
       "    56,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    70,\n",
       "    72,\n",
       "    75,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    85,\n",
       "    86],\n",
       "   [3,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    18,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    39,\n",
       "    40,\n",
       "    43,\n",
       "    45,\n",
       "    46,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    70,\n",
       "    72,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    85,\n",
       "    87],\n",
       "   [2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    28,\n",
       "    29,\n",
       "    33,\n",
       "    35,\n",
       "    36,\n",
       "    39,\n",
       "    40,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    62,\n",
       "    64,\n",
       "    67,\n",
       "    70,\n",
       "    72,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88],\n",
       "   [2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    33,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    59,\n",
       "    66,\n",
       "    67,\n",
       "    70,\n",
       "    72,\n",
       "    79,\n",
       "    80,\n",
       "    83,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89],\n",
       "   [1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    18,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    33,\n",
       "    35,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    61,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    70,\n",
       "    72,\n",
       "    79,\n",
       "    80,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89],\n",
       "   [0,\n",
       "    1,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    35,\n",
       "    36,\n",
       "    43,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    69,\n",
       "    70,\n",
       "    72,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    91],\n",
       "   [2,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    35,\n",
       "    43,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    56,\n",
       "    57,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    70,\n",
       "    72,\n",
       "    77,\n",
       "    79,\n",
       "    80,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    91,\n",
       "    92],\n",
       "   [2,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    28,\n",
       "    30,\n",
       "    37,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89],\n",
       "   [4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    30,\n",
       "    37,\n",
       "    38,\n",
       "    40,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    56,\n",
       "    58,\n",
       "    59,\n",
       "    61,\n",
       "    62,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    69,\n",
       "    70,\n",
       "    72,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    91,\n",
       "    92,\n",
       "    94],\n",
       "   [2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    15,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    28,\n",
       "    35,\n",
       "    37,\n",
       "    40,\n",
       "    41,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    52,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    59,\n",
       "    60,\n",
       "    64,\n",
       "    67,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    74,\n",
       "    75,\n",
       "    79,\n",
       "    80,\n",
       "    82,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    90,\n",
       "    92],\n",
       "   [1,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    27,\n",
       "    28,\n",
       "    30,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    40,\n",
       "    42,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    56,\n",
       "    58,\n",
       "    59,\n",
       "    61,\n",
       "    62,\n",
       "    66,\n",
       "    67,\n",
       "    72,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    85,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    91,\n",
       "    92,\n",
       "    95],\n",
       "   [2,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    18,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    28,\n",
       "    33,\n",
       "    35,\n",
       "    40,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    56,\n",
       "    57,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    70,\n",
       "    72,\n",
       "    75,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    95,\n",
       "    97],\n",
       "   [2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    15,\n",
       "    16,\n",
       "    20,\n",
       "    21,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    28,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    64,\n",
       "    67,\n",
       "    70,\n",
       "    72,\n",
       "    79,\n",
       "    80,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    92,\n",
       "    95],\n",
       "   [3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    16,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    27,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    35,\n",
       "    44,\n",
       "    45,\n",
       "    47,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    55,\n",
       "    56,\n",
       "    58,\n",
       "    59,\n",
       "    61,\n",
       "    63,\n",
       "    66,\n",
       "    67,\n",
       "    69,\n",
       "    70,\n",
       "    72,\n",
       "    77,\n",
       "    81,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    96],\n",
       "   [3,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    20,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    41,\n",
       "    45,\n",
       "    46,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    70,\n",
       "    72,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    90,\n",
       "    92,\n",
       "    95,\n",
       "    97,\n",
       "    99,\n",
       "    100],\n",
       "   [2,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    15,\n",
       "    16,\n",
       "    18,\n",
       "    20,\n",
       "    21,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    28,\n",
       "    35,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    52,\n",
       "    53,\n",
       "    55,\n",
       "    56,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    64,\n",
       "    67,\n",
       "    68,\n",
       "    70,\n",
       "    72,\n",
       "    75,\n",
       "    77,\n",
       "    79,\n",
       "    80,\n",
       "    85,\n",
       "    86,\n",
       "    88,\n",
       "    89,\n",
       "    92,\n",
       "    94,\n",
       "    95,\n",
       "    101],\n",
       "   [3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    34,\n",
       "    35,\n",
       "    45,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    55,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    77,\n",
       "    81,\n",
       "    83,\n",
       "    86,\n",
       "    88,\n",
       "    89,\n",
       "    96],\n",
       "   [1,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    39,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    56,\n",
       "    58,\n",
       "    59,\n",
       "    62,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    70,\n",
       "    72,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    91,\n",
       "    95],\n",
       "   [4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    15,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    28,\n",
       "    33,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    52,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    64,\n",
       "    67,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    74,\n",
       "    75,\n",
       "    77,\n",
       "    79,\n",
       "    80,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    90,\n",
       "    97,\n",
       "    100,\n",
       "    101,\n",
       "    103,\n",
       "    104],\n",
       "   [4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    16,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    34,\n",
       "    42,\n",
       "    45,\n",
       "    46,\n",
       "    49,\n",
       "    52,\n",
       "    53,\n",
       "    56,\n",
       "    57,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    64,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    81,\n",
       "    83,\n",
       "    86,\n",
       "    88,\n",
       "    89,\n",
       "    93,\n",
       "    103,\n",
       "    104,\n",
       "    105],\n",
       "   [4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    18,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    30,\n",
       "    35,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    56,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    70,\n",
       "    72,\n",
       "    79,\n",
       "    80,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    91,\n",
       "    95,\n",
       "    101,\n",
       "    104],\n",
       "   [3,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    15,\n",
       "    16,\n",
       "    18,\n",
       "    20,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    43,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    49,\n",
       "    52,\n",
       "    53,\n",
       "    55,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    64,\n",
       "    67,\n",
       "    68,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    103,\n",
       "    104,\n",
       "    107],\n",
       "   [1,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    18,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    30,\n",
       "    31,\n",
       "    33,\n",
       "    35,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    56,\n",
       "    57,\n",
       "    59,\n",
       "    60,\n",
       "    64,\n",
       "    66,\n",
       "    67,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    83,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    90,\n",
       "    103,\n",
       "    104,\n",
       "    107,\n",
       "    108],\n",
       "   [3,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    28,\n",
       "    29,\n",
       "    35,\n",
       "    36,\n",
       "    38,\n",
       "    45,\n",
       "    46,\n",
       "    49,\n",
       "    51,\n",
       "    52,\n",
       "    55,\n",
       "    56,\n",
       "    58,\n",
       "    59,\n",
       "    64,\n",
       "    67,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    95,\n",
       "    104,\n",
       "    107,\n",
       "    108],\n",
       "   [2,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    15,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    31,\n",
       "    40,\n",
       "    41,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    52,\n",
       "    56,\n",
       "    59,\n",
       "    60,\n",
       "    67,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    74,\n",
       "    75,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    85,\n",
       "    86,\n",
       "    88,\n",
       "    90,\n",
       "    97,\n",
       "    103,\n",
       "    104,\n",
       "    108,\n",
       "    109,\n",
       "    110],\n",
       "   [2,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    11,\n",
       "    12,\n",
       "    15,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    28,\n",
       "    37,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    52,\n",
       "    56,\n",
       "    59,\n",
       "    60,\n",
       "    62,\n",
       "    64,\n",
       "    67,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    75,\n",
       "    76,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    90,\n",
       "    101,\n",
       "    103,\n",
       "    104,\n",
       "    108,\n",
       "    109,\n",
       "    110],\n",
       "   [4,\n",
       "    7,\n",
       "    11,\n",
       "    12,\n",
       "    15,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    39,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    52,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    59,\n",
       "    60,\n",
       "    64,\n",
       "    67,\n",
       "    70,\n",
       "    71,\n",
       "    74,\n",
       "    75,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    83,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    90,\n",
       "    92,\n",
       "    95,\n",
       "    101,\n",
       "    104,\n",
       "    108,\n",
       "    110],\n",
       "   [3,\n",
       "    4,\n",
       "    5,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    15,\n",
       "    16,\n",
       "    18,\n",
       "    20,\n",
       "    21,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    28,\n",
       "    29,\n",
       "    40,\n",
       "    45,\n",
       "    46,\n",
       "    48,\n",
       "    49,\n",
       "    52,\n",
       "    56,\n",
       "    58,\n",
       "    59,\n",
       "    62,\n",
       "    64,\n",
       "    67,\n",
       "    70,\n",
       "    72,\n",
       "    75,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    95,\n",
       "    97,\n",
       "    101,\n",
       "    104,\n",
       "    107,\n",
       "    108,\n",
       "    110,\n",
       "    113]],\n",
       "  'predicted_antecedents': [-1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   4,\n",
       "   -1,\n",
       "   -1,\n",
       "   5,\n",
       "   4,\n",
       "   10,\n",
       "   -1,\n",
       "   5,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   7,\n",
       "   11,\n",
       "   5,\n",
       "   14,\n",
       "   -1,\n",
       "   20,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   10,\n",
       "   35,\n",
       "   -1,\n",
       "   -1,\n",
       "   46,\n",
       "   -1,\n",
       "   14,\n",
       "   44,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   9,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   47,\n",
       "   -1,\n",
       "   37,\n",
       "   43,\n",
       "   -1,\n",
       "   -1,\n",
       "   47,\n",
       "   -1,\n",
       "   10,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   37,\n",
       "   48,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   11,\n",
       "   -1,\n",
       "   9,\n",
       "   28,\n",
       "   -1,\n",
       "   -1,\n",
       "   28,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   45,\n",
       "   -1,\n",
       "   -1,\n",
       "   46,\n",
       "   -1,\n",
       "   -1,\n",
       "   5,\n",
       "   -1,\n",
       "   -1,\n",
       "   40,\n",
       "   -1,\n",
       "   -1,\n",
       "   5,\n",
       "   -1],\n",
       "  'document': ['}',\n",
       "   '#',\n",
       "   'Person1',\n",
       "   ':',\n",
       "   'Ms.',\n",
       "   'Dawson',\n",
       "   ',',\n",
       "   'I',\n",
       "   'need',\n",
       "   'you',\n",
       "   'to',\n",
       "   'take',\n",
       "   'a',\n",
       "   'dictation',\n",
       "   'for',\n",
       "   'me',\n",
       "   '.',\n",
       "   '#',\n",
       "   'Person2',\n",
       "   ':',\n",
       "   'Yes',\n",
       "   ',',\n",
       "   'sir',\n",
       "   '...',\n",
       "   '#',\n",
       "   'Person1',\n",
       "   ':',\n",
       "   'This',\n",
       "   'should',\n",
       "   'go',\n",
       "   'out',\n",
       "   'as',\n",
       "   'an',\n",
       "   'intra',\n",
       "   '-',\n",
       "   'office',\n",
       "   'memorandum',\n",
       "   'to',\n",
       "   'all',\n",
       "   'employees',\n",
       "   'by',\n",
       "   'this',\n",
       "   'afternoon',\n",
       "   '.',\n",
       "   'Are',\n",
       "   'you',\n",
       "   'ready',\n",
       "   '?',\n",
       "   '#',\n",
       "   'Person2',\n",
       "   ':',\n",
       "   'Yes',\n",
       "   ',',\n",
       "   'sir',\n",
       "   '.',\n",
       "   'Go',\n",
       "   'ahead',\n",
       "   '.',\n",
       "   '#',\n",
       "   'Person1',\n",
       "   ':',\n",
       "   'Attention',\n",
       "   'all',\n",
       "   'staff',\n",
       "   '...',\n",
       "   'Effective',\n",
       "   'immediately',\n",
       "   ',',\n",
       "   'all',\n",
       "   'office',\n",
       "   'communications',\n",
       "   'are',\n",
       "   'restricted',\n",
       "   'to',\n",
       "   'email',\n",
       "   'correspondence',\n",
       "   'and',\n",
       "   'official',\n",
       "   'memos',\n",
       "   '.',\n",
       "   'The',\n",
       "   'use',\n",
       "   'of',\n",
       "   'Instant',\n",
       "   'Message',\n",
       "   'programs',\n",
       "   'by',\n",
       "   'employees',\n",
       "   'during',\n",
       "   'working',\n",
       "   'hours',\n",
       "   'is',\n",
       "   'strictly',\n",
       "   'prohibited',\n",
       "   '.',\n",
       "   '#',\n",
       "   'Person2',\n",
       "   ':',\n",
       "   'Sir',\n",
       "   ',',\n",
       "   'does',\n",
       "   'this',\n",
       "   'apply',\n",
       "   'to',\n",
       "   'intra',\n",
       "   '-',\n",
       "   'office',\n",
       "   'communications',\n",
       "   'only',\n",
       "   '?',\n",
       "   'Or',\n",
       "   'will',\n",
       "   'it',\n",
       "   'also',\n",
       "   'restrict',\n",
       "   'external',\n",
       "   'communications',\n",
       "   '?',\n",
       "   '#',\n",
       "   'Person1',\n",
       "   ':',\n",
       "   'It',\n",
       "   'should',\n",
       "   'apply',\n",
       "   'to',\n",
       "   'all',\n",
       "   'communications',\n",
       "   ',',\n",
       "   'not',\n",
       "   'only',\n",
       "   'in',\n",
       "   'this',\n",
       "   'office',\n",
       "   'between',\n",
       "   'employees',\n",
       "   ',',\n",
       "   'but',\n",
       "   'also',\n",
       "   'any',\n",
       "   'outside',\n",
       "   'communications',\n",
       "   '.',\n",
       "   '#',\n",
       "   'Person2',\n",
       "   ':',\n",
       "   'But',\n",
       "   'sir',\n",
       "   ',',\n",
       "   'many',\n",
       "   'employees',\n",
       "   'use',\n",
       "   'Instant',\n",
       "   'Messaging',\n",
       "   'to',\n",
       "   'communicate',\n",
       "   'with',\n",
       "   'their',\n",
       "   'clients',\n",
       "   '.',\n",
       "   '#',\n",
       "   'Person1',\n",
       "   ':',\n",
       "   'They',\n",
       "   'will',\n",
       "   'just',\n",
       "   'have',\n",
       "   'to',\n",
       "   'change',\n",
       "   'their',\n",
       "   'communication',\n",
       "   'methods',\n",
       "   '.',\n",
       "   'I',\n",
       "   'do',\n",
       "   \"n't\",\n",
       "   'want',\n",
       "   'any',\n",
       "   '-',\n",
       "   'one',\n",
       "   'using',\n",
       "   'Instant',\n",
       "   'Messaging',\n",
       "   'in',\n",
       "   'this',\n",
       "   'office',\n",
       "   '.',\n",
       "   'It',\n",
       "   'wastes',\n",
       "   'too',\n",
       "   'much',\n",
       "   'time',\n",
       "   '!',\n",
       "   'Now',\n",
       "   ',',\n",
       "   'please',\n",
       "   'continue',\n",
       "   'with',\n",
       "   'the',\n",
       "   'memo',\n",
       "   '.',\n",
       "   'Where',\n",
       "   'were',\n",
       "   'we',\n",
       "   '?',\n",
       "   '#',\n",
       "   'Person2',\n",
       "   ':',\n",
       "   'This',\n",
       "   'applies',\n",
       "   'to',\n",
       "   'internal',\n",
       "   'and',\n",
       "   'external',\n",
       "   'communications',\n",
       "   '.',\n",
       "   '#',\n",
       "   'Person1',\n",
       "   ':',\n",
       "   'Yes',\n",
       "   '.',\n",
       "   'Any',\n",
       "   'employee',\n",
       "   'who',\n",
       "   'persists',\n",
       "   'in',\n",
       "   'using',\n",
       "   'Instant',\n",
       "   'Messaging',\n",
       "   'will',\n",
       "   'first',\n",
       "   'receive',\n",
       "   'a',\n",
       "   'warning',\n",
       "   'and',\n",
       "   'be',\n",
       "   'placed',\n",
       "   'on',\n",
       "   'probation',\n",
       "   '.',\n",
       "   'At',\n",
       "   'second',\n",
       "   'offense',\n",
       "   ',',\n",
       "   'the',\n",
       "   'employee',\n",
       "   'will',\n",
       "   'face',\n",
       "   'termination',\n",
       "   '.',\n",
       "   'Any',\n",
       "   'questions',\n",
       "   'regarding',\n",
       "   'this',\n",
       "   'new',\n",
       "   'policy',\n",
       "   'may',\n",
       "   'be',\n",
       "   'directed',\n",
       "   'to',\n",
       "   'department',\n",
       "   'heads',\n",
       "   '.',\n",
       "   '#',\n",
       "   'Person2',\n",
       "   ':',\n",
       "   'Is',\n",
       "   'that',\n",
       "   'all',\n",
       "   '?',\n",
       "   '#',\n",
       "   'Person1',\n",
       "   ':',\n",
       "   'Yes',\n",
       "   '.',\n",
       "   'Please',\n",
       "   'get',\n",
       "   'this',\n",
       "   'memo',\n",
       "   'typed',\n",
       "   'up',\n",
       "   'and',\n",
       "   'distributed',\n",
       "   'to',\n",
       "   'all',\n",
       "   'employees',\n",
       "   'before',\n",
       "   '4',\n",
       "   'pm',\n",
       "   '.'],\n",
       "  'clusters': [[[4, 5],\n",
       "    [9, 9],\n",
       "    [18, 18],\n",
       "    [45, 45],\n",
       "    [49, 49],\n",
       "    [205, 205],\n",
       "    [263, 263]],\n",
       "   [[7, 7],\n",
       "    [15, 15],\n",
       "    [22, 22],\n",
       "    [25, 25],\n",
       "    [53, 53],\n",
       "    [59, 59],\n",
       "    [98, 98],\n",
       "    [119, 119],\n",
       "    [146, 146],\n",
       "    [160, 160],\n",
       "    [172, 172],\n",
       "    [216, 216]],\n",
       "   [[38, 39], [62, 63], [283, 284]],\n",
       "   [[72, 72], [101, 101], [112, 112], [121, 121], [207, 207], [252, 254]],\n",
       "   [[148, 149], [156, 156], [162, 162], [168, 168]],\n",
       "   [[131, 132], [183, 184]],\n",
       "   [[180, 181], [186, 186]],\n",
       "   [[27, 27], [197, 198], [276, 277]],\n",
       "   [[220, 227], [243, 244]]]})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]['semicolon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81509393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[2, 2],\n",
       "  [7, 7],\n",
       "  [15, 15],\n",
       "  [22, 22],\n",
       "  [25, 25],\n",
       "  [53, 53],\n",
       "  [59, 59],\n",
       "  [98, 98],\n",
       "  [119, 119],\n",
       "  [146, 146],\n",
       "  [160, 160],\n",
       "  [172, 172]],\n",
       " [[4, 5],\n",
       "  [9, 9],\n",
       "  [18, 18],\n",
       "  [45, 45],\n",
       "  [49, 49],\n",
       "  [143, 143],\n",
       "  [205, 205],\n",
       "  [263, 263]],\n",
       " [[38, 39], [62, 63], [283, 284]],\n",
       " [[72, 72], [101, 101], [112, 112], [121, 121], [207, 207], [252, 254]],\n",
       " [[148, 149], [156, 156], [162, 162], [168, 168]],\n",
       " [[131, 132], [183, 184]],\n",
       " [[180, 181], [186, 186]],\n",
       " [[27, 27], [197, 198], [276, 277]],\n",
       " [[220, 227], [243, 244]]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]['dot'][1]['clusters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1a250d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transfomer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransfomer\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transfomer'"
     ]
    }
   ],
   "source": [
    "import transfomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7620d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [ open(f'data/DialogSum_Data/{split}_dialogsum_all.target').readlines() for split in ['train', 'val', 'test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d7851b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, target_list in enumerate(targets):\n",
    "    for j, target in enumerate(targets[i]):\n",
    "        targets[i][j] = target.replace('#', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a0bd60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, target_list in zip(['train', 'val', 'test'], targets):\n",
    "    trgts = [data for data in target_list]\n",
    "    out_path = os.path.join(data_path, f'{name}.target')\n",
    "    with open(out_path, 'w') as file:\n",
    "        file.writelines(trgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "63ceffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_path, 'r') as file:\n",
    "    target_lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e282bfc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Person1 and Brian are at the birthday party of Brian. Brian thinks Person1 looks great and is popular.\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_lines[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16bb94f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
